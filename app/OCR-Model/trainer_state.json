{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 25.0,
  "eval_steps": 200,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014285714285714285,
      "grad_norm": NaN,
      "learning_rate": 5e-05,
      "loss": 11.417,
      "step": 2
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 74.72924041748047,
      "learning_rate": 4.9971428571428576e-05,
      "loss": 10.7108,
      "step": 4
    },
    {
      "epoch": 0.04285714285714286,
      "grad_norm": 38.20363998413086,
      "learning_rate": 4.994285714285715e-05,
      "loss": 7.6499,
      "step": 6
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 45.96473693847656,
      "learning_rate": 4.9914285714285717e-05,
      "loss": 5.7655,
      "step": 8
    },
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 48.4364128112793,
      "learning_rate": 4.9885714285714283e-05,
      "loss": 5.2396,
      "step": 10
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": NaN,
      "learning_rate": 4.9871428571428574e-05,
      "loss": 3.6906,
      "step": 12
    },
    {
      "epoch": 0.1,
      "grad_norm": 56.531742095947266,
      "learning_rate": 4.984285714285715e-05,
      "loss": 3.4117,
      "step": 14
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 41.45170211791992,
      "learning_rate": 4.981428571428572e-05,
      "loss": 3.0163,
      "step": 16
    },
    {
      "epoch": 0.12857142857142856,
      "grad_norm": 54.28135681152344,
      "learning_rate": 4.978571428571429e-05,
      "loss": 2.9889,
      "step": 18
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 37.647029876708984,
      "learning_rate": 4.9757142857142855e-05,
      "loss": 2.5636,
      "step": 20
    },
    {
      "epoch": 0.15714285714285714,
      "grad_norm": 35.09331130981445,
      "learning_rate": 4.972857142857143e-05,
      "loss": 2.6848,
      "step": 22
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 44.87449264526367,
      "learning_rate": 4.97e-05,
      "loss": 2.584,
      "step": 24
    },
    {
      "epoch": 0.18571428571428572,
      "grad_norm": 35.9012451171875,
      "learning_rate": 4.9671428571428576e-05,
      "loss": 2.297,
      "step": 26
    },
    {
      "epoch": 0.2,
      "grad_norm": 40.46481704711914,
      "learning_rate": 4.964285714285715e-05,
      "loss": 2.2719,
      "step": 28
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 61.50178146362305,
      "learning_rate": 4.9614285714285716e-05,
      "loss": 2.3595,
      "step": 30
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 56.048789978027344,
      "learning_rate": 4.958571428571428e-05,
      "loss": 2.3574,
      "step": 32
    },
    {
      "epoch": 0.24285714285714285,
      "grad_norm": 44.23520278930664,
      "learning_rate": 4.9557142857142857e-05,
      "loss": 2.0151,
      "step": 34
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 31.054216384887695,
      "learning_rate": 4.952857142857143e-05,
      "loss": 1.9995,
      "step": 36
    },
    {
      "epoch": 0.2714285714285714,
      "grad_norm": 46.7239875793457,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 2.2406,
      "step": 38
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 32.80630874633789,
      "learning_rate": 4.947142857142858e-05,
      "loss": 1.6825,
      "step": 40
    },
    {
      "epoch": 0.3,
      "grad_norm": 36.915897369384766,
      "learning_rate": 4.9442857142857144e-05,
      "loss": 1.7379,
      "step": 42
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 46.000221252441406,
      "learning_rate": 4.941428571428572e-05,
      "loss": 1.9277,
      "step": 44
    },
    {
      "epoch": 0.32857142857142857,
      "grad_norm": 37.29416275024414,
      "learning_rate": 4.938571428571429e-05,
      "loss": 2.0655,
      "step": 46
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 34.78339385986328,
      "learning_rate": 4.935714285714286e-05,
      "loss": 1.8858,
      "step": 48
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 36.64944076538086,
      "learning_rate": 4.932857142857143e-05,
      "loss": 2.2399,
      "step": 50
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 38.489288330078125,
      "learning_rate": 4.93e-05,
      "loss": 1.8476,
      "step": 52
    },
    {
      "epoch": 0.38571428571428573,
      "grad_norm": 27.469757080078125,
      "learning_rate": 4.927142857142857e-05,
      "loss": 1.7882,
      "step": 54
    },
    {
      "epoch": 0.4,
      "grad_norm": 32.98270797729492,
      "learning_rate": 4.9242857142857146e-05,
      "loss": 1.6989,
      "step": 56
    },
    {
      "epoch": 0.4142857142857143,
      "grad_norm": 29.227134704589844,
      "learning_rate": 4.921428571428572e-05,
      "loss": 1.7357,
      "step": 58
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 20.879175186157227,
      "learning_rate": 4.9185714285714293e-05,
      "loss": 1.6318,
      "step": 60
    },
    {
      "epoch": 0.44285714285714284,
      "grad_norm": 27.32024574279785,
      "learning_rate": 4.915714285714286e-05,
      "loss": 1.4433,
      "step": 62
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 35.288169860839844,
      "learning_rate": 4.912857142857143e-05,
      "loss": 1.3412,
      "step": 64
    },
    {
      "epoch": 0.4714285714285714,
      "grad_norm": 28.43492889404297,
      "learning_rate": 4.91e-05,
      "loss": 1.4807,
      "step": 66
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 34.238487243652344,
      "learning_rate": 4.9071428571428574e-05,
      "loss": 1.3046,
      "step": 68
    },
    {
      "epoch": 0.5,
      "grad_norm": 39.100467681884766,
      "learning_rate": 4.904285714285715e-05,
      "loss": 1.1041,
      "step": 70
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 34.602596282958984,
      "learning_rate": 4.9014285714285715e-05,
      "loss": 1.2429,
      "step": 72
    },
    {
      "epoch": 0.5285714285714286,
      "grad_norm": 25.1584415435791,
      "learning_rate": 4.898571428571429e-05,
      "loss": 1.3335,
      "step": 74
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 40.21779251098633,
      "learning_rate": 4.8957142857142855e-05,
      "loss": 1.6673,
      "step": 76
    },
    {
      "epoch": 0.5571428571428572,
      "grad_norm": 37.6695442199707,
      "learning_rate": 4.892857142857143e-05,
      "loss": 1.2806,
      "step": 78
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 35.848079681396484,
      "learning_rate": 4.89e-05,
      "loss": 1.4718,
      "step": 80
    },
    {
      "epoch": 0.5857142857142857,
      "grad_norm": 27.18779182434082,
      "learning_rate": 4.8871428571428576e-05,
      "loss": 1.1542,
      "step": 82
    },
    {
      "epoch": 0.6,
      "grad_norm": 27.84397315979004,
      "learning_rate": 4.884285714285714e-05,
      "loss": 1.3094,
      "step": 84
    },
    {
      "epoch": 0.6142857142857143,
      "grad_norm": 17.99553871154785,
      "learning_rate": 4.881428571428572e-05,
      "loss": 1.0058,
      "step": 86
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 28.06264305114746,
      "learning_rate": 4.878571428571429e-05,
      "loss": 1.1722,
      "step": 88
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 20.400943756103516,
      "learning_rate": 4.875714285714286e-05,
      "loss": 0.8194,
      "step": 90
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 26.953327178955078,
      "learning_rate": 4.872857142857143e-05,
      "loss": 0.841,
      "step": 92
    },
    {
      "epoch": 0.6714285714285714,
      "grad_norm": 44.71463394165039,
      "learning_rate": 4.87e-05,
      "loss": 1.3768,
      "step": 94
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 36.24746322631836,
      "learning_rate": 4.867142857142857e-05,
      "loss": 1.0257,
      "step": 96
    },
    {
      "epoch": 0.7,
      "grad_norm": 40.6866340637207,
      "learning_rate": 4.8642857142857145e-05,
      "loss": 1.3046,
      "step": 98
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 25.432315826416016,
      "learning_rate": 4.861428571428572e-05,
      "loss": 1.2029,
      "step": 100
    },
    {
      "epoch": 0.7285714285714285,
      "grad_norm": 39.66619873046875,
      "learning_rate": 4.858571428571429e-05,
      "loss": 1.1738,
      "step": 102
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 33.17524337768555,
      "learning_rate": 4.855714285714286e-05,
      "loss": 1.243,
      "step": 104
    },
    {
      "epoch": 0.7571428571428571,
      "grad_norm": 28.68387794494629,
      "learning_rate": 4.8528571428571426e-05,
      "loss": 1.0115,
      "step": 106
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 24.698101043701172,
      "learning_rate": 4.85e-05,
      "loss": 1.0738,
      "step": 108
    },
    {
      "epoch": 0.7857142857142857,
      "grad_norm": 27.580968856811523,
      "learning_rate": 4.8471428571428573e-05,
      "loss": 0.8389,
      "step": 110
    },
    {
      "epoch": 0.8,
      "grad_norm": 18.761428833007812,
      "learning_rate": 4.844285714285715e-05,
      "loss": 0.948,
      "step": 112
    },
    {
      "epoch": 0.8142857142857143,
      "grad_norm": 40.87208938598633,
      "learning_rate": 4.841428571428572e-05,
      "loss": 0.9663,
      "step": 114
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 20.959184646606445,
      "learning_rate": 4.838571428571429e-05,
      "loss": 0.7909,
      "step": 116
    },
    {
      "epoch": 0.8428571428571429,
      "grad_norm": 26.859760284423828,
      "learning_rate": 4.835714285714286e-05,
      "loss": 0.9722,
      "step": 118
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 34.050567626953125,
      "learning_rate": 4.832857142857143e-05,
      "loss": 1.1471,
      "step": 120
    },
    {
      "epoch": 0.8714285714285714,
      "grad_norm": 35.60254669189453,
      "learning_rate": 4.83e-05,
      "loss": 0.8828,
      "step": 122
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 27.981271743774414,
      "learning_rate": 4.8271428571428575e-05,
      "loss": 0.7969,
      "step": 124
    },
    {
      "epoch": 0.9,
      "grad_norm": 32.14347839355469,
      "learning_rate": 4.824285714285714e-05,
      "loss": 0.5524,
      "step": 126
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 25.117469787597656,
      "learning_rate": 4.8214285714285716e-05,
      "loss": 0.4845,
      "step": 128
    },
    {
      "epoch": 0.9285714285714286,
      "grad_norm": 21.665712356567383,
      "learning_rate": 4.818571428571429e-05,
      "loss": 0.6184,
      "step": 130
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 18.2446231842041,
      "learning_rate": 4.815714285714286e-05,
      "loss": 0.3802,
      "step": 132
    },
    {
      "epoch": 0.9571428571428572,
      "grad_norm": 14.431386947631836,
      "learning_rate": 4.812857142857143e-05,
      "loss": 0.4718,
      "step": 134
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 83.50897216796875,
      "learning_rate": 4.8100000000000004e-05,
      "loss": 0.727,
      "step": 136
    },
    {
      "epoch": 0.9857142857142858,
      "grad_norm": 65.94207763671875,
      "learning_rate": 4.807142857142857e-05,
      "loss": 0.8196,
      "step": 138
    },
    {
      "epoch": 1.0,
      "grad_norm": 48.24192810058594,
      "learning_rate": 4.8042857142857144e-05,
      "loss": 0.3872,
      "step": 140
    },
    {
      "epoch": 1.0142857142857142,
      "grad_norm": 90.51876068115234,
      "learning_rate": 4.801428571428572e-05,
      "loss": 0.4801,
      "step": 142
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 96.5098648071289,
      "learning_rate": 4.8e-05,
      "loss": 0.8244,
      "step": 144
    },
    {
      "epoch": 1.042857142857143,
      "grad_norm": 38.919532775878906,
      "learning_rate": 4.7971428571428575e-05,
      "loss": 0.6647,
      "step": 146
    },
    {
      "epoch": 1.0571428571428572,
      "grad_norm": 51.89517593383789,
      "learning_rate": 4.794285714285714e-05,
      "loss": 0.659,
      "step": 148
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 34.965171813964844,
      "learning_rate": 4.7914285714285715e-05,
      "loss": 0.6128,
      "step": 150
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 30.405061721801758,
      "learning_rate": 4.788571428571429e-05,
      "loss": 0.5986,
      "step": 152
    },
    {
      "epoch": 1.1,
      "grad_norm": 9.285736083984375,
      "learning_rate": 4.785714285714286e-05,
      "loss": 0.1931,
      "step": 154
    },
    {
      "epoch": 1.1142857142857143,
      "grad_norm": 17.27012062072754,
      "learning_rate": 4.782857142857143e-05,
      "loss": 0.4894,
      "step": 156
    },
    {
      "epoch": 1.1285714285714286,
      "grad_norm": 39.87418746948242,
      "learning_rate": 4.78e-05,
      "loss": 0.6375,
      "step": 158
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 6.196207523345947,
      "learning_rate": 4.777142857142857e-05,
      "loss": 0.0519,
      "step": 160
    },
    {
      "epoch": 1.157142857142857,
      "grad_norm": 23.35242462158203,
      "learning_rate": 4.7742857142857144e-05,
      "loss": 0.3631,
      "step": 162
    },
    {
      "epoch": 1.1714285714285715,
      "grad_norm": 26.89459228515625,
      "learning_rate": 4.771428571428572e-05,
      "loss": 0.4127,
      "step": 164
    },
    {
      "epoch": 1.1857142857142857,
      "grad_norm": 5.869510650634766,
      "learning_rate": 4.768571428571429e-05,
      "loss": 0.4247,
      "step": 166
    },
    {
      "epoch": 1.2,
      "grad_norm": 62.168617248535156,
      "learning_rate": 4.7657142857142865e-05,
      "loss": 0.257,
      "step": 168
    },
    {
      "epoch": 1.2142857142857142,
      "grad_norm": 58.80185317993164,
      "learning_rate": 4.762857142857143e-05,
      "loss": 0.2158,
      "step": 170
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 8.836320877075195,
      "learning_rate": 4.76e-05,
      "loss": 0.0494,
      "step": 172
    },
    {
      "epoch": 1.2428571428571429,
      "grad_norm": 13.692083358764648,
      "learning_rate": 4.757142857142857e-05,
      "loss": 0.0512,
      "step": 174
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 44.12244415283203,
      "learning_rate": 4.7542857142857146e-05,
      "loss": 0.3866,
      "step": 176
    },
    {
      "epoch": 1.2714285714285714,
      "grad_norm": 188.0486297607422,
      "learning_rate": 4.751428571428572e-05,
      "loss": 0.3124,
      "step": 178
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 10.87142276763916,
      "learning_rate": 4.7485714285714286e-05,
      "loss": 0.2987,
      "step": 180
    },
    {
      "epoch": 1.3,
      "grad_norm": 11.84122371673584,
      "learning_rate": 4.745714285714286e-05,
      "loss": 0.1758,
      "step": 182
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 16.83974266052246,
      "learning_rate": 4.742857142857143e-05,
      "loss": 0.6587,
      "step": 184
    },
    {
      "epoch": 1.3285714285714285,
      "grad_norm": 32.249778747558594,
      "learning_rate": 4.74e-05,
      "loss": 0.2226,
      "step": 186
    },
    {
      "epoch": 1.342857142857143,
      "grad_norm": 15.376031875610352,
      "learning_rate": 4.7371428571428574e-05,
      "loss": 0.1057,
      "step": 188
    },
    {
      "epoch": 1.3571428571428572,
      "grad_norm": 26.071701049804688,
      "learning_rate": 4.734285714285715e-05,
      "loss": 0.0657,
      "step": 190
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 14.398945808410645,
      "learning_rate": 4.7314285714285714e-05,
      "loss": 0.1993,
      "step": 192
    },
    {
      "epoch": 1.3857142857142857,
      "grad_norm": 17.358287811279297,
      "learning_rate": 4.728571428571429e-05,
      "loss": 0.087,
      "step": 194
    },
    {
      "epoch": 1.4,
      "grad_norm": 52.0725212097168,
      "learning_rate": 4.725714285714286e-05,
      "loss": 0.4521,
      "step": 196
    },
    {
      "epoch": 1.4142857142857144,
      "grad_norm": 38.650909423828125,
      "learning_rate": 4.7228571428571435e-05,
      "loss": 0.3707,
      "step": 198
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 162.7036590576172,
      "learning_rate": 4.72e-05,
      "loss": 0.4919,
      "step": 200
    },
    {
      "epoch": 1.4285714285714286,
      "eval_cer": 0.08488964346349745,
      "eval_loss": 0.20441439747810364,
      "eval_runtime": 20.4678,
      "eval_samples_per_second": 13.631,
      "eval_steps_per_second": 1.71,
      "step": 200
    },
    {
      "epoch": 1.4428571428571428,
      "grad_norm": 144.7506103515625,
      "learning_rate": 4.717142857142857e-05,
      "loss": 0.3262,
      "step": 202
    },
    {
      "epoch": 1.457142857142857,
      "grad_norm": 41.960689544677734,
      "learning_rate": 4.714285714285714e-05,
      "loss": 0.1923,
      "step": 204
    },
    {
      "epoch": 1.4714285714285715,
      "grad_norm": 10.617203712463379,
      "learning_rate": 4.7114285714285716e-05,
      "loss": 0.1522,
      "step": 206
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 22.969680786132812,
      "learning_rate": 4.708571428571429e-05,
      "loss": 0.4427,
      "step": 208
    },
    {
      "epoch": 1.5,
      "grad_norm": 15.391818046569824,
      "learning_rate": 4.7057142857142864e-05,
      "loss": 0.3029,
      "step": 210
    },
    {
      "epoch": 1.5142857142857142,
      "grad_norm": 6.7787981033325195,
      "learning_rate": 4.702857142857143e-05,
      "loss": 0.3057,
      "step": 212
    },
    {
      "epoch": 1.5285714285714285,
      "grad_norm": 17.294540405273438,
      "learning_rate": 4.7e-05,
      "loss": 0.168,
      "step": 214
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 22.435443878173828,
      "learning_rate": 4.697142857142857e-05,
      "loss": 0.33,
      "step": 216
    },
    {
      "epoch": 1.5571428571428572,
      "grad_norm": 17.897396087646484,
      "learning_rate": 4.6942857142857145e-05,
      "loss": 0.1557,
      "step": 218
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 18.246021270751953,
      "learning_rate": 4.691428571428572e-05,
      "loss": 0.3452,
      "step": 220
    },
    {
      "epoch": 1.5857142857142859,
      "grad_norm": 6.9953107833862305,
      "learning_rate": 4.6885714285714285e-05,
      "loss": 0.1826,
      "step": 222
    },
    {
      "epoch": 1.6,
      "grad_norm": 17.17141342163086,
      "learning_rate": 4.685714285714286e-05,
      "loss": 0.1806,
      "step": 224
    },
    {
      "epoch": 1.6142857142857143,
      "grad_norm": 17.963184356689453,
      "learning_rate": 4.682857142857143e-05,
      "loss": 0.1184,
      "step": 226
    },
    {
      "epoch": 1.6285714285714286,
      "grad_norm": 10.309725761413574,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.1438,
      "step": 228
    },
    {
      "epoch": 1.6428571428571428,
      "grad_norm": 26.43284034729004,
      "learning_rate": 4.677142857142857e-05,
      "loss": 0.2774,
      "step": 230
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 2.0131962299346924,
      "learning_rate": 4.6742857142857146e-05,
      "loss": 0.0155,
      "step": 232
    },
    {
      "epoch": 1.6714285714285713,
      "grad_norm": 10.699066162109375,
      "learning_rate": 4.671428571428571e-05,
      "loss": 0.0306,
      "step": 234
    },
    {
      "epoch": 1.6857142857142857,
      "grad_norm": 32.34605407714844,
      "learning_rate": 4.668571428571429e-05,
      "loss": 0.2231,
      "step": 236
    },
    {
      "epoch": 1.7,
      "grad_norm": 42.868743896484375,
      "learning_rate": 4.665714285714286e-05,
      "loss": 0.4832,
      "step": 238
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 33.525733947753906,
      "learning_rate": 4.6628571428571434e-05,
      "loss": 0.385,
      "step": 240
    },
    {
      "epoch": 1.7285714285714286,
      "grad_norm": 29.189729690551758,
      "learning_rate": 4.660000000000001e-05,
      "loss": 0.2963,
      "step": 242
    },
    {
      "epoch": 1.7428571428571429,
      "grad_norm": 0.5874791145324707,
      "learning_rate": 4.6571428571428575e-05,
      "loss": 0.1648,
      "step": 244
    },
    {
      "epoch": 1.7571428571428571,
      "grad_norm": 8.399590492248535,
      "learning_rate": 4.654285714285714e-05,
      "loss": 0.0826,
      "step": 246
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 16.06586456298828,
      "learning_rate": 4.6514285714285715e-05,
      "loss": 0.3234,
      "step": 248
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 19.958303451538086,
      "learning_rate": 4.648571428571429e-05,
      "loss": 0.1431,
      "step": 250
    },
    {
      "epoch": 1.8,
      "grad_norm": 27.351787567138672,
      "learning_rate": 4.645714285714286e-05,
      "loss": 0.2526,
      "step": 252
    },
    {
      "epoch": 1.8142857142857143,
      "grad_norm": 14.381145477294922,
      "learning_rate": 4.642857142857143e-05,
      "loss": 0.7863,
      "step": 254
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 23.77890968322754,
      "learning_rate": 4.64e-05,
      "loss": 0.1602,
      "step": 256
    },
    {
      "epoch": 1.842857142857143,
      "grad_norm": 31.786741256713867,
      "learning_rate": 4.637142857142857e-05,
      "loss": 0.216,
      "step": 258
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 7.024880886077881,
      "learning_rate": 4.6342857142857143e-05,
      "loss": 0.0989,
      "step": 260
    },
    {
      "epoch": 1.8714285714285714,
      "grad_norm": 20.056642532348633,
      "learning_rate": 4.631428571428572e-05,
      "loss": 0.0694,
      "step": 262
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 16.985889434814453,
      "learning_rate": 4.628571428571429e-05,
      "loss": 0.2832,
      "step": 264
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.1460812091827393,
      "learning_rate": 4.625714285714286e-05,
      "loss": 0.1261,
      "step": 266
    },
    {
      "epoch": 1.9142857142857141,
      "grad_norm": 13.568049430847168,
      "learning_rate": 4.622857142857143e-05,
      "loss": 0.1167,
      "step": 268
    },
    {
      "epoch": 1.9285714285714286,
      "grad_norm": 4.140488624572754,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.0329,
      "step": 270
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 13.163836479187012,
      "learning_rate": 4.617142857142857e-05,
      "loss": 0.0775,
      "step": 272
    },
    {
      "epoch": 1.9571428571428573,
      "grad_norm": 1.3090146780014038,
      "learning_rate": 4.6142857142857145e-05,
      "loss": 0.1335,
      "step": 274
    },
    {
      "epoch": 1.9714285714285715,
      "grad_norm": 34.0303840637207,
      "learning_rate": 4.611428571428571e-05,
      "loss": 0.2336,
      "step": 276
    },
    {
      "epoch": 1.9857142857142858,
      "grad_norm": 21.038835525512695,
      "learning_rate": 4.6085714285714286e-05,
      "loss": 0.2038,
      "step": 278
    },
    {
      "epoch": 2.0,
      "grad_norm": 32.0712776184082,
      "learning_rate": 4.605714285714286e-05,
      "loss": 0.1721,
      "step": 280
    },
    {
      "epoch": 2.0142857142857142,
      "grad_norm": 1.5733270645141602,
      "learning_rate": 4.602857142857143e-05,
      "loss": 0.012,
      "step": 282
    },
    {
      "epoch": 2.0285714285714285,
      "grad_norm": 7.343649864196777,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0253,
      "step": 284
    },
    {
      "epoch": 2.0428571428571427,
      "grad_norm": 10.040051460266113,
      "learning_rate": 4.5971428571428574e-05,
      "loss": 0.1319,
      "step": 286
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 20.029916763305664,
      "learning_rate": 4.594285714285714e-05,
      "loss": 0.1262,
      "step": 288
    },
    {
      "epoch": 2.0714285714285716,
      "grad_norm": 9.444976806640625,
      "learning_rate": 4.5914285714285714e-05,
      "loss": 0.1789,
      "step": 290
    },
    {
      "epoch": 2.085714285714286,
      "grad_norm": 11.15174674987793,
      "learning_rate": 4.588571428571429e-05,
      "loss": 0.1238,
      "step": 292
    },
    {
      "epoch": 2.1,
      "grad_norm": 23.473934173583984,
      "learning_rate": 4.585714285714286e-05,
      "loss": 0.2598,
      "step": 294
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 19.63722038269043,
      "learning_rate": 4.5828571428571435e-05,
      "loss": 0.1598,
      "step": 296
    },
    {
      "epoch": 2.1285714285714286,
      "grad_norm": 12.138641357421875,
      "learning_rate": 4.58e-05,
      "loss": 0.4184,
      "step": 298
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 11.486034393310547,
      "learning_rate": 4.5771428571428576e-05,
      "loss": 0.2134,
      "step": 300
    },
    {
      "epoch": 2.157142857142857,
      "grad_norm": 21.573631286621094,
      "learning_rate": 4.574285714285714e-05,
      "loss": 0.1686,
      "step": 302
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 3.9485981464385986,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.1868,
      "step": 304
    },
    {
      "epoch": 2.185714285714286,
      "grad_norm": 14.156501770019531,
      "learning_rate": 4.568571428571429e-05,
      "loss": 0.1995,
      "step": 306
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.3679825067520142,
      "learning_rate": 4.5657142857142857e-05,
      "loss": 0.1444,
      "step": 308
    },
    {
      "epoch": 2.2142857142857144,
      "grad_norm": 3.3873441219329834,
      "learning_rate": 4.562857142857143e-05,
      "loss": 0.0824,
      "step": 310
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 12.042951583862305,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.1988,
      "step": 312
    },
    {
      "epoch": 2.242857142857143,
      "grad_norm": 11.886783599853516,
      "learning_rate": 4.557142857142858e-05,
      "loss": 0.036,
      "step": 314
    },
    {
      "epoch": 2.257142857142857,
      "grad_norm": 9.411999702453613,
      "learning_rate": 4.5542857142857144e-05,
      "loss": 0.0252,
      "step": 316
    },
    {
      "epoch": 2.2714285714285714,
      "grad_norm": 10.37145709991455,
      "learning_rate": 4.551428571428572e-05,
      "loss": 0.0234,
      "step": 318
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 33.61591339111328,
      "learning_rate": 4.5485714285714285e-05,
      "loss": 0.0705,
      "step": 320
    },
    {
      "epoch": 2.3,
      "grad_norm": 13.356278419494629,
      "learning_rate": 4.545714285714286e-05,
      "loss": 0.2578,
      "step": 322
    },
    {
      "epoch": 2.314285714285714,
      "grad_norm": 0.4872148633003235,
      "learning_rate": 4.542857142857143e-05,
      "loss": 0.0045,
      "step": 324
    },
    {
      "epoch": 2.3285714285714287,
      "grad_norm": 1.834606409072876,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 0.1295,
      "step": 326
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 19.64618682861328,
      "learning_rate": 4.537142857142857e-05,
      "loss": 0.1998,
      "step": 328
    },
    {
      "epoch": 2.357142857142857,
      "grad_norm": 1.9241862297058105,
      "learning_rate": 4.534285714285714e-05,
      "loss": 0.0079,
      "step": 330
    },
    {
      "epoch": 2.3714285714285714,
      "grad_norm": 21.25523567199707,
      "learning_rate": 4.531428571428571e-05,
      "loss": 0.0654,
      "step": 332
    },
    {
      "epoch": 2.3857142857142857,
      "grad_norm": 26.539451599121094,
      "learning_rate": 4.528571428571429e-05,
      "loss": 0.0474,
      "step": 334
    },
    {
      "epoch": 2.4,
      "grad_norm": 27.296091079711914,
      "learning_rate": 4.525714285714286e-05,
      "loss": 0.1696,
      "step": 336
    },
    {
      "epoch": 2.414285714285714,
      "grad_norm": 9.927788734436035,
      "learning_rate": 4.5228571428571434e-05,
      "loss": 0.012,
      "step": 338
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 6.245620250701904,
      "learning_rate": 4.52e-05,
      "loss": 0.016,
      "step": 340
    },
    {
      "epoch": 2.442857142857143,
      "grad_norm": 1.1340450048446655,
      "learning_rate": 4.5171428571428575e-05,
      "loss": 0.12,
      "step": 342
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 8.732109069824219,
      "learning_rate": 4.514285714285714e-05,
      "loss": 0.0836,
      "step": 344
    },
    {
      "epoch": 2.4714285714285715,
      "grad_norm": 0.055878568440675735,
      "learning_rate": 4.5114285714285715e-05,
      "loss": 0.0016,
      "step": 346
    },
    {
      "epoch": 2.4857142857142858,
      "grad_norm": 1.3586976528167725,
      "learning_rate": 4.508571428571429e-05,
      "loss": 0.0031,
      "step": 348
    },
    {
      "epoch": 2.5,
      "grad_norm": 22.054147720336914,
      "learning_rate": 4.5057142857142856e-05,
      "loss": 0.0562,
      "step": 350
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 2.042476177215576,
      "learning_rate": 4.502857142857143e-05,
      "loss": 0.1026,
      "step": 352
    },
    {
      "epoch": 2.5285714285714285,
      "grad_norm": 13.625128746032715,
      "learning_rate": 4.5e-05,
      "loss": 0.0327,
      "step": 354
    },
    {
      "epoch": 2.5428571428571427,
      "grad_norm": 27.456607818603516,
      "learning_rate": 4.4971428571428576e-05,
      "loss": 0.1048,
      "step": 356
    },
    {
      "epoch": 2.557142857142857,
      "grad_norm": 22.75792121887207,
      "learning_rate": 4.494285714285715e-05,
      "loss": 0.361,
      "step": 358
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 20.748682022094727,
      "learning_rate": 4.491428571428572e-05,
      "loss": 0.0437,
      "step": 360
    },
    {
      "epoch": 2.585714285714286,
      "grad_norm": 23.98358726501465,
      "learning_rate": 4.4885714285714284e-05,
      "loss": 0.3998,
      "step": 362
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.4873284101486206,
      "learning_rate": 4.485714285714286e-05,
      "loss": 0.0044,
      "step": 364
    },
    {
      "epoch": 2.6142857142857143,
      "grad_norm": 22.879470825195312,
      "learning_rate": 4.482857142857143e-05,
      "loss": 0.0933,
      "step": 366
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 0.2872680425643921,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.0135,
      "step": 368
    },
    {
      "epoch": 2.642857142857143,
      "grad_norm": 4.110566139221191,
      "learning_rate": 4.477142857142858e-05,
      "loss": 0.0392,
      "step": 370
    },
    {
      "epoch": 2.657142857142857,
      "grad_norm": 0.13689973950386047,
      "learning_rate": 4.4742857142857145e-05,
      "loss": 0.0017,
      "step": 372
    },
    {
      "epoch": 2.6714285714285713,
      "grad_norm": 1.7472641468048096,
      "learning_rate": 4.471428571428571e-05,
      "loss": 0.0047,
      "step": 374
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 1.145442247390747,
      "learning_rate": 4.4685714285714286e-05,
      "loss": 0.0034,
      "step": 376
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.1792910397052765,
      "learning_rate": 4.465714285714286e-05,
      "loss": 0.0579,
      "step": 378
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 0.3687855303287506,
      "learning_rate": 4.462857142857143e-05,
      "loss": 0.0013,
      "step": 380
    },
    {
      "epoch": 2.7285714285714286,
      "grad_norm": 0.15461698174476624,
      "learning_rate": 4.46e-05,
      "loss": 0.0071,
      "step": 382
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 0.4103158414363861,
      "learning_rate": 4.4571428571428574e-05,
      "loss": 0.0022,
      "step": 384
    },
    {
      "epoch": 2.757142857142857,
      "grad_norm": 0.9277089238166809,
      "learning_rate": 4.454285714285715e-05,
      "loss": 0.0052,
      "step": 386
    },
    {
      "epoch": 2.7714285714285714,
      "grad_norm": 0.6393987536430359,
      "learning_rate": 4.4514285714285714e-05,
      "loss": 0.0122,
      "step": 388
    },
    {
      "epoch": 2.7857142857142856,
      "grad_norm": 27.81960678100586,
      "learning_rate": 4.448571428571429e-05,
      "loss": 0.0997,
      "step": 390
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.1136242151260376,
      "learning_rate": 4.445714285714286e-05,
      "loss": 0.137,
      "step": 392
    },
    {
      "epoch": 2.814285714285714,
      "grad_norm": 0.08894248306751251,
      "learning_rate": 4.442857142857143e-05,
      "loss": 0.0025,
      "step": 394
    },
    {
      "epoch": 2.8285714285714287,
      "grad_norm": 13.553426742553711,
      "learning_rate": 4.44e-05,
      "loss": 0.1669,
      "step": 396
    },
    {
      "epoch": 2.842857142857143,
      "grad_norm": 7.563955783843994,
      "learning_rate": 4.4371428571428575e-05,
      "loss": 0.0299,
      "step": 398
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.04670724645256996,
      "learning_rate": 4.434285714285715e-05,
      "loss": 0.001,
      "step": 400
    },
    {
      "epoch": 2.857142857142857,
      "eval_cer": 0.01867572156196944,
      "eval_loss": 0.04760277643799782,
      "eval_runtime": 14.6067,
      "eval_samples_per_second": 19.101,
      "eval_steps_per_second": 2.396,
      "step": 400
    },
    {
      "epoch": 2.8714285714285714,
      "grad_norm": 25.64577293395996,
      "learning_rate": 4.4314285714285716e-05,
      "loss": 0.1257,
      "step": 402
    },
    {
      "epoch": 2.8857142857142857,
      "grad_norm": 6.466229438781738,
      "learning_rate": 4.428571428571428e-05,
      "loss": 0.2024,
      "step": 404
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.4988503456115723,
      "learning_rate": 4.4257142857142856e-05,
      "loss": 0.0932,
      "step": 406
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 17.503013610839844,
      "learning_rate": 4.422857142857143e-05,
      "loss": 0.1629,
      "step": 408
    },
    {
      "epoch": 2.928571428571429,
      "grad_norm": 29.805500030517578,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 0.2734,
      "step": 410
    },
    {
      "epoch": 2.942857142857143,
      "grad_norm": 0.41893085837364197,
      "learning_rate": 4.417142857142858e-05,
      "loss": 0.0919,
      "step": 412
    },
    {
      "epoch": 2.9571428571428573,
      "grad_norm": 6.666442394256592,
      "learning_rate": 4.4142857142857144e-05,
      "loss": 0.0175,
      "step": 414
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 29.101987838745117,
      "learning_rate": 4.411428571428572e-05,
      "loss": 0.3859,
      "step": 416
    },
    {
      "epoch": 2.9857142857142858,
      "grad_norm": 32.34809875488281,
      "learning_rate": 4.4085714285714285e-05,
      "loss": 0.2773,
      "step": 418
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.241523504257202,
      "learning_rate": 4.405714285714286e-05,
      "loss": 0.0718,
      "step": 420
    },
    {
      "epoch": 3.0142857142857142,
      "grad_norm": 32.90251159667969,
      "learning_rate": 4.402857142857143e-05,
      "loss": 0.2107,
      "step": 422
    },
    {
      "epoch": 3.0285714285714285,
      "grad_norm": 0.10736813396215439,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.4145,
      "step": 424
    },
    {
      "epoch": 3.0428571428571427,
      "grad_norm": 18.759952545166016,
      "learning_rate": 4.397142857142857e-05,
      "loss": 0.2327,
      "step": 426
    },
    {
      "epoch": 3.057142857142857,
      "grad_norm": 6.401581764221191,
      "learning_rate": 4.3942857142857146e-05,
      "loss": 0.0578,
      "step": 428
    },
    {
      "epoch": 3.0714285714285716,
      "grad_norm": 43.2723274230957,
      "learning_rate": 4.391428571428572e-05,
      "loss": 0.4548,
      "step": 430
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 11.978241920471191,
      "learning_rate": 4.388571428571429e-05,
      "loss": 0.1067,
      "step": 432
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.946271538734436,
      "learning_rate": 4.385714285714286e-05,
      "loss": 0.0054,
      "step": 434
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 24.759302139282227,
      "learning_rate": 4.382857142857143e-05,
      "loss": 0.1787,
      "step": 436
    },
    {
      "epoch": 3.1285714285714286,
      "grad_norm": 0.5545907020568848,
      "learning_rate": 4.38e-05,
      "loss": 0.1205,
      "step": 438
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 204.24720764160156,
      "learning_rate": 4.3771428571428574e-05,
      "loss": 0.5219,
      "step": 440
    },
    {
      "epoch": 3.157142857142857,
      "grad_norm": 13.112372398376465,
      "learning_rate": 4.374285714285715e-05,
      "loss": 0.0105,
      "step": 442
    },
    {
      "epoch": 3.1714285714285713,
      "grad_norm": 15.44935417175293,
      "learning_rate": 4.371428571428572e-05,
      "loss": 0.0438,
      "step": 444
    },
    {
      "epoch": 3.185714285714286,
      "grad_norm": 21.10613441467285,
      "learning_rate": 4.368571428571429e-05,
      "loss": 0.1498,
      "step": 446
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.7732933759689331,
      "learning_rate": 4.3657142857142855e-05,
      "loss": 0.02,
      "step": 448
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 0.13563020527362823,
      "learning_rate": 4.3642857142857146e-05,
      "loss": 0.283,
      "step": 450
    },
    {
      "epoch": 3.2285714285714286,
      "grad_norm": 0.7637807130813599,
      "learning_rate": 4.361428571428572e-05,
      "loss": 0.6812,
      "step": 452
    },
    {
      "epoch": 3.242857142857143,
      "grad_norm": 0.1772983968257904,
      "learning_rate": 4.3585714285714286e-05,
      "loss": 0.0013,
      "step": 454
    },
    {
      "epoch": 3.257142857142857,
      "grad_norm": 3.9615447521209717,
      "learning_rate": 4.355714285714286e-05,
      "loss": 0.0095,
      "step": 456
    },
    {
      "epoch": 3.2714285714285714,
      "grad_norm": 16.467395782470703,
      "learning_rate": 4.352857142857143e-05,
      "loss": 0.2036,
      "step": 458
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 0.6283698678016663,
      "learning_rate": 4.35e-05,
      "loss": 0.005,
      "step": 460
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.09825249016284943,
      "learning_rate": 4.3471428571428574e-05,
      "loss": 0.0007,
      "step": 462
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 0.3679102957248688,
      "learning_rate": 4.344285714285715e-05,
      "loss": 0.0019,
      "step": 464
    },
    {
      "epoch": 3.3285714285714287,
      "grad_norm": 62.3745231628418,
      "learning_rate": 4.341428571428572e-05,
      "loss": 0.1815,
      "step": 466
    },
    {
      "epoch": 3.342857142857143,
      "grad_norm": 1.6299413442611694,
      "learning_rate": 4.338571428571429e-05,
      "loss": 0.0045,
      "step": 468
    },
    {
      "epoch": 3.357142857142857,
      "grad_norm": 0.10513796657323837,
      "learning_rate": 4.3357142857142855e-05,
      "loss": 0.0006,
      "step": 470
    },
    {
      "epoch": 3.3714285714285714,
      "grad_norm": 3.7335987091064453,
      "learning_rate": 4.332857142857143e-05,
      "loss": 0.0099,
      "step": 472
    },
    {
      "epoch": 3.3857142857142857,
      "grad_norm": 0.4131203889846802,
      "learning_rate": 4.33e-05,
      "loss": 0.001,
      "step": 474
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.9901806116104126,
      "learning_rate": 4.3271428571428576e-05,
      "loss": 0.0025,
      "step": 476
    },
    {
      "epoch": 3.414285714285714,
      "grad_norm": 34.02711486816406,
      "learning_rate": 4.324285714285715e-05,
      "loss": 0.1491,
      "step": 478
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 23.157989501953125,
      "learning_rate": 4.3214285714285716e-05,
      "loss": 0.1022,
      "step": 480
    },
    {
      "epoch": 3.442857142857143,
      "grad_norm": 1.0692477226257324,
      "learning_rate": 4.318571428571429e-05,
      "loss": 0.0014,
      "step": 482
    },
    {
      "epoch": 3.4571428571428573,
      "grad_norm": 22.644027709960938,
      "learning_rate": 4.315714285714286e-05,
      "loss": 0.1165,
      "step": 484
    },
    {
      "epoch": 3.4714285714285715,
      "grad_norm": 1.4682152271270752,
      "learning_rate": 4.312857142857143e-05,
      "loss": 0.0038,
      "step": 486
    },
    {
      "epoch": 3.4857142857142858,
      "grad_norm": 0.8558335304260254,
      "learning_rate": 4.3100000000000004e-05,
      "loss": 0.0021,
      "step": 488
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.1334044188261032,
      "learning_rate": 4.307142857142857e-05,
      "loss": 0.0024,
      "step": 490
    },
    {
      "epoch": 3.5142857142857142,
      "grad_norm": 0.3143332004547119,
      "learning_rate": 4.3042857142857145e-05,
      "loss": 0.0026,
      "step": 492
    },
    {
      "epoch": 3.5285714285714285,
      "grad_norm": 0.1644727885723114,
      "learning_rate": 4.301428571428572e-05,
      "loss": 0.0015,
      "step": 494
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 29.622156143188477,
      "learning_rate": 4.298571428571429e-05,
      "loss": 0.0315,
      "step": 496
    },
    {
      "epoch": 3.557142857142857,
      "grad_norm": 0.46070584654808044,
      "learning_rate": 4.295714285714286e-05,
      "loss": 0.0084,
      "step": 498
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.3122202455997467,
      "learning_rate": 4.292857142857143e-05,
      "loss": 0.004,
      "step": 500
    },
    {
      "epoch": 3.585714285714286,
      "grad_norm": 25.984586715698242,
      "learning_rate": 4.29e-05,
      "loss": 0.0293,
      "step": 502
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.17391200363636017,
      "learning_rate": 4.287142857142857e-05,
      "loss": 0.0197,
      "step": 504
    },
    {
      "epoch": 3.6142857142857143,
      "grad_norm": 0.31941983103752136,
      "learning_rate": 4.2842857142857146e-05,
      "loss": 0.0009,
      "step": 506
    },
    {
      "epoch": 3.6285714285714286,
      "grad_norm": 25.009620666503906,
      "learning_rate": 4.281428571428572e-05,
      "loss": 0.1237,
      "step": 508
    },
    {
      "epoch": 3.642857142857143,
      "grad_norm": 21.659656524658203,
      "learning_rate": 4.278571428571429e-05,
      "loss": 0.0514,
      "step": 510
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 0.7978951334953308,
      "learning_rate": 4.2757142857142854e-05,
      "loss": 0.0837,
      "step": 512
    },
    {
      "epoch": 3.6714285714285713,
      "grad_norm": 4.274713039398193,
      "learning_rate": 4.272857142857143e-05,
      "loss": 0.0269,
      "step": 514
    },
    {
      "epoch": 3.685714285714286,
      "grad_norm": 0.1826321929693222,
      "learning_rate": 4.27e-05,
      "loss": 0.0217,
      "step": 516
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.06819135695695877,
      "learning_rate": 4.2671428571428575e-05,
      "loss": 0.0016,
      "step": 518
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 0.09641113132238388,
      "learning_rate": 4.264285714285715e-05,
      "loss": 0.0198,
      "step": 520
    },
    {
      "epoch": 3.7285714285714286,
      "grad_norm": 51.7318000793457,
      "learning_rate": 4.2614285714285715e-05,
      "loss": 0.1215,
      "step": 522
    },
    {
      "epoch": 3.742857142857143,
      "grad_norm": 8.182273864746094,
      "learning_rate": 4.258571428571429e-05,
      "loss": 0.3041,
      "step": 524
    },
    {
      "epoch": 3.757142857142857,
      "grad_norm": 16.766376495361328,
      "learning_rate": 4.2557142857142856e-05,
      "loss": 0.3183,
      "step": 526
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 0.18403199315071106,
      "learning_rate": 4.252857142857143e-05,
      "loss": 0.1804,
      "step": 528
    },
    {
      "epoch": 3.7857142857142856,
      "grad_norm": 10.05221939086914,
      "learning_rate": 4.25e-05,
      "loss": 0.0574,
      "step": 530
    },
    {
      "epoch": 3.8,
      "grad_norm": 30.92991828918457,
      "learning_rate": 4.247142857142857e-05,
      "loss": 0.5263,
      "step": 532
    },
    {
      "epoch": 3.814285714285714,
      "grad_norm": 4.02716588973999,
      "learning_rate": 4.2442857142857144e-05,
      "loss": 0.0102,
      "step": 534
    },
    {
      "epoch": 3.8285714285714287,
      "grad_norm": 0.2417699545621872,
      "learning_rate": 4.241428571428572e-05,
      "loss": 0.0013,
      "step": 536
    },
    {
      "epoch": 3.842857142857143,
      "grad_norm": 108.3581771850586,
      "learning_rate": 4.238571428571429e-05,
      "loss": 0.0095,
      "step": 538
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 33.00555419921875,
      "learning_rate": 4.2357142857142864e-05,
      "loss": 0.0175,
      "step": 540
    },
    {
      "epoch": 3.8714285714285714,
      "grad_norm": 8.567420959472656,
      "learning_rate": 4.232857142857143e-05,
      "loss": 0.068,
      "step": 542
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 0.2609610855579376,
      "learning_rate": 4.23e-05,
      "loss": 0.001,
      "step": 544
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.15615594387054443,
      "learning_rate": 4.227142857142857e-05,
      "loss": 0.1063,
      "step": 546
    },
    {
      "epoch": 3.914285714285714,
      "grad_norm": 0.41217291355133057,
      "learning_rate": 4.2242857142857145e-05,
      "loss": 0.002,
      "step": 548
    },
    {
      "epoch": 3.928571428571429,
      "grad_norm": 35.84550476074219,
      "learning_rate": 4.221428571428572e-05,
      "loss": 0.1169,
      "step": 550
    },
    {
      "epoch": 3.942857142857143,
      "grad_norm": 10.318283081054688,
      "learning_rate": 4.218571428571429e-05,
      "loss": 0.3333,
      "step": 552
    },
    {
      "epoch": 3.9571428571428573,
      "grad_norm": 20.27042579650879,
      "learning_rate": 4.215714285714286e-05,
      "loss": 0.1655,
      "step": 554
    },
    {
      "epoch": 3.9714285714285715,
      "grad_norm": 0.3571987748146057,
      "learning_rate": 4.2128571428571426e-05,
      "loss": 0.009,
      "step": 556
    },
    {
      "epoch": 3.9857142857142858,
      "grad_norm": 0.4486158788204193,
      "learning_rate": 4.21e-05,
      "loss": 0.0021,
      "step": 558
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.05051673203706741,
      "learning_rate": 4.2071428571428574e-05,
      "loss": 0.1383,
      "step": 560
    },
    {
      "epoch": 4.014285714285714,
      "grad_norm": 4.56488561630249,
      "learning_rate": 4.204285714285715e-05,
      "loss": 0.1321,
      "step": 562
    },
    {
      "epoch": 4.0285714285714285,
      "grad_norm": 1.3636679649353027,
      "learning_rate": 4.2014285714285714e-05,
      "loss": 0.0044,
      "step": 564
    },
    {
      "epoch": 4.042857142857143,
      "grad_norm": 4.547382354736328,
      "learning_rate": 4.198571428571429e-05,
      "loss": 0.051,
      "step": 566
    },
    {
      "epoch": 4.057142857142857,
      "grad_norm": 12.202816009521484,
      "learning_rate": 4.195714285714286e-05,
      "loss": 0.0298,
      "step": 568
    },
    {
      "epoch": 4.071428571428571,
      "grad_norm": 0.23705433309078217,
      "learning_rate": 4.192857142857143e-05,
      "loss": 0.0149,
      "step": 570
    },
    {
      "epoch": 4.085714285714285,
      "grad_norm": 4.233648777008057,
      "learning_rate": 4.19e-05,
      "loss": 0.006,
      "step": 572
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.04057204723358154,
      "learning_rate": 4.1871428571428576e-05,
      "loss": 0.001,
      "step": 574
    },
    {
      "epoch": 4.114285714285714,
      "grad_norm": 0.4555800259113312,
      "learning_rate": 4.184285714285714e-05,
      "loss": 0.0043,
      "step": 576
    },
    {
      "epoch": 4.128571428571428,
      "grad_norm": 44.371826171875,
      "learning_rate": 4.1814285714285716e-05,
      "loss": 0.0332,
      "step": 578
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 19.291669845581055,
      "learning_rate": 4.178571428571429e-05,
      "loss": 0.3405,
      "step": 580
    },
    {
      "epoch": 4.1571428571428575,
      "grad_norm": 7.655366897583008,
      "learning_rate": 4.1757142857142863e-05,
      "loss": 0.098,
      "step": 582
    },
    {
      "epoch": 4.171428571428572,
      "grad_norm": 4.156126022338867,
      "learning_rate": 4.172857142857143e-05,
      "loss": 0.1531,
      "step": 584
    },
    {
      "epoch": 4.185714285714286,
      "grad_norm": 0.1437937468290329,
      "learning_rate": 4.17e-05,
      "loss": 0.0006,
      "step": 586
    },
    {
      "epoch": 4.2,
      "grad_norm": 8.328316688537598,
      "learning_rate": 4.167142857142857e-05,
      "loss": 0.0311,
      "step": 588
    },
    {
      "epoch": 4.214285714285714,
      "grad_norm": 0.12859271466732025,
      "learning_rate": 4.1642857142857144e-05,
      "loss": 0.0808,
      "step": 590
    },
    {
      "epoch": 4.228571428571429,
      "grad_norm": 24.971284866333008,
      "learning_rate": 4.161428571428572e-05,
      "loss": 0.0564,
      "step": 592
    },
    {
      "epoch": 4.242857142857143,
      "grad_norm": 4.036090850830078,
      "learning_rate": 4.158571428571429e-05,
      "loss": 0.0049,
      "step": 594
    },
    {
      "epoch": 4.257142857142857,
      "grad_norm": 92.8149642944336,
      "learning_rate": 4.155714285714286e-05,
      "loss": 0.2915,
      "step": 596
    },
    {
      "epoch": 4.271428571428571,
      "grad_norm": 22.643159866333008,
      "learning_rate": 4.1528571428571425e-05,
      "loss": 0.2674,
      "step": 598
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 4.028775691986084,
      "learning_rate": 4.15e-05,
      "loss": 0.0084,
      "step": 600
    },
    {
      "epoch": 4.285714285714286,
      "eval_cer": 0.01867572156196944,
      "eval_loss": 0.05103885754942894,
      "eval_runtime": 10.2957,
      "eval_samples_per_second": 27.099,
      "eval_steps_per_second": 3.399,
      "step": 600
    },
    {
      "epoch": 4.3,
      "grad_norm": 39.003414154052734,
      "learning_rate": 4.147142857142857e-05,
      "loss": 0.0564,
      "step": 602
    },
    {
      "epoch": 4.314285714285714,
      "grad_norm": 0.08376647531986237,
      "learning_rate": 4.1442857142857146e-05,
      "loss": 0.0005,
      "step": 604
    },
    {
      "epoch": 4.328571428571428,
      "grad_norm": 20.254844665527344,
      "learning_rate": 4.141428571428571e-05,
      "loss": 0.0353,
      "step": 606
    },
    {
      "epoch": 4.3428571428571425,
      "grad_norm": 0.4930466413497925,
      "learning_rate": 4.138571428571429e-05,
      "loss": 0.001,
      "step": 608
    },
    {
      "epoch": 4.357142857142857,
      "grad_norm": 0.032267116010189056,
      "learning_rate": 4.135714285714286e-05,
      "loss": 0.0015,
      "step": 610
    },
    {
      "epoch": 4.371428571428572,
      "grad_norm": 1.0386730432510376,
      "learning_rate": 4.1328571428571434e-05,
      "loss": 0.0014,
      "step": 612
    },
    {
      "epoch": 4.385714285714286,
      "grad_norm": 0.08382124453783035,
      "learning_rate": 4.13e-05,
      "loss": 0.0039,
      "step": 614
    },
    {
      "epoch": 4.4,
      "grad_norm": NaN,
      "learning_rate": 4.128571428571429e-05,
      "loss": 0.4579,
      "step": 616
    },
    {
      "epoch": 4.414285714285715,
      "grad_norm": 26.263734817504883,
      "learning_rate": 4.125714285714286e-05,
      "loss": 0.5478,
      "step": 618
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 0.45127227902412415,
      "learning_rate": 4.122857142857143e-05,
      "loss": 0.622,
      "step": 620
    },
    {
      "epoch": 4.442857142857143,
      "grad_norm": 0.46588999032974243,
      "learning_rate": 4.12e-05,
      "loss": 0.0525,
      "step": 622
    },
    {
      "epoch": 4.457142857142857,
      "grad_norm": 25.109121322631836,
      "learning_rate": 4.117142857142857e-05,
      "loss": 0.045,
      "step": 624
    },
    {
      "epoch": 4.4714285714285715,
      "grad_norm": 78.0742416381836,
      "learning_rate": 4.1142857142857146e-05,
      "loss": 0.3226,
      "step": 626
    },
    {
      "epoch": 4.485714285714286,
      "grad_norm": 1.4234950542449951,
      "learning_rate": 4.111428571428572e-05,
      "loss": 0.0028,
      "step": 628
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.09343785047531128,
      "learning_rate": 4.1085714285714286e-05,
      "loss": 0.0006,
      "step": 630
    },
    {
      "epoch": 4.514285714285714,
      "grad_norm": 1.620712161064148,
      "learning_rate": 4.105714285714286e-05,
      "loss": 0.003,
      "step": 632
    },
    {
      "epoch": 4.5285714285714285,
      "grad_norm": 0.06787855178117752,
      "learning_rate": 4.1028571428571434e-05,
      "loss": 0.0003,
      "step": 634
    },
    {
      "epoch": 4.542857142857143,
      "grad_norm": 0.06675773859024048,
      "learning_rate": 4.1e-05,
      "loss": 0.0002,
      "step": 636
    },
    {
      "epoch": 4.557142857142857,
      "grad_norm": 0.02808161824941635,
      "learning_rate": 4.0971428571428574e-05,
      "loss": 0.0001,
      "step": 638
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.06443571299314499,
      "learning_rate": 4.094285714285714e-05,
      "loss": 0.0007,
      "step": 640
    },
    {
      "epoch": 4.585714285714285,
      "grad_norm": 0.04992176219820976,
      "learning_rate": 4.0914285714285715e-05,
      "loss": 0.0201,
      "step": 642
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.9224340319633484,
      "learning_rate": 4.088571428571429e-05,
      "loss": 0.0016,
      "step": 644
    },
    {
      "epoch": 4.614285714285714,
      "grad_norm": 0.03811865299940109,
      "learning_rate": 4.085714285714286e-05,
      "loss": 0.0015,
      "step": 646
    },
    {
      "epoch": 4.628571428571428,
      "grad_norm": 0.04719655588269234,
      "learning_rate": 4.0828571428571436e-05,
      "loss": 0.0305,
      "step": 648
    },
    {
      "epoch": 4.642857142857143,
      "grad_norm": 0.27802249789237976,
      "learning_rate": 4.08e-05,
      "loss": 0.0007,
      "step": 650
    },
    {
      "epoch": 4.6571428571428575,
      "grad_norm": 0.5721579194068909,
      "learning_rate": 4.077142857142857e-05,
      "loss": 0.001,
      "step": 652
    },
    {
      "epoch": 4.671428571428572,
      "grad_norm": 2.202759027481079,
      "learning_rate": 4.074285714285714e-05,
      "loss": 0.0026,
      "step": 654
    },
    {
      "epoch": 4.685714285714286,
      "grad_norm": 0.13415375351905823,
      "learning_rate": 4.0714285714285717e-05,
      "loss": 0.001,
      "step": 656
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.5541704893112183,
      "learning_rate": 4.068571428571429e-05,
      "loss": 0.0019,
      "step": 658
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 30.28035545349121,
      "learning_rate": 4.065714285714286e-05,
      "loss": 0.3247,
      "step": 660
    },
    {
      "epoch": 4.728571428571429,
      "grad_norm": 42.599021911621094,
      "learning_rate": 4.062857142857143e-05,
      "loss": 0.0259,
      "step": 662
    },
    {
      "epoch": 4.742857142857143,
      "grad_norm": 26.779630661010742,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 0.0705,
      "step": 664
    },
    {
      "epoch": 4.757142857142857,
      "grad_norm": 0.14007781445980072,
      "learning_rate": 4.057142857142857e-05,
      "loss": 0.0024,
      "step": 666
    },
    {
      "epoch": 4.771428571428571,
      "grad_norm": 12.746180534362793,
      "learning_rate": 4.0542857142857145e-05,
      "loss": 0.0101,
      "step": 668
    },
    {
      "epoch": 4.785714285714286,
      "grad_norm": 47.57746124267578,
      "learning_rate": 4.051428571428572e-05,
      "loss": 0.1118,
      "step": 670
    },
    {
      "epoch": 4.8,
      "grad_norm": 3.575360059738159,
      "learning_rate": 4.0485714285714285e-05,
      "loss": 0.3679,
      "step": 672
    },
    {
      "epoch": 4.814285714285714,
      "grad_norm": 0.2277553379535675,
      "learning_rate": 4.045714285714286e-05,
      "loss": 0.0006,
      "step": 674
    },
    {
      "epoch": 4.828571428571428,
      "grad_norm": 0.1343005746603012,
      "learning_rate": 4.042857142857143e-05,
      "loss": 0.0007,
      "step": 676
    },
    {
      "epoch": 4.8428571428571425,
      "grad_norm": 0.3371204435825348,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 0.001,
      "step": 678
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.247415229678154,
      "learning_rate": 4.037142857142857e-05,
      "loss": 0.257,
      "step": 680
    },
    {
      "epoch": 4.871428571428572,
      "grad_norm": 0.08113312721252441,
      "learning_rate": 4.034285714285715e-05,
      "loss": 0.0003,
      "step": 682
    },
    {
      "epoch": 4.885714285714286,
      "grad_norm": 0.10574020445346832,
      "learning_rate": 4.0314285714285714e-05,
      "loss": 0.0009,
      "step": 684
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.10242249071598053,
      "learning_rate": 4.028571428571429e-05,
      "loss": 0.107,
      "step": 686
    },
    {
      "epoch": 4.914285714285715,
      "grad_norm": 1.4979928731918335,
      "learning_rate": 4.025714285714286e-05,
      "loss": 0.0998,
      "step": 688
    },
    {
      "epoch": 4.928571428571429,
      "grad_norm": 0.08120234310626984,
      "learning_rate": 4.0228571428571434e-05,
      "loss": 0.0006,
      "step": 690
    },
    {
      "epoch": 4.942857142857143,
      "grad_norm": 16.317218780517578,
      "learning_rate": 4.02e-05,
      "loss": 0.1459,
      "step": 692
    },
    {
      "epoch": 4.957142857142857,
      "grad_norm": 13.548107147216797,
      "learning_rate": 4.017142857142857e-05,
      "loss": 0.0113,
      "step": 694
    },
    {
      "epoch": 4.9714285714285715,
      "grad_norm": 0.17475435137748718,
      "learning_rate": 4.014285714285714e-05,
      "loss": 0.0006,
      "step": 696
    },
    {
      "epoch": 4.985714285714286,
      "grad_norm": 3.577054738998413,
      "learning_rate": 4.0114285714285715e-05,
      "loss": 0.0118,
      "step": 698
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.22785991430282593,
      "learning_rate": 4.008571428571429e-05,
      "loss": 0.002,
      "step": 700
    },
    {
      "epoch": 5.014285714285714,
      "grad_norm": 3.7421796321868896,
      "learning_rate": 4.005714285714286e-05,
      "loss": 0.0081,
      "step": 702
    },
    {
      "epoch": 5.0285714285714285,
      "grad_norm": 17.015806198120117,
      "learning_rate": 4.002857142857143e-05,
      "loss": 0.2071,
      "step": 704
    },
    {
      "epoch": 5.042857142857143,
      "grad_norm": 44.3948860168457,
      "learning_rate": 4e-05,
      "loss": 0.133,
      "step": 706
    },
    {
      "epoch": 5.057142857142857,
      "grad_norm": 0.054195042699575424,
      "learning_rate": 3.997142857142857e-05,
      "loss": 0.0028,
      "step": 708
    },
    {
      "epoch": 5.071428571428571,
      "grad_norm": 13.614337921142578,
      "learning_rate": 3.9942857142857144e-05,
      "loss": 0.0417,
      "step": 710
    },
    {
      "epoch": 5.085714285714285,
      "grad_norm": 0.10566509515047073,
      "learning_rate": 3.991428571428572e-05,
      "loss": 0.0008,
      "step": 712
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.08889666199684143,
      "learning_rate": 3.9885714285714284e-05,
      "loss": 0.0003,
      "step": 714
    },
    {
      "epoch": 5.114285714285714,
      "grad_norm": 3.8900277614593506,
      "learning_rate": 3.985714285714286e-05,
      "loss": 0.0053,
      "step": 716
    },
    {
      "epoch": 5.128571428571428,
      "grad_norm": 0.050397928804159164,
      "learning_rate": 3.982857142857143e-05,
      "loss": 0.0001,
      "step": 718
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 1.590399980545044,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.1983,
      "step": 720
    },
    {
      "epoch": 5.1571428571428575,
      "grad_norm": 0.09797351062297821,
      "learning_rate": 3.977142857142857e-05,
      "loss": 0.0004,
      "step": 722
    },
    {
      "epoch": 5.171428571428572,
      "grad_norm": 0.10010989755392075,
      "learning_rate": 3.9742857142857146e-05,
      "loss": 0.0004,
      "step": 724
    },
    {
      "epoch": 5.185714285714286,
      "grad_norm": 0.07996318489313126,
      "learning_rate": 3.971428571428571e-05,
      "loss": 0.0002,
      "step": 726
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.2572563886642456,
      "learning_rate": 3.9685714285714286e-05,
      "loss": 0.0007,
      "step": 728
    },
    {
      "epoch": 5.214285714285714,
      "grad_norm": 0.07260677218437195,
      "learning_rate": 3.965714285714286e-05,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 5.228571428571429,
      "grad_norm": 1.63462233543396,
      "learning_rate": 3.9628571428571433e-05,
      "loss": 0.0028,
      "step": 732
    },
    {
      "epoch": 5.242857142857143,
      "grad_norm": 1.993919014930725,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.0023,
      "step": 734
    },
    {
      "epoch": 5.257142857142857,
      "grad_norm": 0.07631413638591766,
      "learning_rate": 3.9571428571428574e-05,
      "loss": 0.0002,
      "step": 736
    },
    {
      "epoch": 5.271428571428571,
      "grad_norm": 0.09494742006063461,
      "learning_rate": 3.954285714285714e-05,
      "loss": 0.0005,
      "step": 738
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 0.3045521676540375,
      "learning_rate": 3.9514285714285714e-05,
      "loss": 0.0072,
      "step": 740
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.08138268440961838,
      "learning_rate": 3.948571428571429e-05,
      "loss": 0.0003,
      "step": 742
    },
    {
      "epoch": 5.314285714285714,
      "grad_norm": 21.18204689025879,
      "learning_rate": 3.945714285714286e-05,
      "loss": 0.1014,
      "step": 744
    },
    {
      "epoch": 5.328571428571428,
      "grad_norm": 0.06108277291059494,
      "learning_rate": 3.942857142857143e-05,
      "loss": 0.0002,
      "step": 746
    },
    {
      "epoch": 5.3428571428571425,
      "grad_norm": 7.6238627433776855,
      "learning_rate": 3.94e-05,
      "loss": 0.0055,
      "step": 748
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.057331494987010956,
      "learning_rate": 3.9371428571428576e-05,
      "loss": 0.0683,
      "step": 750
    },
    {
      "epoch": 5.371428571428572,
      "grad_norm": 0.11027155071496964,
      "learning_rate": 3.934285714285714e-05,
      "loss": 0.0005,
      "step": 752
    },
    {
      "epoch": 5.385714285714286,
      "grad_norm": 0.06960909813642502,
      "learning_rate": 3.9314285714285716e-05,
      "loss": 0.003,
      "step": 754
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.04595174640417099,
      "learning_rate": 3.928571428571429e-05,
      "loss": 0.0001,
      "step": 756
    },
    {
      "epoch": 5.414285714285715,
      "grad_norm": 0.06051446869969368,
      "learning_rate": 3.925714285714286e-05,
      "loss": 0.0001,
      "step": 758
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 25.024112701416016,
      "learning_rate": 3.922857142857143e-05,
      "loss": 0.1477,
      "step": 760
    },
    {
      "epoch": 5.442857142857143,
      "grad_norm": 0.07992596924304962,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.0012,
      "step": 762
    },
    {
      "epoch": 5.457142857142857,
      "grad_norm": 0.7493134140968323,
      "learning_rate": 3.917142857142858e-05,
      "loss": 0.001,
      "step": 764
    },
    {
      "epoch": 5.4714285714285715,
      "grad_norm": 0.078092060983181,
      "learning_rate": 3.9142857142857145e-05,
      "loss": 0.0004,
      "step": 766
    },
    {
      "epoch": 5.485714285714286,
      "grad_norm": 0.06893064081668854,
      "learning_rate": 3.911428571428571e-05,
      "loss": 0.0007,
      "step": 768
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.06680209189653397,
      "learning_rate": 3.9085714285714285e-05,
      "loss": 0.0004,
      "step": 770
    },
    {
      "epoch": 5.514285714285714,
      "grad_norm": 5.190942287445068,
      "learning_rate": 3.905714285714286e-05,
      "loss": 0.008,
      "step": 772
    },
    {
      "epoch": 5.5285714285714285,
      "grad_norm": 0.04591575637459755,
      "learning_rate": 3.902857142857143e-05,
      "loss": 0.0009,
      "step": 774
    },
    {
      "epoch": 5.542857142857143,
      "grad_norm": 0.09907510131597519,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0012,
      "step": 776
    },
    {
      "epoch": 5.557142857142857,
      "grad_norm": 0.07601487636566162,
      "learning_rate": 3.897142857142857e-05,
      "loss": 0.0013,
      "step": 778
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 2.977379083633423,
      "learning_rate": 3.894285714285714e-05,
      "loss": 0.0135,
      "step": 780
    },
    {
      "epoch": 5.585714285714285,
      "grad_norm": 0.07457936555147171,
      "learning_rate": 3.8914285714285713e-05,
      "loss": 0.0002,
      "step": 782
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.1595892906188965,
      "learning_rate": 3.888571428571429e-05,
      "loss": 0.0023,
      "step": 784
    },
    {
      "epoch": 5.614285714285714,
      "grad_norm": 1.0101134777069092,
      "learning_rate": 3.885714285714286e-05,
      "loss": 0.0699,
      "step": 786
    },
    {
      "epoch": 5.628571428571428,
      "grad_norm": 0.05121474340558052,
      "learning_rate": 3.882857142857143e-05,
      "loss": 0.0034,
      "step": 788
    },
    {
      "epoch": 5.642857142857143,
      "grad_norm": 0.11658650636672974,
      "learning_rate": 3.88e-05,
      "loss": 0.0006,
      "step": 790
    },
    {
      "epoch": 5.6571428571428575,
      "grad_norm": 0.8257467746734619,
      "learning_rate": 3.8771428571428575e-05,
      "loss": 0.0018,
      "step": 792
    },
    {
      "epoch": 5.671428571428572,
      "grad_norm": 14.310221672058105,
      "learning_rate": 3.874285714285715e-05,
      "loss": 0.2815,
      "step": 794
    },
    {
      "epoch": 5.685714285714286,
      "grad_norm": 0.04524417221546173,
      "learning_rate": 3.8714285714285715e-05,
      "loss": 0.0001,
      "step": 796
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.06381632387638092,
      "learning_rate": 3.868571428571429e-05,
      "loss": 0.0001,
      "step": 798
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.12325514853000641,
      "learning_rate": 3.8657142857142856e-05,
      "loss": 0.0008,
      "step": 800
    },
    {
      "epoch": 5.714285714285714,
      "eval_cer": 0.015280135823429542,
      "eval_loss": 0.06144048273563385,
      "eval_runtime": 10.7815,
      "eval_samples_per_second": 25.878,
      "eval_steps_per_second": 3.246,
      "step": 800
    },
    {
      "epoch": 5.728571428571429,
      "grad_norm": 0.16742189228534698,
      "learning_rate": 3.862857142857143e-05,
      "loss": 0.0209,
      "step": 802
    },
    {
      "epoch": 5.742857142857143,
      "grad_norm": 0.5514113306999207,
      "learning_rate": 3.86e-05,
      "loss": 0.0019,
      "step": 804
    },
    {
      "epoch": 5.757142857142857,
      "grad_norm": 0.06832873821258545,
      "learning_rate": 3.857142857142858e-05,
      "loss": 0.0634,
      "step": 806
    },
    {
      "epoch": 5.771428571428571,
      "grad_norm": 3.399186611175537,
      "learning_rate": 3.854285714285715e-05,
      "loss": 0.002,
      "step": 808
    },
    {
      "epoch": 5.785714285714286,
      "grad_norm": 0.06372830271720886,
      "learning_rate": 3.851428571428571e-05,
      "loss": 0.0002,
      "step": 810
    },
    {
      "epoch": 5.8,
      "grad_norm": 12.774886131286621,
      "learning_rate": 3.8485714285714284e-05,
      "loss": 0.0133,
      "step": 812
    },
    {
      "epoch": 5.814285714285714,
      "grad_norm": 0.06636787205934525,
      "learning_rate": 3.845714285714286e-05,
      "loss": 0.0018,
      "step": 814
    },
    {
      "epoch": 5.828571428571428,
      "grad_norm": 31.53740882873535,
      "learning_rate": 3.842857142857143e-05,
      "loss": 0.2449,
      "step": 816
    },
    {
      "epoch": 5.8428571428571425,
      "grad_norm": 0.5371326208114624,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.0027,
      "step": 818
    },
    {
      "epoch": 5.857142857142857,
      "grad_norm": 0.10837522894144058,
      "learning_rate": 3.837142857142857e-05,
      "loss": 0.0003,
      "step": 820
    },
    {
      "epoch": 5.871428571428572,
      "grad_norm": 0.09491876512765884,
      "learning_rate": 3.8342857142857146e-05,
      "loss": 0.0043,
      "step": 822
    },
    {
      "epoch": 5.885714285714286,
      "grad_norm": 0.87836754322052,
      "learning_rate": 3.831428571428571e-05,
      "loss": 0.0138,
      "step": 824
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.17583447694778442,
      "learning_rate": 3.8285714285714286e-05,
      "loss": 0.0017,
      "step": 826
    },
    {
      "epoch": 5.914285714285715,
      "grad_norm": 1.9708364009857178,
      "learning_rate": 3.825714285714286e-05,
      "loss": 0.003,
      "step": 828
    },
    {
      "epoch": 5.928571428571429,
      "grad_norm": 36.71250915527344,
      "learning_rate": 3.822857142857143e-05,
      "loss": 0.0712,
      "step": 830
    },
    {
      "epoch": 5.942857142857143,
      "grad_norm": 0.05175860971212387,
      "learning_rate": 3.82e-05,
      "loss": 0.0005,
      "step": 832
    },
    {
      "epoch": 5.957142857142857,
      "grad_norm": 0.14097537100315094,
      "learning_rate": 3.8171428571428574e-05,
      "loss": 0.0004,
      "step": 834
    },
    {
      "epoch": 5.9714285714285715,
      "grad_norm": 0.07549580931663513,
      "learning_rate": 3.814285714285715e-05,
      "loss": 0.0009,
      "step": 836
    },
    {
      "epoch": 5.985714285714286,
      "grad_norm": 33.91487121582031,
      "learning_rate": 3.8114285714285714e-05,
      "loss": 0.253,
      "step": 838
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.11313468217849731,
      "learning_rate": 3.808571428571429e-05,
      "loss": 0.0004,
      "step": 840
    },
    {
      "epoch": 6.014285714285714,
      "grad_norm": 0.029860343784093857,
      "learning_rate": 3.8057142857142855e-05,
      "loss": 0.0007,
      "step": 842
    },
    {
      "epoch": 6.0285714285714285,
      "grad_norm": 36.362247467041016,
      "learning_rate": 3.802857142857143e-05,
      "loss": 0.0929,
      "step": 844
    },
    {
      "epoch": 6.042857142857143,
      "grad_norm": 0.049376290291547775,
      "learning_rate": 3.8e-05,
      "loss": 0.0001,
      "step": 846
    },
    {
      "epoch": 6.057142857142857,
      "grad_norm": 0.28090164065361023,
      "learning_rate": 3.7971428571428576e-05,
      "loss": 0.0007,
      "step": 848
    },
    {
      "epoch": 6.071428571428571,
      "grad_norm": 0.04415985941886902,
      "learning_rate": 3.794285714285715e-05,
      "loss": 0.0003,
      "step": 850
    },
    {
      "epoch": 6.085714285714285,
      "grad_norm": 0.24533644318580627,
      "learning_rate": 3.7914285714285716e-05,
      "loss": 0.0008,
      "step": 852
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.06421563774347305,
      "learning_rate": 3.788571428571428e-05,
      "loss": 0.0001,
      "step": 854
    },
    {
      "epoch": 6.114285714285714,
      "grad_norm": 19.82817268371582,
      "learning_rate": 3.785714285714286e-05,
      "loss": 0.0486,
      "step": 856
    },
    {
      "epoch": 6.128571428571428,
      "grad_norm": 0.05799112468957901,
      "learning_rate": 3.782857142857143e-05,
      "loss": 0.0003,
      "step": 858
    },
    {
      "epoch": 6.142857142857143,
      "grad_norm": 0.14023065567016602,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.0004,
      "step": 860
    },
    {
      "epoch": 6.1571428571428575,
      "grad_norm": 0.04496701434254646,
      "learning_rate": 3.777142857142858e-05,
      "loss": 0.0001,
      "step": 862
    },
    {
      "epoch": 6.171428571428572,
      "grad_norm": 0.051269516348838806,
      "learning_rate": 3.7742857142857145e-05,
      "loss": 0.0003,
      "step": 864
    },
    {
      "epoch": 6.185714285714286,
      "grad_norm": 0.044087376445531845,
      "learning_rate": 3.771428571428572e-05,
      "loss": 0.0001,
      "step": 866
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.04420952498912811,
      "learning_rate": 3.7685714285714285e-05,
      "loss": 0.0002,
      "step": 868
    },
    {
      "epoch": 6.214285714285714,
      "grad_norm": 0.033671025186777115,
      "learning_rate": 3.765714285714286e-05,
      "loss": 0.0001,
      "step": 870
    },
    {
      "epoch": 6.228571428571429,
      "grad_norm": 0.09992575645446777,
      "learning_rate": 3.762857142857143e-05,
      "loss": 0.0003,
      "step": 872
    },
    {
      "epoch": 6.242857142857143,
      "grad_norm": 0.15683351457118988,
      "learning_rate": 3.76e-05,
      "loss": 0.0008,
      "step": 874
    },
    {
      "epoch": 6.257142857142857,
      "grad_norm": 0.02765878476202488,
      "learning_rate": 3.757142857142857e-05,
      "loss": 0.0002,
      "step": 876
    },
    {
      "epoch": 6.271428571428571,
      "grad_norm": 0.047160547226667404,
      "learning_rate": 3.7542857142857146e-05,
      "loss": 0.0004,
      "step": 878
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 0.03244173526763916,
      "learning_rate": 3.751428571428572e-05,
      "loss": 0.0001,
      "step": 880
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.043984610587358475,
      "learning_rate": 3.748571428571429e-05,
      "loss": 0.0001,
      "step": 882
    },
    {
      "epoch": 6.314285714285714,
      "grad_norm": 0.043849099427461624,
      "learning_rate": 3.745714285714286e-05,
      "loss": 0.0001,
      "step": 884
    },
    {
      "epoch": 6.328571428571428,
      "grad_norm": 4.899003028869629,
      "learning_rate": 3.742857142857143e-05,
      "loss": 0.0022,
      "step": 886
    },
    {
      "epoch": 6.3428571428571425,
      "grad_norm": 0.039417777210474014,
      "learning_rate": 3.74e-05,
      "loss": 0.0007,
      "step": 888
    },
    {
      "epoch": 6.357142857142857,
      "grad_norm": 0.0418848879635334,
      "learning_rate": 3.7371428571428575e-05,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 6.371428571428572,
      "grad_norm": 0.032242100685834885,
      "learning_rate": 3.734285714285715e-05,
      "loss": 0.0001,
      "step": 892
    },
    {
      "epoch": 6.385714285714286,
      "grad_norm": 0.03342825919389725,
      "learning_rate": 3.7314285714285715e-05,
      "loss": 0.0001,
      "step": 894
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.06100026145577431,
      "learning_rate": 3.728571428571428e-05,
      "loss": 0.0002,
      "step": 896
    },
    {
      "epoch": 6.414285714285715,
      "grad_norm": 0.026110680773854256,
      "learning_rate": 3.7257142857142856e-05,
      "loss": 0.0001,
      "step": 898
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.019989894703030586,
      "learning_rate": 3.722857142857143e-05,
      "loss": 0.0001,
      "step": 900
    },
    {
      "epoch": 6.442857142857143,
      "grad_norm": 0.03519915044307709,
      "learning_rate": 3.72e-05,
      "loss": 0.0009,
      "step": 902
    },
    {
      "epoch": 6.457142857142857,
      "grad_norm": 15.609092712402344,
      "learning_rate": 3.717142857142858e-05,
      "loss": 0.2656,
      "step": 904
    },
    {
      "epoch": 6.4714285714285715,
      "grad_norm": 0.12329117953777313,
      "learning_rate": 3.7142857142857143e-05,
      "loss": 0.0009,
      "step": 906
    },
    {
      "epoch": 6.485714285714286,
      "grad_norm": 0.7679964303970337,
      "learning_rate": 3.711428571428572e-05,
      "loss": 0.0013,
      "step": 908
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.0502677746117115,
      "learning_rate": 3.7085714285714284e-05,
      "loss": 0.0002,
      "step": 910
    },
    {
      "epoch": 6.514285714285714,
      "grad_norm": 0.039839137345552444,
      "learning_rate": 3.705714285714286e-05,
      "loss": 0.0001,
      "step": 912
    },
    {
      "epoch": 6.5285714285714285,
      "grad_norm": 0.06356798112392426,
      "learning_rate": 3.702857142857143e-05,
      "loss": 0.0001,
      "step": 914
    },
    {
      "epoch": 6.542857142857143,
      "grad_norm": 0.07159911096096039,
      "learning_rate": 3.7e-05,
      "loss": 0.0013,
      "step": 916
    },
    {
      "epoch": 6.557142857142857,
      "grad_norm": 0.1091327890753746,
      "learning_rate": 3.697142857142857e-05,
      "loss": 0.0002,
      "step": 918
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.16914108395576477,
      "learning_rate": 3.6942857142857145e-05,
      "loss": 0.0075,
      "step": 920
    },
    {
      "epoch": 6.585714285714285,
      "grad_norm": 19.002765655517578,
      "learning_rate": 3.691428571428572e-05,
      "loss": 0.1107,
      "step": 922
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.09557493031024933,
      "learning_rate": 3.688571428571429e-05,
      "loss": 0.0004,
      "step": 924
    },
    {
      "epoch": 6.614285714285714,
      "grad_norm": 0.06014597415924072,
      "learning_rate": 3.685714285714286e-05,
      "loss": 0.0003,
      "step": 926
    },
    {
      "epoch": 6.628571428571428,
      "grad_norm": 0.07801038771867752,
      "learning_rate": 3.6828571428571426e-05,
      "loss": 0.0007,
      "step": 928
    },
    {
      "epoch": 6.642857142857143,
      "grad_norm": 0.04793820530176163,
      "learning_rate": 3.68e-05,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 6.6571428571428575,
      "grad_norm": 0.07455427944660187,
      "learning_rate": 3.6771428571428574e-05,
      "loss": 0.0002,
      "step": 932
    },
    {
      "epoch": 6.671428571428572,
      "grad_norm": 0.0586126446723938,
      "learning_rate": 3.674285714285715e-05,
      "loss": 0.0002,
      "step": 934
    },
    {
      "epoch": 6.685714285714286,
      "grad_norm": 0.10396096110343933,
      "learning_rate": 3.671428571428572e-05,
      "loss": 0.0042,
      "step": 936
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.1514334678649902,
      "learning_rate": 3.668571428571429e-05,
      "loss": 0.002,
      "step": 938
    },
    {
      "epoch": 6.714285714285714,
      "grad_norm": 0.07690250873565674,
      "learning_rate": 3.6657142857142855e-05,
      "loss": 0.0003,
      "step": 940
    },
    {
      "epoch": 6.728571428571429,
      "grad_norm": 25.58333396911621,
      "learning_rate": 3.662857142857143e-05,
      "loss": 0.1706,
      "step": 942
    },
    {
      "epoch": 6.742857142857143,
      "grad_norm": 0.03935646265745163,
      "learning_rate": 3.66e-05,
      "loss": 0.0001,
      "step": 944
    },
    {
      "epoch": 6.757142857142857,
      "grad_norm": 0.04658674821257591,
      "learning_rate": 3.6571428571428576e-05,
      "loss": 0.0001,
      "step": 946
    },
    {
      "epoch": 6.771428571428571,
      "grad_norm": 0.04082205146551132,
      "learning_rate": 3.654285714285714e-05,
      "loss": 0.0001,
      "step": 948
    },
    {
      "epoch": 6.785714285714286,
      "grad_norm": 4.707807540893555,
      "learning_rate": 3.6514285714285716e-05,
      "loss": 0.0024,
      "step": 950
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.04502621665596962,
      "learning_rate": 3.648571428571429e-05,
      "loss": 0.0001,
      "step": 952
    },
    {
      "epoch": 6.814285714285714,
      "grad_norm": 0.027216846123337746,
      "learning_rate": 3.6457142857142857e-05,
      "loss": 0.0001,
      "step": 954
    },
    {
      "epoch": 6.828571428571428,
      "grad_norm": 0.05826731026172638,
      "learning_rate": 3.642857142857143e-05,
      "loss": 0.0001,
      "step": 956
    },
    {
      "epoch": 6.8428571428571425,
      "grad_norm": 27.835609436035156,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 0.1831,
      "step": 958
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 0.030414212495088577,
      "learning_rate": 3.637142857142857e-05,
      "loss": 0.0002,
      "step": 960
    },
    {
      "epoch": 6.871428571428572,
      "grad_norm": 35.02980041503906,
      "learning_rate": 3.6342857142857144e-05,
      "loss": 0.0704,
      "step": 962
    },
    {
      "epoch": 6.885714285714286,
      "grad_norm": 0.09384983777999878,
      "learning_rate": 3.631428571428572e-05,
      "loss": 0.0002,
      "step": 964
    },
    {
      "epoch": 6.9,
      "grad_norm": 8.969179153442383,
      "learning_rate": 3.628571428571429e-05,
      "loss": 0.004,
      "step": 966
    },
    {
      "epoch": 6.914285714285715,
      "grad_norm": 0.38315653800964355,
      "learning_rate": 3.625714285714286e-05,
      "loss": 0.0008,
      "step": 968
    },
    {
      "epoch": 6.928571428571429,
      "grad_norm": 0.0740998387336731,
      "learning_rate": 3.6228571428571425e-05,
      "loss": 0.0002,
      "step": 970
    },
    {
      "epoch": 6.942857142857143,
      "grad_norm": 0.09569471329450607,
      "learning_rate": 3.62e-05,
      "loss": 0.0004,
      "step": 972
    },
    {
      "epoch": 6.957142857142857,
      "grad_norm": 14.711803436279297,
      "learning_rate": 3.617142857142857e-05,
      "loss": 0.0057,
      "step": 974
    },
    {
      "epoch": 6.9714285714285715,
      "grad_norm": 0.04907510057091713,
      "learning_rate": 3.6142857142857146e-05,
      "loss": 0.0002,
      "step": 976
    },
    {
      "epoch": 6.985714285714286,
      "grad_norm": 0.07370804995298386,
      "learning_rate": 3.611428571428572e-05,
      "loss": 0.0009,
      "step": 978
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.1266467124223709,
      "learning_rate": 3.608571428571429e-05,
      "loss": 0.0002,
      "step": 980
    },
    {
      "epoch": 7.014285714285714,
      "grad_norm": 0.05125792324542999,
      "learning_rate": 3.605714285714286e-05,
      "loss": 0.0001,
      "step": 982
    },
    {
      "epoch": 7.0285714285714285,
      "grad_norm": 0.027359738945961,
      "learning_rate": 3.602857142857143e-05,
      "loss": 0.0004,
      "step": 984
    },
    {
      "epoch": 7.042857142857143,
      "grad_norm": 0.06931514292955399,
      "learning_rate": 3.6e-05,
      "loss": 0.0003,
      "step": 986
    },
    {
      "epoch": 7.057142857142857,
      "grad_norm": 36.89813232421875,
      "learning_rate": 3.5971428571428575e-05,
      "loss": 0.0338,
      "step": 988
    },
    {
      "epoch": 7.071428571428571,
      "grad_norm": 0.07682381570339203,
      "learning_rate": 3.594285714285714e-05,
      "loss": 0.0001,
      "step": 990
    },
    {
      "epoch": 7.085714285714285,
      "grad_norm": 0.04528640955686569,
      "learning_rate": 3.5914285714285715e-05,
      "loss": 0.0001,
      "step": 992
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.044897496700286865,
      "learning_rate": 3.588571428571429e-05,
      "loss": 0.0,
      "step": 994
    },
    {
      "epoch": 7.114285714285714,
      "grad_norm": 0.05850148946046829,
      "learning_rate": 3.585714285714286e-05,
      "loss": 0.0002,
      "step": 996
    },
    {
      "epoch": 7.128571428571428,
      "grad_norm": 0.07716406881809235,
      "learning_rate": 3.582857142857143e-05,
      "loss": 0.0002,
      "step": 998
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.1474454253911972,
      "learning_rate": 3.58e-05,
      "loss": 0.0002,
      "step": 1000
    },
    {
      "epoch": 7.142857142857143,
      "eval_cer": 0.0050933786078098476,
      "eval_loss": 0.012115414254367352,
      "eval_runtime": 12.2559,
      "eval_samples_per_second": 22.765,
      "eval_steps_per_second": 2.856,
      "step": 1000
    },
    {
      "epoch": 7.1571428571428575,
      "grad_norm": 0.05990151688456535,
      "learning_rate": 3.577142857142857e-05,
      "loss": 0.0002,
      "step": 1002
    },
    {
      "epoch": 7.171428571428572,
      "grad_norm": 0.058810338377952576,
      "learning_rate": 3.574285714285714e-05,
      "loss": 0.0001,
      "step": 1004
    },
    {
      "epoch": 7.185714285714286,
      "grad_norm": 36.53069305419922,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.0314,
      "step": 1006
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.05394066497683525,
      "learning_rate": 3.568571428571429e-05,
      "loss": 0.0001,
      "step": 1008
    },
    {
      "epoch": 7.214285714285714,
      "grad_norm": 0.21318228542804718,
      "learning_rate": 3.5657142857142864e-05,
      "loss": 0.0003,
      "step": 1010
    },
    {
      "epoch": 7.228571428571429,
      "grad_norm": 0.061559367924928665,
      "learning_rate": 3.562857142857143e-05,
      "loss": 0.0892,
      "step": 1012
    },
    {
      "epoch": 7.242857142857143,
      "grad_norm": 0.05616975575685501,
      "learning_rate": 3.56e-05,
      "loss": 0.0001,
      "step": 1014
    },
    {
      "epoch": 7.257142857142857,
      "grad_norm": 0.09113556146621704,
      "learning_rate": 3.557142857142857e-05,
      "loss": 0.0002,
      "step": 1016
    },
    {
      "epoch": 7.271428571428571,
      "grad_norm": 0.12541155517101288,
      "learning_rate": 3.5542857142857145e-05,
      "loss": 0.0003,
      "step": 1018
    },
    {
      "epoch": 7.285714285714286,
      "grad_norm": 0.05279026925563812,
      "learning_rate": 3.551428571428572e-05,
      "loss": 0.0001,
      "step": 1020
    },
    {
      "epoch": 7.3,
      "grad_norm": 5.035836219787598,
      "learning_rate": 3.5485714285714286e-05,
      "loss": 0.0025,
      "step": 1022
    },
    {
      "epoch": 7.314285714285714,
      "grad_norm": 0.04629000648856163,
      "learning_rate": 3.545714285714286e-05,
      "loss": 0.0072,
      "step": 1024
    },
    {
      "epoch": 7.328571428571428,
      "grad_norm": 0.045671939849853516,
      "learning_rate": 3.5428571428571426e-05,
      "loss": 0.0001,
      "step": 1026
    },
    {
      "epoch": 7.3428571428571425,
      "grad_norm": 1.0222394466400146,
      "learning_rate": 3.54e-05,
      "loss": 0.0006,
      "step": 1028
    },
    {
      "epoch": 7.357142857142857,
      "grad_norm": 0.029621440917253494,
      "learning_rate": 3.5371428571428574e-05,
      "loss": 0.0001,
      "step": 1030
    },
    {
      "epoch": 7.371428571428572,
      "grad_norm": 0.04940575361251831,
      "learning_rate": 3.534285714285715e-05,
      "loss": 0.0004,
      "step": 1032
    },
    {
      "epoch": 7.385714285714286,
      "grad_norm": 0.105977863073349,
      "learning_rate": 3.5314285714285714e-05,
      "loss": 0.0004,
      "step": 1034
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.19155539572238922,
      "learning_rate": 3.528571428571429e-05,
      "loss": 0.0004,
      "step": 1036
    },
    {
      "epoch": 7.414285714285715,
      "grad_norm": 0.1081901490688324,
      "learning_rate": 3.525714285714286e-05,
      "loss": 0.0003,
      "step": 1038
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 0.04092530161142349,
      "learning_rate": 3.5228571428571435e-05,
      "loss": 0.0001,
      "step": 1040
    },
    {
      "epoch": 7.442857142857143,
      "grad_norm": 0.05883156135678291,
      "learning_rate": 3.52e-05,
      "loss": 0.08,
      "step": 1042
    },
    {
      "epoch": 7.457142857142857,
      "grad_norm": 0.03323841840028763,
      "learning_rate": 3.517142857142857e-05,
      "loss": 0.0001,
      "step": 1044
    },
    {
      "epoch": 7.4714285714285715,
      "grad_norm": 8.710021018981934,
      "learning_rate": 3.514285714285714e-05,
      "loss": 0.0025,
      "step": 1046
    },
    {
      "epoch": 7.485714285714286,
      "grad_norm": 0.15992742776870728,
      "learning_rate": 3.5114285714285716e-05,
      "loss": 0.0004,
      "step": 1048
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.05254675820469856,
      "learning_rate": 3.508571428571429e-05,
      "loss": 0.0001,
      "step": 1050
    },
    {
      "epoch": 7.514285714285714,
      "grad_norm": 43.50452423095703,
      "learning_rate": 3.505714285714286e-05,
      "loss": 0.0539,
      "step": 1052
    },
    {
      "epoch": 7.5285714285714285,
      "grad_norm": 1.914374589920044,
      "learning_rate": 3.502857142857143e-05,
      "loss": 0.0023,
      "step": 1054
    },
    {
      "epoch": 7.542857142857143,
      "grad_norm": 1.7397830486297607,
      "learning_rate": 3.5e-05,
      "loss": 0.0012,
      "step": 1056
    },
    {
      "epoch": 7.557142857142857,
      "grad_norm": 20.540142059326172,
      "learning_rate": 3.497142857142857e-05,
      "loss": 0.2133,
      "step": 1058
    },
    {
      "epoch": 7.571428571428571,
      "grad_norm": 0.06615347415208817,
      "learning_rate": 3.4942857142857144e-05,
      "loss": 0.0002,
      "step": 1060
    },
    {
      "epoch": 7.585714285714285,
      "grad_norm": 0.058172792196273804,
      "learning_rate": 3.491428571428572e-05,
      "loss": 0.0002,
      "step": 1062
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.04732032120227814,
      "learning_rate": 3.488571428571429e-05,
      "loss": 0.0001,
      "step": 1064
    },
    {
      "epoch": 7.614285714285714,
      "grad_norm": 0.06322847306728363,
      "learning_rate": 3.485714285714286e-05,
      "loss": 0.0001,
      "step": 1066
    },
    {
      "epoch": 7.628571428571428,
      "grad_norm": 0.15633709728717804,
      "learning_rate": 3.482857142857143e-05,
      "loss": 0.0042,
      "step": 1068
    },
    {
      "epoch": 7.642857142857143,
      "grad_norm": 0.9823592901229858,
      "learning_rate": 3.48e-05,
      "loss": 0.0013,
      "step": 1070
    },
    {
      "epoch": 7.6571428571428575,
      "grad_norm": 0.04611131176352501,
      "learning_rate": 3.477142857142857e-05,
      "loss": 0.0002,
      "step": 1072
    },
    {
      "epoch": 7.671428571428572,
      "grad_norm": 0.07365334779024124,
      "learning_rate": 3.4742857142857146e-05,
      "loss": 0.0163,
      "step": 1074
    },
    {
      "epoch": 7.685714285714286,
      "grad_norm": 0.056744690984487534,
      "learning_rate": 3.471428571428571e-05,
      "loss": 0.0001,
      "step": 1076
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.05700303241610527,
      "learning_rate": 3.468571428571429e-05,
      "loss": 0.0001,
      "step": 1078
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 0.18334655463695526,
      "learning_rate": 3.465714285714286e-05,
      "loss": 0.0497,
      "step": 1080
    },
    {
      "epoch": 7.728571428571429,
      "grad_norm": 0.04535188898444176,
      "learning_rate": 3.4628571428571434e-05,
      "loss": 0.0011,
      "step": 1082
    },
    {
      "epoch": 7.742857142857143,
      "grad_norm": 0.4421234130859375,
      "learning_rate": 3.46e-05,
      "loss": 0.0029,
      "step": 1084
    },
    {
      "epoch": 7.757142857142857,
      "grad_norm": 0.04446927085518837,
      "learning_rate": 3.4571428571428574e-05,
      "loss": 0.0,
      "step": 1086
    },
    {
      "epoch": 7.771428571428571,
      "grad_norm": 0.04859609156847,
      "learning_rate": 3.454285714285714e-05,
      "loss": 0.0001,
      "step": 1088
    },
    {
      "epoch": 7.785714285714286,
      "grad_norm": 0.06312122941017151,
      "learning_rate": 3.4514285714285715e-05,
      "loss": 0.0001,
      "step": 1090
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.02168351039290428,
      "learning_rate": 3.448571428571429e-05,
      "loss": 0.0016,
      "step": 1092
    },
    {
      "epoch": 7.814285714285714,
      "grad_norm": 0.07679940015077591,
      "learning_rate": 3.445714285714286e-05,
      "loss": 0.0001,
      "step": 1094
    },
    {
      "epoch": 7.828571428571428,
      "grad_norm": 0.08313708752393723,
      "learning_rate": 3.442857142857143e-05,
      "loss": 0.0001,
      "step": 1096
    },
    {
      "epoch": 7.8428571428571425,
      "grad_norm": 0.10115721821784973,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 0.0003,
      "step": 1098
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 0.07564497739076614,
      "learning_rate": 3.437142857142857e-05,
      "loss": 0.0008,
      "step": 1100
    },
    {
      "epoch": 7.871428571428572,
      "grad_norm": 17.11028289794922,
      "learning_rate": 3.434285714285714e-05,
      "loss": 0.0222,
      "step": 1102
    },
    {
      "epoch": 7.885714285714286,
      "grad_norm": 0.045864131301641464,
      "learning_rate": 3.431428571428572e-05,
      "loss": 0.0001,
      "step": 1104
    },
    {
      "epoch": 7.9,
      "grad_norm": 5.597611904144287,
      "learning_rate": 3.428571428571429e-05,
      "loss": 0.0066,
      "step": 1106
    },
    {
      "epoch": 7.914285714285715,
      "grad_norm": 0.05373188108205795,
      "learning_rate": 3.425714285714286e-05,
      "loss": 0.0009,
      "step": 1108
    },
    {
      "epoch": 7.928571428571429,
      "grad_norm": 0.06899713724851608,
      "learning_rate": 3.422857142857143e-05,
      "loss": 0.0001,
      "step": 1110
    },
    {
      "epoch": 7.942857142857143,
      "grad_norm": 0.281139612197876,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 0.0006,
      "step": 1112
    },
    {
      "epoch": 7.957142857142857,
      "grad_norm": 0.0540834441781044,
      "learning_rate": 3.417142857142857e-05,
      "loss": 0.0006,
      "step": 1114
    },
    {
      "epoch": 7.9714285714285715,
      "grad_norm": 95.79432678222656,
      "learning_rate": 3.4142857142857145e-05,
      "loss": 0.0844,
      "step": 1116
    },
    {
      "epoch": 7.985714285714286,
      "grad_norm": 0.10267109423875809,
      "learning_rate": 3.411428571428571e-05,
      "loss": 0.0009,
      "step": 1118
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.06947725266218185,
      "learning_rate": 3.4085714285714286e-05,
      "loss": 0.0002,
      "step": 1120
    },
    {
      "epoch": 8.014285714285714,
      "grad_norm": 0.07770948112010956,
      "learning_rate": 3.405714285714286e-05,
      "loss": 0.0103,
      "step": 1122
    },
    {
      "epoch": 8.028571428571428,
      "grad_norm": 0.04807409644126892,
      "learning_rate": 3.402857142857143e-05,
      "loss": 0.0024,
      "step": 1124
    },
    {
      "epoch": 8.042857142857143,
      "grad_norm": 0.11988671123981476,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0003,
      "step": 1126
    },
    {
      "epoch": 8.057142857142857,
      "grad_norm": 0.041545506566762924,
      "learning_rate": 3.397142857142857e-05,
      "loss": 0.0721,
      "step": 1128
    },
    {
      "epoch": 8.071428571428571,
      "grad_norm": 0.07874222844839096,
      "learning_rate": 3.394285714285714e-05,
      "loss": 0.0001,
      "step": 1130
    },
    {
      "epoch": 8.085714285714285,
      "grad_norm": 0.05208037793636322,
      "learning_rate": 3.3914285714285714e-05,
      "loss": 0.0001,
      "step": 1132
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.0627310648560524,
      "learning_rate": 3.388571428571429e-05,
      "loss": 0.0001,
      "step": 1134
    },
    {
      "epoch": 8.114285714285714,
      "grad_norm": 2.832474946975708,
      "learning_rate": 3.385714285714286e-05,
      "loss": 0.0022,
      "step": 1136
    },
    {
      "epoch": 8.128571428571428,
      "grad_norm": 0.06582816690206528,
      "learning_rate": 3.3828571428571435e-05,
      "loss": 0.0001,
      "step": 1138
    },
    {
      "epoch": 8.142857142857142,
      "grad_norm": 0.04797777161002159,
      "learning_rate": 3.38e-05,
      "loss": 0.0009,
      "step": 1140
    },
    {
      "epoch": 8.157142857142857,
      "grad_norm": 0.041445422917604446,
      "learning_rate": 3.377142857142857e-05,
      "loss": 0.0042,
      "step": 1142
    },
    {
      "epoch": 8.17142857142857,
      "grad_norm": 0.045235421508550644,
      "learning_rate": 3.374285714285714e-05,
      "loss": 0.0003,
      "step": 1144
    },
    {
      "epoch": 8.185714285714285,
      "grad_norm": 0.07158178091049194,
      "learning_rate": 3.3714285714285716e-05,
      "loss": 0.0002,
      "step": 1146
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.07247362285852432,
      "learning_rate": 3.368571428571429e-05,
      "loss": 0.0007,
      "step": 1148
    },
    {
      "epoch": 8.214285714285714,
      "grad_norm": 0.0404331348836422,
      "learning_rate": 3.3657142857142856e-05,
      "loss": 0.0001,
      "step": 1150
    },
    {
      "epoch": 8.228571428571428,
      "grad_norm": 0.06992360949516296,
      "learning_rate": 3.362857142857143e-05,
      "loss": 0.0002,
      "step": 1152
    },
    {
      "epoch": 8.242857142857142,
      "grad_norm": 0.05704529583454132,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.0001,
      "step": 1154
    },
    {
      "epoch": 8.257142857142856,
      "grad_norm": 0.04337626323103905,
      "learning_rate": 3.357142857142857e-05,
      "loss": 0.0001,
      "step": 1156
    },
    {
      "epoch": 8.271428571428572,
      "grad_norm": 4.553080081939697,
      "learning_rate": 3.3542857142857144e-05,
      "loss": 0.0041,
      "step": 1158
    },
    {
      "epoch": 8.285714285714286,
      "grad_norm": 0.024007132276892662,
      "learning_rate": 3.351428571428572e-05,
      "loss": 0.0001,
      "step": 1160
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.042420756071805954,
      "learning_rate": 3.3485714285714285e-05,
      "loss": 0.0001,
      "step": 1162
    },
    {
      "epoch": 8.314285714285715,
      "grad_norm": 0.13455459475517273,
      "learning_rate": 3.345714285714286e-05,
      "loss": 0.0002,
      "step": 1164
    },
    {
      "epoch": 8.32857142857143,
      "grad_norm": 2.2095282077789307,
      "learning_rate": 3.342857142857143e-05,
      "loss": 0.0055,
      "step": 1166
    },
    {
      "epoch": 8.342857142857143,
      "grad_norm": 0.026831129565835,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 0.0001,
      "step": 1168
    },
    {
      "epoch": 8.357142857142858,
      "grad_norm": 0.03340335562825203,
      "learning_rate": 3.337142857142857e-05,
      "loss": 0.0001,
      "step": 1170
    },
    {
      "epoch": 8.371428571428572,
      "grad_norm": 0.020952021703124046,
      "learning_rate": 3.334285714285714e-05,
      "loss": 0.0001,
      "step": 1172
    },
    {
      "epoch": 8.385714285714286,
      "grad_norm": 0.056910160928964615,
      "learning_rate": 3.331428571428571e-05,
      "loss": 0.0001,
      "step": 1174
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.8078587055206299,
      "learning_rate": 3.3285714285714286e-05,
      "loss": 0.0009,
      "step": 1176
    },
    {
      "epoch": 8.414285714285715,
      "grad_norm": 0.055549267679452896,
      "learning_rate": 3.325714285714286e-05,
      "loss": 0.0001,
      "step": 1178
    },
    {
      "epoch": 8.428571428571429,
      "grad_norm": 0.08401057124137878,
      "learning_rate": 3.3228571428571434e-05,
      "loss": 0.0067,
      "step": 1180
    },
    {
      "epoch": 8.442857142857143,
      "grad_norm": 0.065955251455307,
      "learning_rate": 3.32e-05,
      "loss": 0.001,
      "step": 1182
    },
    {
      "epoch": 8.457142857142857,
      "grad_norm": 0.030337192118167877,
      "learning_rate": 3.3171428571428574e-05,
      "loss": 0.0018,
      "step": 1184
    },
    {
      "epoch": 8.471428571428572,
      "grad_norm": 0.03950343281030655,
      "learning_rate": 3.314285714285714e-05,
      "loss": 0.0002,
      "step": 1186
    },
    {
      "epoch": 8.485714285714286,
      "grad_norm": 41.26006317138672,
      "learning_rate": 3.3114285714285715e-05,
      "loss": 0.1148,
      "step": 1188
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.026046425104141235,
      "learning_rate": 3.308571428571429e-05,
      "loss": 0.0001,
      "step": 1190
    },
    {
      "epoch": 8.514285714285714,
      "grad_norm": 0.04422922432422638,
      "learning_rate": 3.305714285714286e-05,
      "loss": 0.0001,
      "step": 1192
    },
    {
      "epoch": 8.528571428571428,
      "grad_norm": 0.07179602980613708,
      "learning_rate": 3.302857142857143e-05,
      "loss": 0.0002,
      "step": 1194
    },
    {
      "epoch": 8.542857142857143,
      "grad_norm": 0.07579731196165085,
      "learning_rate": 3.3e-05,
      "loss": 0.0042,
      "step": 1196
    },
    {
      "epoch": 8.557142857142857,
      "grad_norm": 0.06649702787399292,
      "learning_rate": 3.2971428571428576e-05,
      "loss": 0.0002,
      "step": 1198
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.08804484456777573,
      "learning_rate": 3.294285714285714e-05,
      "loss": 0.0002,
      "step": 1200
    },
    {
      "epoch": 8.571428571428571,
      "eval_cer": 0.006791171477079796,
      "eval_loss": 0.034024279564619064,
      "eval_runtime": 11.3302,
      "eval_samples_per_second": 24.625,
      "eval_steps_per_second": 3.089,
      "step": 1200
    },
    {
      "epoch": 8.585714285714285,
      "grad_norm": 0.03886549547314644,
      "learning_rate": 3.291428571428572e-05,
      "loss": 0.0001,
      "step": 1202
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.4651192426681519,
      "learning_rate": 3.2885714285714284e-05,
      "loss": 0.0011,
      "step": 1204
    },
    {
      "epoch": 8.614285714285714,
      "grad_norm": 0.051266860216856,
      "learning_rate": 3.285714285714286e-05,
      "loss": 0.0001,
      "step": 1206
    },
    {
      "epoch": 8.628571428571428,
      "grad_norm": 0.04641621187329292,
      "learning_rate": 3.282857142857143e-05,
      "loss": 0.0005,
      "step": 1208
    },
    {
      "epoch": 8.642857142857142,
      "grad_norm": 0.7820459604263306,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 0.0009,
      "step": 1210
    },
    {
      "epoch": 8.657142857142857,
      "grad_norm": 0.06808853894472122,
      "learning_rate": 3.277142857142858e-05,
      "loss": 0.0001,
      "step": 1212
    },
    {
      "epoch": 8.67142857142857,
      "grad_norm": 0.042263828217983246,
      "learning_rate": 3.2742857142857145e-05,
      "loss": 0.0001,
      "step": 1214
    },
    {
      "epoch": 8.685714285714285,
      "grad_norm": 0.04399983584880829,
      "learning_rate": 3.271428571428571e-05,
      "loss": 0.0001,
      "step": 1216
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.05025865137577057,
      "learning_rate": 3.2685714285714285e-05,
      "loss": 0.0002,
      "step": 1218
    },
    {
      "epoch": 8.714285714285714,
      "grad_norm": 0.05261866748332977,
      "learning_rate": 3.265714285714286e-05,
      "loss": 0.0615,
      "step": 1220
    },
    {
      "epoch": 8.728571428571428,
      "grad_norm": 0.047204505652189255,
      "learning_rate": 3.262857142857143e-05,
      "loss": 0.0613,
      "step": 1222
    },
    {
      "epoch": 8.742857142857144,
      "grad_norm": 0.05799682065844536,
      "learning_rate": 3.26e-05,
      "loss": 0.0001,
      "step": 1224
    },
    {
      "epoch": 8.757142857142856,
      "grad_norm": 30.28124237060547,
      "learning_rate": 3.257142857142857e-05,
      "loss": 0.134,
      "step": 1226
    },
    {
      "epoch": 8.771428571428572,
      "grad_norm": 0.038577962666749954,
      "learning_rate": 3.254285714285715e-05,
      "loss": 0.0001,
      "step": 1228
    },
    {
      "epoch": 8.785714285714286,
      "grad_norm": 0.09257201105356216,
      "learning_rate": 3.2514285714285714e-05,
      "loss": 0.0006,
      "step": 1230
    },
    {
      "epoch": 8.8,
      "grad_norm": 5.012985706329346,
      "learning_rate": 3.248571428571429e-05,
      "loss": 0.0032,
      "step": 1232
    },
    {
      "epoch": 8.814285714285715,
      "grad_norm": 0.03822707757353783,
      "learning_rate": 3.245714285714286e-05,
      "loss": 0.0001,
      "step": 1234
    },
    {
      "epoch": 8.82857142857143,
      "grad_norm": 0.06878392398357391,
      "learning_rate": 3.242857142857143e-05,
      "loss": 0.2245,
      "step": 1236
    },
    {
      "epoch": 8.842857142857143,
      "grad_norm": 0.045247141271829605,
      "learning_rate": 3.24e-05,
      "loss": 0.0001,
      "step": 1238
    },
    {
      "epoch": 8.857142857142858,
      "grad_norm": 0.08572880178689957,
      "learning_rate": 3.2371428571428575e-05,
      "loss": 0.0008,
      "step": 1240
    },
    {
      "epoch": 8.871428571428572,
      "grad_norm": 0.06188768148422241,
      "learning_rate": 3.234285714285715e-05,
      "loss": 0.0001,
      "step": 1242
    },
    {
      "epoch": 8.885714285714286,
      "grad_norm": 0.03835248947143555,
      "learning_rate": 3.2314285714285716e-05,
      "loss": 0.0002,
      "step": 1244
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.06446406245231628,
      "learning_rate": 3.228571428571428e-05,
      "loss": 0.0002,
      "step": 1246
    },
    {
      "epoch": 8.914285714285715,
      "grad_norm": 0.05138733983039856,
      "learning_rate": 3.2257142857142856e-05,
      "loss": 0.0001,
      "step": 1248
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.05424552410840988,
      "learning_rate": 3.222857142857143e-05,
      "loss": 0.0002,
      "step": 1250
    },
    {
      "epoch": 8.942857142857143,
      "grad_norm": 0.3355996906757355,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 0.0008,
      "step": 1252
    },
    {
      "epoch": 8.957142857142857,
      "grad_norm": 0.07017850875854492,
      "learning_rate": 3.217142857142858e-05,
      "loss": 0.0001,
      "step": 1254
    },
    {
      "epoch": 8.971428571428572,
      "grad_norm": 0.03513317555189133,
      "learning_rate": 3.2142857142857144e-05,
      "loss": 0.0001,
      "step": 1256
    },
    {
      "epoch": 8.985714285714286,
      "grad_norm": 0.032082296907901764,
      "learning_rate": 3.211428571428571e-05,
      "loss": 0.0001,
      "step": 1258
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.028759842738509178,
      "learning_rate": 3.2085714285714284e-05,
      "loss": 0.0001,
      "step": 1260
    },
    {
      "epoch": 9.014285714285714,
      "grad_norm": 0.3605794310569763,
      "learning_rate": 3.205714285714286e-05,
      "loss": 0.0007,
      "step": 1262
    },
    {
      "epoch": 9.028571428571428,
      "grad_norm": 0.057065777480602264,
      "learning_rate": 3.202857142857143e-05,
      "loss": 0.0001,
      "step": 1264
    },
    {
      "epoch": 9.042857142857143,
      "grad_norm": 0.07715116441249847,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0001,
      "step": 1266
    },
    {
      "epoch": 9.057142857142857,
      "grad_norm": 37.77495574951172,
      "learning_rate": 3.197142857142857e-05,
      "loss": 0.1424,
      "step": 1268
    },
    {
      "epoch": 9.071428571428571,
      "grad_norm": 1.4453866481781006,
      "learning_rate": 3.1942857142857146e-05,
      "loss": 0.0014,
      "step": 1270
    },
    {
      "epoch": 9.085714285714285,
      "grad_norm": 0.026240257546305656,
      "learning_rate": 3.191428571428571e-05,
      "loss": 0.0,
      "step": 1272
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.253002405166626,
      "learning_rate": 3.1885714285714286e-05,
      "loss": 0.0082,
      "step": 1274
    },
    {
      "epoch": 9.114285714285714,
      "grad_norm": 0.0547046922147274,
      "learning_rate": 3.185714285714286e-05,
      "loss": 0.0001,
      "step": 1276
    },
    {
      "epoch": 9.128571428571428,
      "grad_norm": 0.03403911739587784,
      "learning_rate": 3.182857142857143e-05,
      "loss": 0.0006,
      "step": 1278
    },
    {
      "epoch": 9.142857142857142,
      "grad_norm": 0.06560014933347702,
      "learning_rate": 3.18e-05,
      "loss": 0.0006,
      "step": 1280
    },
    {
      "epoch": 9.157142857142857,
      "grad_norm": 0.05060117319226265,
      "learning_rate": 3.1771428571428574e-05,
      "loss": 0.0001,
      "step": 1282
    },
    {
      "epoch": 9.17142857142857,
      "grad_norm": 0.0481923446059227,
      "learning_rate": 3.174285714285715e-05,
      "loss": 0.0001,
      "step": 1284
    },
    {
      "epoch": 9.185714285714285,
      "grad_norm": 0.04344809055328369,
      "learning_rate": 3.1714285714285715e-05,
      "loss": 0.0001,
      "step": 1286
    },
    {
      "epoch": 9.2,
      "grad_norm": 19.922388076782227,
      "learning_rate": 3.168571428571429e-05,
      "loss": 0.0279,
      "step": 1288
    },
    {
      "epoch": 9.214285714285714,
      "grad_norm": 0.06914182007312775,
      "learning_rate": 3.1657142857142855e-05,
      "loss": 0.0002,
      "step": 1290
    },
    {
      "epoch": 9.228571428571428,
      "grad_norm": 0.030357927083969116,
      "learning_rate": 3.162857142857143e-05,
      "loss": 0.0738,
      "step": 1292
    },
    {
      "epoch": 9.242857142857142,
      "grad_norm": 1.4185289144515991,
      "learning_rate": 3.16e-05,
      "loss": 0.001,
      "step": 1294
    },
    {
      "epoch": 9.257142857142856,
      "grad_norm": 0.02656399831175804,
      "learning_rate": 3.1571428571428576e-05,
      "loss": 0.0,
      "step": 1296
    },
    {
      "epoch": 9.271428571428572,
      "grad_norm": 0.06187602877616882,
      "learning_rate": 3.154285714285714e-05,
      "loss": 0.0001,
      "step": 1298
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 0.06048006936907768,
      "learning_rate": 3.1514285714285717e-05,
      "loss": 0.0001,
      "step": 1300
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.10680009424686432,
      "learning_rate": 3.148571428571428e-05,
      "loss": 0.0003,
      "step": 1302
    },
    {
      "epoch": 9.314285714285715,
      "grad_norm": 0.04741814360022545,
      "learning_rate": 3.145714285714286e-05,
      "loss": 0.0008,
      "step": 1304
    },
    {
      "epoch": 9.32857142857143,
      "grad_norm": 0.046499695628881454,
      "learning_rate": 3.142857142857143e-05,
      "loss": 0.0005,
      "step": 1306
    },
    {
      "epoch": 9.342857142857143,
      "grad_norm": 0.037382908165454865,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 0.0001,
      "step": 1308
    },
    {
      "epoch": 9.357142857142858,
      "grad_norm": 0.06633800268173218,
      "learning_rate": 3.137142857142857e-05,
      "loss": 0.0003,
      "step": 1310
    },
    {
      "epoch": 9.371428571428572,
      "grad_norm": 39.685298919677734,
      "learning_rate": 3.1342857142857145e-05,
      "loss": 0.0784,
      "step": 1312
    },
    {
      "epoch": 9.385714285714286,
      "grad_norm": 0.07255420088768005,
      "learning_rate": 3.131428571428572e-05,
      "loss": 0.0014,
      "step": 1314
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.09745996445417404,
      "learning_rate": 3.1285714285714285e-05,
      "loss": 0.0001,
      "step": 1316
    },
    {
      "epoch": 9.414285714285715,
      "grad_norm": 0.4643391966819763,
      "learning_rate": 3.125714285714286e-05,
      "loss": 0.0002,
      "step": 1318
    },
    {
      "epoch": 9.428571428571429,
      "grad_norm": 0.07988065481185913,
      "learning_rate": 3.122857142857143e-05,
      "loss": 0.0002,
      "step": 1320
    },
    {
      "epoch": 9.442857142857143,
      "grad_norm": 0.03669566661119461,
      "learning_rate": 3.12e-05,
      "loss": 0.0262,
      "step": 1322
    },
    {
      "epoch": 9.457142857142857,
      "grad_norm": 0.0562756173312664,
      "learning_rate": 3.117142857142857e-05,
      "loss": 0.0001,
      "step": 1324
    },
    {
      "epoch": 9.471428571428572,
      "grad_norm": 0.04265247657895088,
      "learning_rate": 3.114285714285715e-05,
      "loss": 0.0001,
      "step": 1326
    },
    {
      "epoch": 9.485714285714286,
      "grad_norm": 0.027761509642004967,
      "learning_rate": 3.111428571428572e-05,
      "loss": 0.0001,
      "step": 1328
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.0390336699783802,
      "learning_rate": 3.108571428571429e-05,
      "loss": 0.0001,
      "step": 1330
    },
    {
      "epoch": 9.514285714285714,
      "grad_norm": 0.04296586662530899,
      "learning_rate": 3.1057142857142854e-05,
      "loss": 0.0001,
      "step": 1332
    },
    {
      "epoch": 9.528571428571428,
      "grad_norm": 0.05326416715979576,
      "learning_rate": 3.102857142857143e-05,
      "loss": 0.0002,
      "step": 1334
    },
    {
      "epoch": 9.542857142857143,
      "grad_norm": 0.0672507956624031,
      "learning_rate": 3.1e-05,
      "loss": 0.0001,
      "step": 1336
    },
    {
      "epoch": 9.557142857142857,
      "grad_norm": 0.03532463684678078,
      "learning_rate": 3.0971428571428575e-05,
      "loss": 0.0001,
      "step": 1338
    },
    {
      "epoch": 9.571428571428571,
      "grad_norm": 0.050596415996551514,
      "learning_rate": 3.094285714285715e-05,
      "loss": 0.0001,
      "step": 1340
    },
    {
      "epoch": 9.585714285714285,
      "grad_norm": 0.03925814852118492,
      "learning_rate": 3.0914285714285715e-05,
      "loss": 0.0001,
      "step": 1342
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.07283095270395279,
      "learning_rate": 3.088571428571428e-05,
      "loss": 0.0003,
      "step": 1344
    },
    {
      "epoch": 9.614285714285714,
      "grad_norm": 0.054349374026060104,
      "learning_rate": 3.0857142857142856e-05,
      "loss": 0.0001,
      "step": 1346
    },
    {
      "epoch": 9.628571428571428,
      "grad_norm": 0.04984574019908905,
      "learning_rate": 3.082857142857143e-05,
      "loss": 0.0001,
      "step": 1348
    },
    {
      "epoch": 9.642857142857142,
      "grad_norm": 0.02840498834848404,
      "learning_rate": 3.08e-05,
      "loss": 0.0009,
      "step": 1350
    },
    {
      "epoch": 9.657142857142857,
      "grad_norm": 0.032722339034080505,
      "learning_rate": 3.077142857142857e-05,
      "loss": 0.0001,
      "step": 1352
    },
    {
      "epoch": 9.67142857142857,
      "grad_norm": 0.05936979874968529,
      "learning_rate": 3.0742857142857144e-05,
      "loss": 0.0001,
      "step": 1354
    },
    {
      "epoch": 9.685714285714285,
      "grad_norm": 0.05267961323261261,
      "learning_rate": 3.071428571428572e-05,
      "loss": 0.0001,
      "step": 1356
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.04732811450958252,
      "learning_rate": 3.068571428571429e-05,
      "loss": 0.0002,
      "step": 1358
    },
    {
      "epoch": 9.714285714285714,
      "grad_norm": 0.15293440222740173,
      "learning_rate": 3.065714285714286e-05,
      "loss": 0.0002,
      "step": 1360
    },
    {
      "epoch": 9.728571428571428,
      "grad_norm": 0.03711824119091034,
      "learning_rate": 3.062857142857143e-05,
      "loss": 0.0001,
      "step": 1362
    },
    {
      "epoch": 9.742857142857144,
      "grad_norm": 0.04779839515686035,
      "learning_rate": 3.06e-05,
      "loss": 0.0,
      "step": 1364
    },
    {
      "epoch": 9.757142857142856,
      "grad_norm": 0.3237484097480774,
      "learning_rate": 3.057142857142857e-05,
      "loss": 0.0009,
      "step": 1366
    },
    {
      "epoch": 9.771428571428572,
      "grad_norm": 0.03202785924077034,
      "learning_rate": 3.0542857142857146e-05,
      "loss": 0.0,
      "step": 1368
    },
    {
      "epoch": 9.785714285714286,
      "grad_norm": 0.017942171543836594,
      "learning_rate": 3.0514285714285716e-05,
      "loss": 0.0,
      "step": 1370
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.04379533231258392,
      "learning_rate": 3.048571428571429e-05,
      "loss": 0.2595,
      "step": 1372
    },
    {
      "epoch": 9.814285714285715,
      "grad_norm": 0.034820280969142914,
      "learning_rate": 3.0457142857142856e-05,
      "loss": 0.0001,
      "step": 1374
    },
    {
      "epoch": 9.82857142857143,
      "grad_norm": 0.025862203910946846,
      "learning_rate": 3.042857142857143e-05,
      "loss": 0.0,
      "step": 1376
    },
    {
      "epoch": 9.842857142857143,
      "grad_norm": 0.04525914415717125,
      "learning_rate": 3.04e-05,
      "loss": 0.0001,
      "step": 1378
    },
    {
      "epoch": 9.857142857142858,
      "grad_norm": 0.04602423682808876,
      "learning_rate": 3.0371428571428574e-05,
      "loss": 0.0001,
      "step": 1380
    },
    {
      "epoch": 9.871428571428572,
      "grad_norm": 0.050102461129426956,
      "learning_rate": 3.0342857142857144e-05,
      "loss": 0.0001,
      "step": 1382
    },
    {
      "epoch": 9.885714285714286,
      "grad_norm": 0.05454959720373154,
      "learning_rate": 3.0314285714285718e-05,
      "loss": 0.0001,
      "step": 1384
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.05771978199481964,
      "learning_rate": 3.0285714285714288e-05,
      "loss": 0.0001,
      "step": 1386
    },
    {
      "epoch": 9.914285714285715,
      "grad_norm": 0.025000903755426407,
      "learning_rate": 3.0257142857142855e-05,
      "loss": 0.0,
      "step": 1388
    },
    {
      "epoch": 9.928571428571429,
      "grad_norm": 0.06354706734418869,
      "learning_rate": 3.022857142857143e-05,
      "loss": 0.0011,
      "step": 1390
    },
    {
      "epoch": 9.942857142857143,
      "grad_norm": 0.04610865190625191,
      "learning_rate": 3.02e-05,
      "loss": 0.0001,
      "step": 1392
    },
    {
      "epoch": 9.957142857142857,
      "grad_norm": 0.024371720850467682,
      "learning_rate": 3.0171428571428572e-05,
      "loss": 0.0001,
      "step": 1394
    },
    {
      "epoch": 9.971428571428572,
      "grad_norm": 99.84137725830078,
      "learning_rate": 3.0142857142857146e-05,
      "loss": 0.1034,
      "step": 1396
    },
    {
      "epoch": 9.985714285714286,
      "grad_norm": 0.1137806698679924,
      "learning_rate": 3.0114285714285716e-05,
      "loss": 0.0002,
      "step": 1398
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0287962406873703,
      "learning_rate": 3.008571428571429e-05,
      "loss": 0.0001,
      "step": 1400
    },
    {
      "epoch": 10.0,
      "eval_cer": 0.0050933786078098476,
      "eval_loss": 0.02007901854813099,
      "eval_runtime": 10.1317,
      "eval_samples_per_second": 27.537,
      "eval_steps_per_second": 3.455,
      "step": 1400
    },
    {
      "epoch": 10.014285714285714,
      "grad_norm": 0.04566121846437454,
      "learning_rate": 3.0057142857142857e-05,
      "loss": 0.0002,
      "step": 1402
    },
    {
      "epoch": 10.028571428571428,
      "grad_norm": 0.03719083592295647,
      "learning_rate": 3.0028571428571427e-05,
      "loss": 0.0001,
      "step": 1404
    },
    {
      "epoch": 10.042857142857143,
      "grad_norm": 0.05096810683608055,
      "learning_rate": 3e-05,
      "loss": 0.0001,
      "step": 1406
    },
    {
      "epoch": 10.057142857142857,
      "grad_norm": 10.867266654968262,
      "learning_rate": 2.997142857142857e-05,
      "loss": 0.0077,
      "step": 1408
    },
    {
      "epoch": 10.071428571428571,
      "grad_norm": 0.14051976799964905,
      "learning_rate": 2.9942857142857145e-05,
      "loss": 0.0398,
      "step": 1410
    },
    {
      "epoch": 10.085714285714285,
      "grad_norm": 0.045642513781785965,
      "learning_rate": 2.9914285714285718e-05,
      "loss": 0.0001,
      "step": 1412
    },
    {
      "epoch": 10.1,
      "grad_norm": 0.07051955163478851,
      "learning_rate": 2.988571428571429e-05,
      "loss": 0.0001,
      "step": 1414
    },
    {
      "epoch": 10.114285714285714,
      "grad_norm": 0.04038507118821144,
      "learning_rate": 2.9857142857142862e-05,
      "loss": 0.0001,
      "step": 1416
    },
    {
      "epoch": 10.128571428571428,
      "grad_norm": 0.062131430953741074,
      "learning_rate": 2.982857142857143e-05,
      "loss": 0.0001,
      "step": 1418
    },
    {
      "epoch": 10.142857142857142,
      "grad_norm": 0.0523502379655838,
      "learning_rate": 2.98e-05,
      "loss": 0.0001,
      "step": 1420
    },
    {
      "epoch": 10.157142857142857,
      "grad_norm": 0.055639125406742096,
      "learning_rate": 2.9771428571428573e-05,
      "loss": 0.0001,
      "step": 1422
    },
    {
      "epoch": 10.17142857142857,
      "grad_norm": 0.05961364880204201,
      "learning_rate": 2.9742857142857143e-05,
      "loss": 0.0088,
      "step": 1424
    },
    {
      "epoch": 10.185714285714285,
      "grad_norm": 0.04349001124501228,
      "learning_rate": 2.9714285714285717e-05,
      "loss": 0.1472,
      "step": 1426
    },
    {
      "epoch": 10.2,
      "grad_norm": 0.041136931627988815,
      "learning_rate": 2.968571428571429e-05,
      "loss": 0.0001,
      "step": 1428
    },
    {
      "epoch": 10.214285714285714,
      "grad_norm": 0.03672204911708832,
      "learning_rate": 2.965714285714286e-05,
      "loss": 0.0001,
      "step": 1430
    },
    {
      "epoch": 10.228571428571428,
      "grad_norm": 0.03465846925973892,
      "learning_rate": 2.9628571428571428e-05,
      "loss": 0.0,
      "step": 1432
    },
    {
      "epoch": 10.242857142857142,
      "grad_norm": 0.05418960377573967,
      "learning_rate": 2.96e-05,
      "loss": 0.0001,
      "step": 1434
    },
    {
      "epoch": 10.257142857142856,
      "grad_norm": 0.0481802262365818,
      "learning_rate": 2.957142857142857e-05,
      "loss": 0.0001,
      "step": 1436
    },
    {
      "epoch": 10.271428571428572,
      "grad_norm": 0.05283288285136223,
      "learning_rate": 2.9542857142857145e-05,
      "loss": 0.0001,
      "step": 1438
    },
    {
      "epoch": 10.285714285714286,
      "grad_norm": 0.055295512080192566,
      "learning_rate": 2.9514285714285715e-05,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 10.3,
      "grad_norm": 0.03333311155438423,
      "learning_rate": 2.948571428571429e-05,
      "loss": 0.2025,
      "step": 1442
    },
    {
      "epoch": 10.314285714285715,
      "grad_norm": 0.05091080442070961,
      "learning_rate": 2.9457142857142863e-05,
      "loss": 0.0001,
      "step": 1444
    },
    {
      "epoch": 10.32857142857143,
      "grad_norm": 0.02431289106607437,
      "learning_rate": 2.9428571428571426e-05,
      "loss": 0.0192,
      "step": 1446
    },
    {
      "epoch": 10.342857142857143,
      "grad_norm": 0.04874446615576744,
      "learning_rate": 2.94e-05,
      "loss": 0.0001,
      "step": 1448
    },
    {
      "epoch": 10.357142857142858,
      "grad_norm": 0.03184095770120621,
      "learning_rate": 2.9371428571428573e-05,
      "loss": 0.0001,
      "step": 1450
    },
    {
      "epoch": 10.371428571428572,
      "grad_norm": 0.16116344928741455,
      "learning_rate": 2.9342857142857144e-05,
      "loss": 0.0296,
      "step": 1452
    },
    {
      "epoch": 10.385714285714286,
      "grad_norm": 0.04400290548801422,
      "learning_rate": 2.9314285714285717e-05,
      "loss": 0.0001,
      "step": 1454
    },
    {
      "epoch": 10.4,
      "grad_norm": 0.02626892551779747,
      "learning_rate": 2.9285714285714288e-05,
      "loss": 0.0001,
      "step": 1456
    },
    {
      "epoch": 10.414285714285715,
      "grad_norm": 0.033237189054489136,
      "learning_rate": 2.925714285714286e-05,
      "loss": 0.0002,
      "step": 1458
    },
    {
      "epoch": 10.428571428571429,
      "grad_norm": 0.03964027017354965,
      "learning_rate": 2.9228571428571428e-05,
      "loss": 0.0,
      "step": 1460
    },
    {
      "epoch": 10.442857142857143,
      "grad_norm": 0.03572596609592438,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 0.0001,
      "step": 1462
    },
    {
      "epoch": 10.457142857142857,
      "grad_norm": 0.042942844331264496,
      "learning_rate": 2.9171428571428572e-05,
      "loss": 0.0002,
      "step": 1464
    },
    {
      "epoch": 10.471428571428572,
      "grad_norm": 0.03410475328564644,
      "learning_rate": 2.9142857142857146e-05,
      "loss": 0.0001,
      "step": 1466
    },
    {
      "epoch": 10.485714285714286,
      "grad_norm": 141.0221710205078,
      "learning_rate": 2.9114285714285716e-05,
      "loss": 0.0374,
      "step": 1468
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.0543326735496521,
      "learning_rate": 2.908571428571429e-05,
      "loss": 0.0008,
      "step": 1470
    },
    {
      "epoch": 10.514285714285714,
      "grad_norm": 27.64326286315918,
      "learning_rate": 2.905714285714286e-05,
      "loss": 0.0222,
      "step": 1472
    },
    {
      "epoch": 10.528571428571428,
      "grad_norm": 0.09562601894140244,
      "learning_rate": 2.9028571428571427e-05,
      "loss": 0.0004,
      "step": 1474
    },
    {
      "epoch": 10.542857142857143,
      "grad_norm": 0.035336341708898544,
      "learning_rate": 2.9e-05,
      "loss": 0.0001,
      "step": 1476
    },
    {
      "epoch": 10.557142857142857,
      "grad_norm": 0.037321045994758606,
      "learning_rate": 2.897142857142857e-05,
      "loss": 0.0,
      "step": 1478
    },
    {
      "epoch": 10.571428571428571,
      "grad_norm": 0.04921654984354973,
      "learning_rate": 2.8942857142857144e-05,
      "loss": 0.0001,
      "step": 1480
    },
    {
      "epoch": 10.585714285714285,
      "grad_norm": 0.045374494045972824,
      "learning_rate": 2.8914285714285714e-05,
      "loss": 0.0001,
      "step": 1482
    },
    {
      "epoch": 10.6,
      "grad_norm": 0.040137115865945816,
      "learning_rate": 2.8885714285714288e-05,
      "loss": 0.0001,
      "step": 1484
    },
    {
      "epoch": 10.614285714285714,
      "grad_norm": 1.5928150415420532,
      "learning_rate": 2.885714285714286e-05,
      "loss": 0.002,
      "step": 1486
    },
    {
      "epoch": 10.628571428571428,
      "grad_norm": 0.03771817684173584,
      "learning_rate": 2.8828571428571432e-05,
      "loss": 0.0001,
      "step": 1488
    },
    {
      "epoch": 10.642857142857142,
      "grad_norm": 0.05112025886774063,
      "learning_rate": 2.88e-05,
      "loss": 0.0001,
      "step": 1490
    },
    {
      "epoch": 10.657142857142857,
      "grad_norm": 0.04607905074954033,
      "learning_rate": 2.8771428571428572e-05,
      "loss": 0.0009,
      "step": 1492
    },
    {
      "epoch": 10.67142857142857,
      "grad_norm": 0.06980927288532257,
      "learning_rate": 2.8742857142857143e-05,
      "loss": 0.0002,
      "step": 1494
    },
    {
      "epoch": 10.685714285714285,
      "grad_norm": 0.08293729275465012,
      "learning_rate": 2.8714285714285716e-05,
      "loss": 0.0003,
      "step": 1496
    },
    {
      "epoch": 10.7,
      "grad_norm": 0.04626419395208359,
      "learning_rate": 2.8685714285714286e-05,
      "loss": 0.0002,
      "step": 1498
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.11904575675725937,
      "learning_rate": 2.865714285714286e-05,
      "loss": 0.0003,
      "step": 1500
    },
    {
      "epoch": 10.728571428571428,
      "grad_norm": 0.056788403540849686,
      "learning_rate": 2.8628571428571434e-05,
      "loss": 0.0001,
      "step": 1502
    },
    {
      "epoch": 10.742857142857144,
      "grad_norm": 0.05646858736872673,
      "learning_rate": 2.86e-05,
      "loss": 0.0001,
      "step": 1504
    },
    {
      "epoch": 10.757142857142856,
      "grad_norm": 12.360307693481445,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.0146,
      "step": 1506
    },
    {
      "epoch": 10.771428571428572,
      "grad_norm": 27.61056137084961,
      "learning_rate": 2.8542857142857144e-05,
      "loss": 0.0514,
      "step": 1508
    },
    {
      "epoch": 10.785714285714286,
      "grad_norm": 0.05708180367946625,
      "learning_rate": 2.8514285714285715e-05,
      "loss": 0.0001,
      "step": 1510
    },
    {
      "epoch": 10.8,
      "grad_norm": 0.025235459208488464,
      "learning_rate": 2.848571428571429e-05,
      "loss": 0.0002,
      "step": 1512
    },
    {
      "epoch": 10.814285714285715,
      "grad_norm": 0.030230464413762093,
      "learning_rate": 2.845714285714286e-05,
      "loss": 0.0002,
      "step": 1514
    },
    {
      "epoch": 10.82857142857143,
      "grad_norm": 0.03575509414076805,
      "learning_rate": 2.8428571428571432e-05,
      "loss": 0.0001,
      "step": 1516
    },
    {
      "epoch": 10.842857142857143,
      "grad_norm": 0.5073796510696411,
      "learning_rate": 2.84e-05,
      "loss": 0.0009,
      "step": 1518
    },
    {
      "epoch": 10.857142857142858,
      "grad_norm": 0.3739776313304901,
      "learning_rate": 2.837142857142857e-05,
      "loss": 0.0006,
      "step": 1520
    },
    {
      "epoch": 10.871428571428572,
      "grad_norm": 0.4038394093513489,
      "learning_rate": 2.8342857142857143e-05,
      "loss": 0.0005,
      "step": 1522
    },
    {
      "epoch": 10.885714285714286,
      "grad_norm": 0.03521232306957245,
      "learning_rate": 2.8314285714285717e-05,
      "loss": 0.0001,
      "step": 1524
    },
    {
      "epoch": 10.9,
      "grad_norm": 0.031655166298151016,
      "learning_rate": 2.8285714285714287e-05,
      "loss": 0.0001,
      "step": 1526
    },
    {
      "epoch": 10.914285714285715,
      "grad_norm": 0.05503843352198601,
      "learning_rate": 2.825714285714286e-05,
      "loss": 0.0002,
      "step": 1528
    },
    {
      "epoch": 10.928571428571429,
      "grad_norm": 0.032445814460515976,
      "learning_rate": 2.822857142857143e-05,
      "loss": 0.0001,
      "step": 1530
    },
    {
      "epoch": 10.942857142857143,
      "grad_norm": 0.03645705804228783,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.0001,
      "step": 1532
    },
    {
      "epoch": 10.957142857142857,
      "grad_norm": 0.04088335111737251,
      "learning_rate": 2.817142857142857e-05,
      "loss": 0.0001,
      "step": 1534
    },
    {
      "epoch": 10.971428571428572,
      "grad_norm": 0.030600395053625107,
      "learning_rate": 2.814285714285714e-05,
      "loss": 0.0,
      "step": 1536
    },
    {
      "epoch": 10.985714285714286,
      "grad_norm": 0.04440467432141304,
      "learning_rate": 2.8114285714285715e-05,
      "loss": 0.0001,
      "step": 1538
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.04512755200266838,
      "learning_rate": 2.808571428571429e-05,
      "loss": 0.0002,
      "step": 1540
    },
    {
      "epoch": 11.014285714285714,
      "grad_norm": 0.040853556245565414,
      "learning_rate": 2.805714285714286e-05,
      "loss": 0.0001,
      "step": 1542
    },
    {
      "epoch": 11.028571428571428,
      "grad_norm": 0.020668961107730865,
      "learning_rate": 2.8028571428571433e-05,
      "loss": 0.0,
      "step": 1544
    },
    {
      "epoch": 11.042857142857143,
      "grad_norm": 0.029255740344524384,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0,
      "step": 1546
    },
    {
      "epoch": 11.057142857142857,
      "grad_norm": 0.04167981073260307,
      "learning_rate": 2.797142857142857e-05,
      "loss": 0.0001,
      "step": 1548
    },
    {
      "epoch": 11.071428571428571,
      "grad_norm": 0.02344655618071556,
      "learning_rate": 2.7942857142857143e-05,
      "loss": 0.0,
      "step": 1550
    },
    {
      "epoch": 11.085714285714285,
      "grad_norm": 0.020217467099428177,
      "learning_rate": 2.7914285714285714e-05,
      "loss": 0.0,
      "step": 1552
    },
    {
      "epoch": 11.1,
      "grad_norm": 0.02365552820265293,
      "learning_rate": 2.7885714285714287e-05,
      "loss": 0.0,
      "step": 1554
    },
    {
      "epoch": 11.114285714285714,
      "grad_norm": 0.022036898881196976,
      "learning_rate": 2.785714285714286e-05,
      "loss": 0.0001,
      "step": 1556
    },
    {
      "epoch": 11.128571428571428,
      "grad_norm": 0.029201043769717216,
      "learning_rate": 2.782857142857143e-05,
      "loss": 0.0,
      "step": 1558
    },
    {
      "epoch": 11.142857142857142,
      "grad_norm": 0.03012596070766449,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 0.0,
      "step": 1560
    },
    {
      "epoch": 11.157142857142857,
      "grad_norm": 0.03359774500131607,
      "learning_rate": 2.7771428571428572e-05,
      "loss": 0.0001,
      "step": 1562
    },
    {
      "epoch": 11.17142857142857,
      "grad_norm": 0.018749751150608063,
      "learning_rate": 2.7742857142857142e-05,
      "loss": 0.0,
      "step": 1564
    },
    {
      "epoch": 11.185714285714285,
      "grad_norm": 0.52751624584198,
      "learning_rate": 2.7714285714285716e-05,
      "loss": 0.0004,
      "step": 1566
    },
    {
      "epoch": 11.2,
      "grad_norm": 0.05133293569087982,
      "learning_rate": 2.7685714285714286e-05,
      "loss": 0.0001,
      "step": 1568
    },
    {
      "epoch": 11.214285714285714,
      "grad_norm": 0.03328683227300644,
      "learning_rate": 2.765714285714286e-05,
      "loss": 0.0001,
      "step": 1570
    },
    {
      "epoch": 11.228571428571428,
      "grad_norm": 0.04472103342413902,
      "learning_rate": 2.762857142857143e-05,
      "loss": 0.0001,
      "step": 1572
    },
    {
      "epoch": 11.242857142857142,
      "grad_norm": 0.04097313806414604,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.0001,
      "step": 1574
    },
    {
      "epoch": 11.257142857142856,
      "grad_norm": 0.0369303859770298,
      "learning_rate": 2.757142857142857e-05,
      "loss": 0.0,
      "step": 1576
    },
    {
      "epoch": 11.271428571428572,
      "grad_norm": 0.06269069015979767,
      "learning_rate": 2.7542857142857144e-05,
      "loss": 0.0,
      "step": 1578
    },
    {
      "epoch": 11.285714285714286,
      "grad_norm": 0.0766521692276001,
      "learning_rate": 2.7514285714285714e-05,
      "loss": 0.0001,
      "step": 1580
    },
    {
      "epoch": 11.3,
      "grad_norm": 0.034412674605846405,
      "learning_rate": 2.7485714285714288e-05,
      "loss": 0.0001,
      "step": 1582
    },
    {
      "epoch": 11.314285714285715,
      "grad_norm": 0.027735861018300056,
      "learning_rate": 2.7457142857142858e-05,
      "loss": 0.0,
      "step": 1584
    },
    {
      "epoch": 11.32857142857143,
      "grad_norm": 0.056990403681993484,
      "learning_rate": 2.742857142857143e-05,
      "loss": 0.0001,
      "step": 1586
    },
    {
      "epoch": 11.342857142857143,
      "grad_norm": 0.06661354750394821,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 0.0003,
      "step": 1588
    },
    {
      "epoch": 11.357142857142858,
      "grad_norm": 0.02172321081161499,
      "learning_rate": 2.737142857142857e-05,
      "loss": 0.0,
      "step": 1590
    },
    {
      "epoch": 11.371428571428572,
      "grad_norm": 0.03331030532717705,
      "learning_rate": 2.7342857142857142e-05,
      "loss": 0.0,
      "step": 1592
    },
    {
      "epoch": 11.385714285714286,
      "grad_norm": 0.044213950634002686,
      "learning_rate": 2.7314285714285716e-05,
      "loss": 0.0001,
      "step": 1594
    },
    {
      "epoch": 11.4,
      "grad_norm": 0.04054902493953705,
      "learning_rate": 2.7285714285714286e-05,
      "loss": 0.0,
      "step": 1596
    },
    {
      "epoch": 11.414285714285715,
      "grad_norm": 0.021433372050523758,
      "learning_rate": 2.725714285714286e-05,
      "loss": 0.0,
      "step": 1598
    },
    {
      "epoch": 11.428571428571429,
      "grad_norm": 0.02932678908109665,
      "learning_rate": 2.722857142857143e-05,
      "loss": 0.0,
      "step": 1600
    },
    {
      "epoch": 11.428571428571429,
      "eval_cer": 0.006791171477079796,
      "eval_loss": 0.031756237149238586,
      "eval_runtime": 12.0713,
      "eval_samples_per_second": 23.113,
      "eval_steps_per_second": 2.899,
      "step": 1600
    },
    {
      "epoch": 11.442857142857143,
      "grad_norm": 0.03318310156464577,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 0.0,
      "step": 1602
    },
    {
      "epoch": 11.457142857142857,
      "grad_norm": 0.020095210522413254,
      "learning_rate": 2.7171428571428574e-05,
      "loss": 0.0,
      "step": 1604
    },
    {
      "epoch": 11.471428571428572,
      "grad_norm": 0.021628301590681076,
      "learning_rate": 2.714285714285714e-05,
      "loss": 0.0,
      "step": 1606
    },
    {
      "epoch": 11.485714285714286,
      "grad_norm": 0.03899639844894409,
      "learning_rate": 2.7114285714285715e-05,
      "loss": 0.0,
      "step": 1608
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.019599756225943565,
      "learning_rate": 2.7085714285714285e-05,
      "loss": 0.0,
      "step": 1610
    },
    {
      "epoch": 11.514285714285714,
      "grad_norm": 0.031819943338632584,
      "learning_rate": 2.705714285714286e-05,
      "loss": 0.0003,
      "step": 1612
    },
    {
      "epoch": 11.528571428571428,
      "grad_norm": 0.027551785111427307,
      "learning_rate": 2.7028571428571432e-05,
      "loss": 0.0,
      "step": 1614
    },
    {
      "epoch": 11.542857142857143,
      "grad_norm": 0.03189845010638237,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0001,
      "step": 1616
    },
    {
      "epoch": 11.557142857142857,
      "grad_norm": 0.024592911824584007,
      "learning_rate": 2.6971428571428576e-05,
      "loss": 0.0001,
      "step": 1618
    },
    {
      "epoch": 11.571428571428571,
      "grad_norm": 0.047375865280628204,
      "learning_rate": 2.6942857142857143e-05,
      "loss": 0.0001,
      "step": 1620
    },
    {
      "epoch": 11.585714285714285,
      "grad_norm": 0.02883845567703247,
      "learning_rate": 2.6914285714285713e-05,
      "loss": 0.0,
      "step": 1622
    },
    {
      "epoch": 11.6,
      "grad_norm": 0.027878496795892715,
      "learning_rate": 2.6885714285714287e-05,
      "loss": 0.0001,
      "step": 1624
    },
    {
      "epoch": 11.614285714285714,
      "grad_norm": 0.0474574901163578,
      "learning_rate": 2.6857142857142857e-05,
      "loss": 0.0,
      "step": 1626
    },
    {
      "epoch": 11.628571428571428,
      "grad_norm": 0.024941053241491318,
      "learning_rate": 2.682857142857143e-05,
      "loss": 0.0,
      "step": 1628
    },
    {
      "epoch": 11.642857142857142,
      "grad_norm": 0.03325054794549942,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.0001,
      "step": 1630
    },
    {
      "epoch": 11.657142857142857,
      "grad_norm": 0.029438819736242294,
      "learning_rate": 2.6771428571428575e-05,
      "loss": 0.0001,
      "step": 1632
    },
    {
      "epoch": 11.67142857142857,
      "grad_norm": 0.020680326968431473,
      "learning_rate": 2.674285714285714e-05,
      "loss": 0.0001,
      "step": 1634
    },
    {
      "epoch": 11.685714285714285,
      "grad_norm": 0.029468296095728874,
      "learning_rate": 2.6714285714285715e-05,
      "loss": 0.0001,
      "step": 1636
    },
    {
      "epoch": 11.7,
      "grad_norm": 0.06454240530729294,
      "learning_rate": 2.6685714285714285e-05,
      "loss": 0.0001,
      "step": 1638
    },
    {
      "epoch": 11.714285714285714,
      "grad_norm": 0.026471011340618134,
      "learning_rate": 2.665714285714286e-05,
      "loss": 0.0,
      "step": 1640
    },
    {
      "epoch": 11.728571428571428,
      "grad_norm": 0.03251505643129349,
      "learning_rate": 2.662857142857143e-05,
      "loss": 0.0,
      "step": 1642
    },
    {
      "epoch": 11.742857142857144,
      "grad_norm": 0.032182980328798294,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 0.0001,
      "step": 1644
    },
    {
      "epoch": 11.757142857142856,
      "grad_norm": 0.0297407153993845,
      "learning_rate": 2.6571428571428576e-05,
      "loss": 0.0,
      "step": 1646
    },
    {
      "epoch": 11.771428571428572,
      "grad_norm": 0.020419934764504433,
      "learning_rate": 2.654285714285714e-05,
      "loss": 0.0,
      "step": 1648
    },
    {
      "epoch": 11.785714285714286,
      "grad_norm": 0.03766050934791565,
      "learning_rate": 2.6514285714285714e-05,
      "loss": 0.0001,
      "step": 1650
    },
    {
      "epoch": 11.8,
      "grad_norm": 0.0421857088804245,
      "learning_rate": 2.6485714285714287e-05,
      "loss": 0.0,
      "step": 1652
    },
    {
      "epoch": 11.814285714285715,
      "grad_norm": 0.02227788232266903,
      "learning_rate": 2.6457142857142857e-05,
      "loss": 0.0,
      "step": 1654
    },
    {
      "epoch": 11.82857142857143,
      "grad_norm": 0.01795213855803013,
      "learning_rate": 2.642857142857143e-05,
      "loss": 0.0,
      "step": 1656
    },
    {
      "epoch": 11.842857142857143,
      "grad_norm": 0.024959027767181396,
      "learning_rate": 2.64e-05,
      "loss": 0.0,
      "step": 1658
    },
    {
      "epoch": 11.857142857142858,
      "grad_norm": 0.027983317151665688,
      "learning_rate": 2.6371428571428575e-05,
      "loss": 0.0,
      "step": 1660
    },
    {
      "epoch": 11.871428571428572,
      "grad_norm": 0.05006036162376404,
      "learning_rate": 2.6342857142857142e-05,
      "loss": 0.0001,
      "step": 1662
    },
    {
      "epoch": 11.885714285714286,
      "grad_norm": 0.06201181933283806,
      "learning_rate": 2.6314285714285712e-05,
      "loss": 0.0,
      "step": 1664
    },
    {
      "epoch": 11.9,
      "grad_norm": 0.04076775908470154,
      "learning_rate": 2.6285714285714286e-05,
      "loss": 0.0,
      "step": 1666
    },
    {
      "epoch": 11.914285714285715,
      "grad_norm": 0.019220873713493347,
      "learning_rate": 2.625714285714286e-05,
      "loss": 0.0,
      "step": 1668
    },
    {
      "epoch": 11.928571428571429,
      "grad_norm": 0.15632028877735138,
      "learning_rate": 2.622857142857143e-05,
      "loss": 0.0001,
      "step": 1670
    },
    {
      "epoch": 11.942857142857143,
      "grad_norm": 6.418473243713379,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 0.004,
      "step": 1672
    },
    {
      "epoch": 11.957142857142857,
      "grad_norm": 0.0323483943939209,
      "learning_rate": 2.6171428571428574e-05,
      "loss": 0.0001,
      "step": 1674
    },
    {
      "epoch": 11.971428571428572,
      "grad_norm": 0.0307804886251688,
      "learning_rate": 2.6142857142857147e-05,
      "loss": 0.0,
      "step": 1676
    },
    {
      "epoch": 11.985714285714286,
      "grad_norm": 0.022773699834942818,
      "learning_rate": 2.6114285714285714e-05,
      "loss": 0.0,
      "step": 1678
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.038001030683517456,
      "learning_rate": 2.6085714285714284e-05,
      "loss": 0.0001,
      "step": 1680
    },
    {
      "epoch": 12.014285714285714,
      "grad_norm": 0.031722843647003174,
      "learning_rate": 2.6057142857142858e-05,
      "loss": 0.0,
      "step": 1682
    },
    {
      "epoch": 12.028571428571428,
      "grad_norm": 0.02452857978641987,
      "learning_rate": 2.602857142857143e-05,
      "loss": 0.0,
      "step": 1684
    },
    {
      "epoch": 12.042857142857143,
      "grad_norm": 0.03276395797729492,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0001,
      "step": 1686
    },
    {
      "epoch": 12.057142857142857,
      "grad_norm": 0.050150953233242035,
      "learning_rate": 2.5971428571428575e-05,
      "loss": 0.0001,
      "step": 1688
    },
    {
      "epoch": 12.071428571428571,
      "grad_norm": 0.040973253548145294,
      "learning_rate": 2.5942857142857146e-05,
      "loss": 0.0,
      "step": 1690
    },
    {
      "epoch": 12.085714285714285,
      "grad_norm": 0.03245941177010536,
      "learning_rate": 2.5914285714285713e-05,
      "loss": 0.0,
      "step": 1692
    },
    {
      "epoch": 12.1,
      "grad_norm": 0.03525028005242348,
      "learning_rate": 2.5885714285714286e-05,
      "loss": 0.0001,
      "step": 1694
    },
    {
      "epoch": 12.114285714285714,
      "grad_norm": 0.13349784910678864,
      "learning_rate": 2.5857142857142856e-05,
      "loss": 0.0001,
      "step": 1696
    },
    {
      "epoch": 12.128571428571428,
      "grad_norm": 0.018369872123003006,
      "learning_rate": 2.582857142857143e-05,
      "loss": 0.0,
      "step": 1698
    },
    {
      "epoch": 12.142857142857142,
      "grad_norm": 0.03390531986951828,
      "learning_rate": 2.58e-05,
      "loss": 0.0,
      "step": 1700
    },
    {
      "epoch": 12.157142857142857,
      "grad_norm": 0.03154454007744789,
      "learning_rate": 2.5771428571428574e-05,
      "loss": 0.0001,
      "step": 1702
    },
    {
      "epoch": 12.17142857142857,
      "grad_norm": 0.12485502660274506,
      "learning_rate": 2.5742857142857148e-05,
      "loss": 0.0,
      "step": 1704
    },
    {
      "epoch": 12.185714285714285,
      "grad_norm": 0.040441084653139114,
      "learning_rate": 2.5714285714285714e-05,
      "loss": 0.0,
      "step": 1706
    },
    {
      "epoch": 12.2,
      "grad_norm": 0.02863616682589054,
      "learning_rate": 2.5685714285714285e-05,
      "loss": 0.0,
      "step": 1708
    },
    {
      "epoch": 12.214285714285714,
      "grad_norm": 0.04280107468366623,
      "learning_rate": 2.565714285714286e-05,
      "loss": 0.0001,
      "step": 1710
    },
    {
      "epoch": 12.228571428571428,
      "grad_norm": 0.050127338618040085,
      "learning_rate": 2.562857142857143e-05,
      "loss": 0.0,
      "step": 1712
    },
    {
      "epoch": 12.242857142857142,
      "grad_norm": 0.043260082602500916,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.0,
      "step": 1714
    },
    {
      "epoch": 12.257142857142856,
      "grad_norm": 0.03672553598880768,
      "learning_rate": 2.5571428571428572e-05,
      "loss": 0.0001,
      "step": 1716
    },
    {
      "epoch": 12.271428571428572,
      "grad_norm": 0.04694904759526253,
      "learning_rate": 2.5542857142857146e-05,
      "loss": 0.0,
      "step": 1718
    },
    {
      "epoch": 12.285714285714286,
      "grad_norm": 0.03247634321451187,
      "learning_rate": 2.5514285714285713e-05,
      "loss": 0.0001,
      "step": 1720
    },
    {
      "epoch": 12.3,
      "grad_norm": 0.025131314992904663,
      "learning_rate": 2.5485714285714287e-05,
      "loss": 0.0,
      "step": 1722
    },
    {
      "epoch": 12.314285714285715,
      "grad_norm": 0.02554917521774769,
      "learning_rate": 2.5457142857142857e-05,
      "loss": 0.0,
      "step": 1724
    },
    {
      "epoch": 12.32857142857143,
      "grad_norm": 0.020539993420243263,
      "learning_rate": 2.542857142857143e-05,
      "loss": 0.0,
      "step": 1726
    },
    {
      "epoch": 12.342857142857143,
      "grad_norm": 0.04050431400537491,
      "learning_rate": 2.54e-05,
      "loss": 0.0001,
      "step": 1728
    },
    {
      "epoch": 12.357142857142858,
      "grad_norm": 0.05675308406352997,
      "learning_rate": 2.5371428571428574e-05,
      "loss": 0.0001,
      "step": 1730
    },
    {
      "epoch": 12.371428571428572,
      "grad_norm": 0.024266045540571213,
      "learning_rate": 2.5342857142857145e-05,
      "loss": 0.0,
      "step": 1732
    },
    {
      "epoch": 12.385714285714286,
      "grad_norm": 0.027856217697262764,
      "learning_rate": 2.5314285714285718e-05,
      "loss": 0.0,
      "step": 1734
    },
    {
      "epoch": 12.4,
      "grad_norm": 0.024475233629345894,
      "learning_rate": 2.5285714285714285e-05,
      "loss": 0.0001,
      "step": 1736
    },
    {
      "epoch": 12.414285714285715,
      "grad_norm": 0.05010579898953438,
      "learning_rate": 2.5257142857142855e-05,
      "loss": 0.0,
      "step": 1738
    },
    {
      "epoch": 12.428571428571429,
      "grad_norm": 0.03789124637842178,
      "learning_rate": 2.522857142857143e-05,
      "loss": 0.0004,
      "step": 1740
    },
    {
      "epoch": 12.442857142857143,
      "grad_norm": 0.17213210463523865,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 0.0001,
      "step": 1742
    },
    {
      "epoch": 12.457142857142857,
      "grad_norm": 0.02657025121152401,
      "learning_rate": 2.5171428571428573e-05,
      "loss": 0.0,
      "step": 1744
    },
    {
      "epoch": 12.471428571428572,
      "grad_norm": 0.03696165978908539,
      "learning_rate": 2.5142857142857147e-05,
      "loss": 0.0001,
      "step": 1746
    },
    {
      "epoch": 12.485714285714286,
      "grad_norm": 0.03456239029765129,
      "learning_rate": 2.5114285714285717e-05,
      "loss": 0.0,
      "step": 1748
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.048722945153713226,
      "learning_rate": 2.5085714285714284e-05,
      "loss": 0.0,
      "step": 1750
    },
    {
      "epoch": 12.514285714285714,
      "grad_norm": 0.03599110618233681,
      "learning_rate": 2.5057142857142857e-05,
      "loss": 0.0,
      "step": 1752
    },
    {
      "epoch": 12.528571428571428,
      "grad_norm": 0.024295207113027573,
      "learning_rate": 2.5028571428571428e-05,
      "loss": 0.0,
      "step": 1754
    },
    {
      "epoch": 12.542857142857143,
      "grad_norm": 0.02605021931231022,
      "learning_rate": 2.5e-05,
      "loss": 0.0,
      "step": 1756
    },
    {
      "epoch": 12.557142857142857,
      "grad_norm": 0.028237182646989822,
      "learning_rate": 2.4971428571428575e-05,
      "loss": 0.0,
      "step": 1758
    },
    {
      "epoch": 12.571428571428571,
      "grad_norm": 0.025830140337347984,
      "learning_rate": 2.4942857142857142e-05,
      "loss": 0.0,
      "step": 1760
    },
    {
      "epoch": 12.585714285714285,
      "grad_norm": 0.04107094928622246,
      "learning_rate": 2.4914285714285715e-05,
      "loss": 0.0001,
      "step": 1762
    },
    {
      "epoch": 12.6,
      "grad_norm": 0.031382206827402115,
      "learning_rate": 2.4885714285714286e-05,
      "loss": 0.0,
      "step": 1764
    },
    {
      "epoch": 12.614285714285714,
      "grad_norm": 0.023399796336889267,
      "learning_rate": 2.485714285714286e-05,
      "loss": 0.0,
      "step": 1766
    },
    {
      "epoch": 12.628571428571428,
      "grad_norm": 0.02547852322459221,
      "learning_rate": 2.482857142857143e-05,
      "loss": 0.0,
      "step": 1768
    },
    {
      "epoch": 12.642857142857142,
      "grad_norm": 0.03885169327259064,
      "learning_rate": 2.48e-05,
      "loss": 0.0001,
      "step": 1770
    },
    {
      "epoch": 12.657142857142857,
      "grad_norm": 0.05069772154092789,
      "learning_rate": 2.4771428571428573e-05,
      "loss": 0.0,
      "step": 1772
    },
    {
      "epoch": 12.67142857142857,
      "grad_norm": 0.04406556114554405,
      "learning_rate": 2.4742857142857147e-05,
      "loss": 0.0,
      "step": 1774
    },
    {
      "epoch": 12.685714285714285,
      "grad_norm": 0.017941074445843697,
      "learning_rate": 2.4714285714285714e-05,
      "loss": 0.0,
      "step": 1776
    },
    {
      "epoch": 12.7,
      "grad_norm": 0.025728771463036537,
      "learning_rate": 2.4685714285714288e-05,
      "loss": 0.0,
      "step": 1778
    },
    {
      "epoch": 12.714285714285714,
      "grad_norm": 0.052366189658641815,
      "learning_rate": 2.4657142857142858e-05,
      "loss": 0.0001,
      "step": 1780
    },
    {
      "epoch": 12.728571428571428,
      "grad_norm": 0.039399392902851105,
      "learning_rate": 2.4628571428571428e-05,
      "loss": 0.0,
      "step": 1782
    },
    {
      "epoch": 12.742857142857144,
      "grad_norm": 0.0343952439725399,
      "learning_rate": 2.46e-05,
      "loss": 0.0,
      "step": 1784
    },
    {
      "epoch": 12.757142857142856,
      "grad_norm": 0.023358171805739403,
      "learning_rate": 2.4571428571428572e-05,
      "loss": 0.0,
      "step": 1786
    },
    {
      "epoch": 12.771428571428572,
      "grad_norm": 0.05899824574589729,
      "learning_rate": 2.4542857142857146e-05,
      "loss": 0.0001,
      "step": 1788
    },
    {
      "epoch": 12.785714285714286,
      "grad_norm": 0.029548874124884605,
      "learning_rate": 2.4514285714285716e-05,
      "loss": 0.0,
      "step": 1790
    },
    {
      "epoch": 12.8,
      "grad_norm": 0.06470523029565811,
      "learning_rate": 2.4485714285714286e-05,
      "loss": 0.0001,
      "step": 1792
    },
    {
      "epoch": 12.814285714285715,
      "grad_norm": 0.03391717001795769,
      "learning_rate": 2.445714285714286e-05,
      "loss": 0.0001,
      "step": 1794
    },
    {
      "epoch": 12.82857142857143,
      "grad_norm": 0.03577914834022522,
      "learning_rate": 2.442857142857143e-05,
      "loss": 0.0,
      "step": 1796
    },
    {
      "epoch": 12.842857142857143,
      "grad_norm": 0.037040576338768005,
      "learning_rate": 2.44e-05,
      "loss": 0.0001,
      "step": 1798
    },
    {
      "epoch": 12.857142857142858,
      "grad_norm": 0.026408858597278595,
      "learning_rate": 2.4371428571428574e-05,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 12.857142857142858,
      "eval_cer": 0.006791171477079796,
      "eval_loss": 0.038318559527397156,
      "eval_runtime": 10.0506,
      "eval_samples_per_second": 27.759,
      "eval_steps_per_second": 3.482,
      "step": 1800
    },
    {
      "epoch": 12.871428571428572,
      "grad_norm": 0.03337319195270538,
      "learning_rate": 2.4342857142857144e-05,
      "loss": 0.0,
      "step": 1802
    },
    {
      "epoch": 12.885714285714286,
      "grad_norm": 0.02645236812531948,
      "learning_rate": 2.4314285714285714e-05,
      "loss": 0.0,
      "step": 1804
    },
    {
      "epoch": 12.9,
      "grad_norm": 0.03699692338705063,
      "learning_rate": 2.4285714285714288e-05,
      "loss": 0.0001,
      "step": 1806
    },
    {
      "epoch": 12.914285714285715,
      "grad_norm": 0.562379777431488,
      "learning_rate": 2.4257142857142858e-05,
      "loss": 0.0003,
      "step": 1808
    },
    {
      "epoch": 12.928571428571429,
      "grad_norm": 0.02748771198093891,
      "learning_rate": 2.4228571428571432e-05,
      "loss": 0.0,
      "step": 1810
    },
    {
      "epoch": 12.942857142857143,
      "grad_norm": 0.02602284960448742,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 0.0001,
      "step": 1812
    },
    {
      "epoch": 12.957142857142857,
      "grad_norm": 0.02764320746064186,
      "learning_rate": 2.4171428571428572e-05,
      "loss": 0.0,
      "step": 1814
    },
    {
      "epoch": 12.971428571428572,
      "grad_norm": 0.047885168343782425,
      "learning_rate": 2.4142857142857146e-05,
      "loss": 0.0,
      "step": 1816
    },
    {
      "epoch": 12.985714285714286,
      "grad_norm": 0.021367743611335754,
      "learning_rate": 2.4114285714285713e-05,
      "loss": 0.0001,
      "step": 1818
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.04509890824556351,
      "learning_rate": 2.4085714285714286e-05,
      "loss": 0.0,
      "step": 1820
    },
    {
      "epoch": 13.014285714285714,
      "grad_norm": 0.04008837789297104,
      "learning_rate": 2.405714285714286e-05,
      "loss": 0.0001,
      "step": 1822
    },
    {
      "epoch": 13.028571428571428,
      "grad_norm": 0.025188950821757317,
      "learning_rate": 2.402857142857143e-05,
      "loss": 0.0001,
      "step": 1824
    },
    {
      "epoch": 13.042857142857143,
      "grad_norm": 0.022955061867833138,
      "learning_rate": 2.4e-05,
      "loss": 0.0,
      "step": 1826
    },
    {
      "epoch": 13.057142857142857,
      "grad_norm": 0.03688299283385277,
      "learning_rate": 2.397142857142857e-05,
      "loss": 0.0,
      "step": 1828
    },
    {
      "epoch": 13.071428571428571,
      "grad_norm": 0.049139030277729034,
      "learning_rate": 2.3942857142857144e-05,
      "loss": 0.0,
      "step": 1830
    },
    {
      "epoch": 13.085714285714285,
      "grad_norm": 0.024254409596323967,
      "learning_rate": 2.3914285714285715e-05,
      "loss": 0.0,
      "step": 1832
    },
    {
      "epoch": 13.1,
      "grad_norm": 0.04229545220732689,
      "learning_rate": 2.3885714285714285e-05,
      "loss": 0.0001,
      "step": 1834
    },
    {
      "epoch": 13.114285714285714,
      "grad_norm": 0.01758032850921154,
      "learning_rate": 2.385714285714286e-05,
      "loss": 0.0001,
      "step": 1836
    },
    {
      "epoch": 13.128571428571428,
      "grad_norm": 0.02847130037844181,
      "learning_rate": 2.3828571428571432e-05,
      "loss": 0.0,
      "step": 1838
    },
    {
      "epoch": 13.142857142857142,
      "grad_norm": 0.024319184944033623,
      "learning_rate": 2.38e-05,
      "loss": 0.0001,
      "step": 1840
    },
    {
      "epoch": 13.157142857142857,
      "grad_norm": 0.020038336515426636,
      "learning_rate": 2.3771428571428573e-05,
      "loss": 0.0,
      "step": 1842
    },
    {
      "epoch": 13.17142857142857,
      "grad_norm": 0.014049208723008633,
      "learning_rate": 2.3742857142857143e-05,
      "loss": 0.0001,
      "step": 1844
    },
    {
      "epoch": 13.185714285714285,
      "grad_norm": 0.03469834476709366,
      "learning_rate": 2.3714285714285717e-05,
      "loss": 0.0001,
      "step": 1846
    },
    {
      "epoch": 13.2,
      "grad_norm": 0.031494200229644775,
      "learning_rate": 2.3685714285714287e-05,
      "loss": 0.0004,
      "step": 1848
    },
    {
      "epoch": 13.214285714285714,
      "grad_norm": 0.020844651386141777,
      "learning_rate": 2.3657142857142857e-05,
      "loss": 0.0,
      "step": 1850
    },
    {
      "epoch": 13.228571428571428,
      "grad_norm": 0.03273237496614456,
      "learning_rate": 2.362857142857143e-05,
      "loss": 0.0,
      "step": 1852
    },
    {
      "epoch": 13.242857142857142,
      "grad_norm": 0.04732869192957878,
      "learning_rate": 2.36e-05,
      "loss": 0.0001,
      "step": 1854
    },
    {
      "epoch": 13.257142857142856,
      "grad_norm": 0.031163636595010757,
      "learning_rate": 2.357142857142857e-05,
      "loss": 0.0,
      "step": 1856
    },
    {
      "epoch": 13.271428571428572,
      "grad_norm": 0.025072259828448296,
      "learning_rate": 2.3542857142857145e-05,
      "loss": 0.0,
      "step": 1858
    },
    {
      "epoch": 13.285714285714286,
      "grad_norm": 0.026404626667499542,
      "learning_rate": 2.3514285714285715e-05,
      "loss": 0.0,
      "step": 1860
    },
    {
      "epoch": 13.3,
      "grad_norm": 0.031004751101136208,
      "learning_rate": 2.3485714285714285e-05,
      "loss": 0.0,
      "step": 1862
    },
    {
      "epoch": 13.314285714285715,
      "grad_norm": 0.03919563069939613,
      "learning_rate": 2.345714285714286e-05,
      "loss": 0.0,
      "step": 1864
    },
    {
      "epoch": 13.32857142857143,
      "grad_norm": 0.03380824252963066,
      "learning_rate": 2.342857142857143e-05,
      "loss": 0.0,
      "step": 1866
    },
    {
      "epoch": 13.342857142857143,
      "grad_norm": 0.0357903428375721,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 0.0,
      "step": 1868
    },
    {
      "epoch": 13.357142857142858,
      "grad_norm": 0.15549321472644806,
      "learning_rate": 2.3371428571428573e-05,
      "loss": 0.0001,
      "step": 1870
    },
    {
      "epoch": 13.371428571428572,
      "grad_norm": 0.01882803998887539,
      "learning_rate": 2.3342857142857143e-05,
      "loss": 0.0,
      "step": 1872
    },
    {
      "epoch": 13.385714285714286,
      "grad_norm": 0.029409820213913918,
      "learning_rate": 2.3314285714285717e-05,
      "loss": 0.0001,
      "step": 1874
    },
    {
      "epoch": 13.4,
      "grad_norm": 0.062140628695487976,
      "learning_rate": 2.3285714285714287e-05,
      "loss": 0.0001,
      "step": 1876
    },
    {
      "epoch": 13.414285714285715,
      "grad_norm": 0.032102711498737335,
      "learning_rate": 2.3257142857142858e-05,
      "loss": 0.0,
      "step": 1878
    },
    {
      "epoch": 13.428571428571429,
      "grad_norm": 0.024121807888150215,
      "learning_rate": 2.322857142857143e-05,
      "loss": 0.0,
      "step": 1880
    },
    {
      "epoch": 13.442857142857143,
      "grad_norm": 0.025511927902698517,
      "learning_rate": 2.32e-05,
      "loss": 0.0,
      "step": 1882
    },
    {
      "epoch": 13.457142857142857,
      "grad_norm": 0.024276738986372948,
      "learning_rate": 2.3171428571428572e-05,
      "loss": 0.0001,
      "step": 1884
    },
    {
      "epoch": 13.471428571428572,
      "grad_norm": 0.0176077913492918,
      "learning_rate": 2.3142857142857145e-05,
      "loss": 0.0,
      "step": 1886
    },
    {
      "epoch": 13.485714285714286,
      "grad_norm": 0.01912110671401024,
      "learning_rate": 2.3114285714285716e-05,
      "loss": 0.0,
      "step": 1888
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.07140891999006271,
      "learning_rate": 2.3085714285714286e-05,
      "loss": 0.0,
      "step": 1890
    },
    {
      "epoch": 13.514285714285714,
      "grad_norm": 0.024253057315945625,
      "learning_rate": 2.3057142857142856e-05,
      "loss": 0.0,
      "step": 1892
    },
    {
      "epoch": 13.528571428571428,
      "grad_norm": 0.02041744627058506,
      "learning_rate": 2.302857142857143e-05,
      "loss": 0.0,
      "step": 1894
    },
    {
      "epoch": 13.542857142857143,
      "grad_norm": 0.017719868570566177,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0,
      "step": 1896
    },
    {
      "epoch": 13.557142857142857,
      "grad_norm": 3.6992383003234863,
      "learning_rate": 2.297142857142857e-05,
      "loss": 0.0014,
      "step": 1898
    },
    {
      "epoch": 13.571428571428571,
      "grad_norm": 0.023393968120217323,
      "learning_rate": 2.2942857142857144e-05,
      "loss": 0.0,
      "step": 1900
    },
    {
      "epoch": 13.585714285714285,
      "grad_norm": 0.038531526923179626,
      "learning_rate": 2.2914285714285718e-05,
      "loss": 0.0,
      "step": 1902
    },
    {
      "epoch": 13.6,
      "grad_norm": 0.6255476474761963,
      "learning_rate": 2.2885714285714288e-05,
      "loss": 0.0005,
      "step": 1904
    },
    {
      "epoch": 13.614285714285714,
      "grad_norm": 0.01934184320271015,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 0.0,
      "step": 1906
    },
    {
      "epoch": 13.628571428571428,
      "grad_norm": 0.03546635061502457,
      "learning_rate": 2.2828571428571428e-05,
      "loss": 0.0,
      "step": 1908
    },
    {
      "epoch": 13.642857142857142,
      "grad_norm": 0.039970070123672485,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.0,
      "step": 1910
    },
    {
      "epoch": 13.657142857142857,
      "grad_norm": 0.03276931867003441,
      "learning_rate": 2.2771428571428572e-05,
      "loss": 0.0001,
      "step": 1912
    },
    {
      "epoch": 13.67142857142857,
      "grad_norm": 0.09287718683481216,
      "learning_rate": 2.2742857142857142e-05,
      "loss": 0.0001,
      "step": 1914
    },
    {
      "epoch": 13.685714285714285,
      "grad_norm": 0.03928540647029877,
      "learning_rate": 2.2714285714285716e-05,
      "loss": 0.0,
      "step": 1916
    },
    {
      "epoch": 13.7,
      "grad_norm": 0.03326030075550079,
      "learning_rate": 2.2685714285714286e-05,
      "loss": 0.0,
      "step": 1918
    },
    {
      "epoch": 13.714285714285714,
      "grad_norm": 0.05058735981583595,
      "learning_rate": 2.2657142857142857e-05,
      "loss": 0.0,
      "step": 1920
    },
    {
      "epoch": 13.728571428571428,
      "grad_norm": 0.02690325677394867,
      "learning_rate": 2.262857142857143e-05,
      "loss": 0.0001,
      "step": 1922
    },
    {
      "epoch": 13.742857142857144,
      "grad_norm": 0.014542859978973866,
      "learning_rate": 2.26e-05,
      "loss": 0.0,
      "step": 1924
    },
    {
      "epoch": 13.757142857142856,
      "grad_norm": 0.018227742984890938,
      "learning_rate": 2.257142857142857e-05,
      "loss": 0.0,
      "step": 1926
    },
    {
      "epoch": 13.771428571428572,
      "grad_norm": 0.030280089005827904,
      "learning_rate": 2.2542857142857144e-05,
      "loss": 0.0,
      "step": 1928
    },
    {
      "epoch": 13.785714285714286,
      "grad_norm": 0.017135068774223328,
      "learning_rate": 2.2514285714285715e-05,
      "loss": 0.0,
      "step": 1930
    },
    {
      "epoch": 13.8,
      "grad_norm": 0.03348409757018089,
      "learning_rate": 2.2485714285714288e-05,
      "loss": 0.0,
      "step": 1932
    },
    {
      "epoch": 13.814285714285715,
      "grad_norm": 0.02847999706864357,
      "learning_rate": 2.245714285714286e-05,
      "loss": 0.0,
      "step": 1934
    },
    {
      "epoch": 13.82857142857143,
      "grad_norm": 0.017266325652599335,
      "learning_rate": 2.242857142857143e-05,
      "loss": 0.0,
      "step": 1936
    },
    {
      "epoch": 13.842857142857143,
      "grad_norm": 0.041640713810920715,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 0.0,
      "step": 1938
    },
    {
      "epoch": 13.857142857142858,
      "grad_norm": 0.0409974530339241,
      "learning_rate": 2.2371428571428573e-05,
      "loss": 0.0,
      "step": 1940
    },
    {
      "epoch": 13.871428571428572,
      "grad_norm": 0.017253201454877853,
      "learning_rate": 2.2342857142857143e-05,
      "loss": 0.0,
      "step": 1942
    },
    {
      "epoch": 13.885714285714286,
      "grad_norm": 0.03628621622920036,
      "learning_rate": 2.2314285714285717e-05,
      "loss": 0.0001,
      "step": 1944
    },
    {
      "epoch": 13.9,
      "grad_norm": 0.02675049751996994,
      "learning_rate": 2.2285714285714287e-05,
      "loss": 0.0001,
      "step": 1946
    },
    {
      "epoch": 13.914285714285715,
      "grad_norm": 0.011986910365521908,
      "learning_rate": 2.2257142857142857e-05,
      "loss": 0.0,
      "step": 1948
    },
    {
      "epoch": 13.928571428571429,
      "grad_norm": 0.18352575600147247,
      "learning_rate": 2.222857142857143e-05,
      "loss": 0.0002,
      "step": 1950
    },
    {
      "epoch": 13.942857142857143,
      "grad_norm": 0.027761423960328102,
      "learning_rate": 2.22e-05,
      "loss": 0.0,
      "step": 1952
    },
    {
      "epoch": 13.957142857142857,
      "grad_norm": 0.02896064706146717,
      "learning_rate": 2.2171428571428575e-05,
      "loss": 0.0,
      "step": 1954
    },
    {
      "epoch": 13.971428571428572,
      "grad_norm": 0.022754551842808723,
      "learning_rate": 2.214285714285714e-05,
      "loss": 0.0,
      "step": 1956
    },
    {
      "epoch": 13.985714285714286,
      "grad_norm": 0.03855689987540245,
      "learning_rate": 2.2114285714285715e-05,
      "loss": 0.0,
      "step": 1958
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.02150145173072815,
      "learning_rate": 2.208571428571429e-05,
      "loss": 0.0116,
      "step": 1960
    },
    {
      "epoch": 14.014285714285714,
      "grad_norm": 0.026495780795812607,
      "learning_rate": 2.205714285714286e-05,
      "loss": 0.0,
      "step": 1962
    },
    {
      "epoch": 14.028571428571428,
      "grad_norm": 0.024692615494132042,
      "learning_rate": 2.202857142857143e-05,
      "loss": 0.0,
      "step": 1964
    },
    {
      "epoch": 14.042857142857143,
      "grad_norm": 0.04232462868094444,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0001,
      "step": 1966
    },
    {
      "epoch": 14.057142857142857,
      "grad_norm": 0.024735884740948677,
      "learning_rate": 2.1971428571428573e-05,
      "loss": 0.0,
      "step": 1968
    },
    {
      "epoch": 14.071428571428571,
      "grad_norm": 0.024915045127272606,
      "learning_rate": 2.1942857142857143e-05,
      "loss": 0.0,
      "step": 1970
    },
    {
      "epoch": 14.085714285714285,
      "grad_norm": 0.019573474302887917,
      "learning_rate": 2.1914285714285714e-05,
      "loss": 0.0,
      "step": 1972
    },
    {
      "epoch": 14.1,
      "grad_norm": 0.018818072974681854,
      "learning_rate": 2.1885714285714287e-05,
      "loss": 0.0,
      "step": 1974
    },
    {
      "epoch": 14.114285714285714,
      "grad_norm": 0.03214140981435776,
      "learning_rate": 2.185714285714286e-05,
      "loss": 0.0,
      "step": 1976
    },
    {
      "epoch": 14.128571428571428,
      "grad_norm": 0.02714572660624981,
      "learning_rate": 2.1828571428571428e-05,
      "loss": 0.0,
      "step": 1978
    },
    {
      "epoch": 14.142857142857142,
      "grad_norm": 0.028416719287633896,
      "learning_rate": 2.18e-05,
      "loss": 0.0,
      "step": 1980
    },
    {
      "epoch": 14.157142857142857,
      "grad_norm": 0.019560668617486954,
      "learning_rate": 2.177142857142857e-05,
      "loss": 0.0,
      "step": 1982
    },
    {
      "epoch": 14.17142857142857,
      "grad_norm": 0.018270589411258698,
      "learning_rate": 2.1742857142857142e-05,
      "loss": 0.0,
      "step": 1984
    },
    {
      "epoch": 14.185714285714285,
      "grad_norm": 0.05432342365384102,
      "learning_rate": 2.1714285714285715e-05,
      "loss": 0.0,
      "step": 1986
    },
    {
      "epoch": 14.2,
      "grad_norm": 0.046170368790626526,
      "learning_rate": 2.1685714285714286e-05,
      "loss": 0.0,
      "step": 1988
    },
    {
      "epoch": 14.214285714285714,
      "grad_norm": 0.025380920618772507,
      "learning_rate": 2.165714285714286e-05,
      "loss": 0.0,
      "step": 1990
    },
    {
      "epoch": 14.228571428571428,
      "grad_norm": 0.023348642513155937,
      "learning_rate": 2.162857142857143e-05,
      "loss": 0.0001,
      "step": 1992
    },
    {
      "epoch": 14.242857142857142,
      "grad_norm": 0.031170595437288284,
      "learning_rate": 2.16e-05,
      "loss": 0.0,
      "step": 1994
    },
    {
      "epoch": 14.257142857142856,
      "grad_norm": 0.025329433381557465,
      "learning_rate": 2.1571428571428574e-05,
      "loss": 0.0,
      "step": 1996
    },
    {
      "epoch": 14.271428571428572,
      "grad_norm": 0.018594369292259216,
      "learning_rate": 2.1542857142857144e-05,
      "loss": 0.0,
      "step": 1998
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.04020099714398384,
      "learning_rate": 2.1514285714285714e-05,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 14.285714285714286,
      "eval_cer": 0.008488964346349746,
      "eval_loss": 0.03180404379963875,
      "eval_runtime": 9.7555,
      "eval_samples_per_second": 28.599,
      "eval_steps_per_second": 3.588,
      "step": 2000
    },
    {
      "epoch": 14.3,
      "grad_norm": 0.029867306351661682,
      "learning_rate": 2.1485714285714288e-05,
      "loss": 0.0,
      "step": 2002
    },
    {
      "epoch": 14.314285714285715,
      "grad_norm": 0.03707939758896828,
      "learning_rate": 2.1457142857142858e-05,
      "loss": 0.0,
      "step": 2004
    },
    {
      "epoch": 14.32857142857143,
      "grad_norm": 0.038221899420022964,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 0.0001,
      "step": 2006
    },
    {
      "epoch": 14.342857142857143,
      "grad_norm": 1.4255119562149048,
      "learning_rate": 2.1400000000000002e-05,
      "loss": 0.0009,
      "step": 2008
    },
    {
      "epoch": 14.357142857142858,
      "grad_norm": 0.031154466792941093,
      "learning_rate": 2.1371428571428572e-05,
      "loss": 0.0,
      "step": 2010
    },
    {
      "epoch": 14.371428571428572,
      "grad_norm": 0.03550465777516365,
      "learning_rate": 2.1342857142857146e-05,
      "loss": 0.0,
      "step": 2012
    },
    {
      "epoch": 14.385714285714286,
      "grad_norm": 0.0388253815472126,
      "learning_rate": 2.1314285714285716e-05,
      "loss": 0.0,
      "step": 2014
    },
    {
      "epoch": 14.4,
      "grad_norm": 0.020835675299167633,
      "learning_rate": 2.1285714285714286e-05,
      "loss": 0.0001,
      "step": 2016
    },
    {
      "epoch": 14.414285714285715,
      "grad_norm": 0.024691225960850716,
      "learning_rate": 2.125714285714286e-05,
      "loss": 0.0,
      "step": 2018
    },
    {
      "epoch": 14.428571428571429,
      "grad_norm": 0.02348422259092331,
      "learning_rate": 2.1228571428571427e-05,
      "loss": 0.0,
      "step": 2020
    },
    {
      "epoch": 14.442857142857143,
      "grad_norm": 0.03959224000573158,
      "learning_rate": 2.12e-05,
      "loss": 0.0001,
      "step": 2022
    },
    {
      "epoch": 14.457142857142857,
      "grad_norm": 0.015783065930008888,
      "learning_rate": 2.1171428571428574e-05,
      "loss": 0.0001,
      "step": 2024
    },
    {
      "epoch": 14.471428571428572,
      "grad_norm": 0.03059711493551731,
      "learning_rate": 2.1142857142857144e-05,
      "loss": 0.062,
      "step": 2026
    },
    {
      "epoch": 14.485714285714286,
      "grad_norm": 0.031913526356220245,
      "learning_rate": 2.1114285714285714e-05,
      "loss": 0.0,
      "step": 2028
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.042754169553518295,
      "learning_rate": 2.1085714285714288e-05,
      "loss": 0.0,
      "step": 2030
    },
    {
      "epoch": 14.514285714285714,
      "grad_norm": 0.03597726672887802,
      "learning_rate": 2.105714285714286e-05,
      "loss": 0.1105,
      "step": 2032
    },
    {
      "epoch": 14.528571428571428,
      "grad_norm": 0.0237093735486269,
      "learning_rate": 2.1028571428571432e-05,
      "loss": 0.0,
      "step": 2034
    },
    {
      "epoch": 14.542857142857143,
      "grad_norm": 0.02652154304087162,
      "learning_rate": 2.1e-05,
      "loss": 0.0,
      "step": 2036
    },
    {
      "epoch": 14.557142857142857,
      "grad_norm": 0.0305835772305727,
      "learning_rate": 2.0971428571428572e-05,
      "loss": 0.0,
      "step": 2038
    },
    {
      "epoch": 14.571428571428571,
      "grad_norm": 0.04384273663163185,
      "learning_rate": 2.0942857142857146e-05,
      "loss": 0.0021,
      "step": 2040
    },
    {
      "epoch": 14.585714285714285,
      "grad_norm": 0.03973887488245964,
      "learning_rate": 2.0914285714285713e-05,
      "loss": 0.0001,
      "step": 2042
    },
    {
      "epoch": 14.6,
      "grad_norm": 0.6858567595481873,
      "learning_rate": 2.0885714285714287e-05,
      "loss": 0.0005,
      "step": 2044
    },
    {
      "epoch": 14.614285714285714,
      "grad_norm": 42.382572174072266,
      "learning_rate": 2.0857142857142857e-05,
      "loss": 0.1603,
      "step": 2046
    },
    {
      "epoch": 14.628571428571428,
      "grad_norm": 87.11643981933594,
      "learning_rate": 2.082857142857143e-05,
      "loss": 0.0672,
      "step": 2048
    },
    {
      "epoch": 14.642857142857142,
      "grad_norm": 0.038096003234386444,
      "learning_rate": 2.08e-05,
      "loss": 0.0,
      "step": 2050
    },
    {
      "epoch": 14.657142857142857,
      "grad_norm": 0.06658008694648743,
      "learning_rate": 2.077142857142857e-05,
      "loss": 0.0001,
      "step": 2052
    },
    {
      "epoch": 14.67142857142857,
      "grad_norm": 0.02689102105796337,
      "learning_rate": 2.0742857142857145e-05,
      "loss": 0.0002,
      "step": 2054
    },
    {
      "epoch": 14.685714285714285,
      "grad_norm": 0.03775482252240181,
      "learning_rate": 2.0714285714285718e-05,
      "loss": 0.0001,
      "step": 2056
    },
    {
      "epoch": 14.7,
      "grad_norm": 0.034636445343494415,
      "learning_rate": 2.0685714285714285e-05,
      "loss": 0.0001,
      "step": 2058
    },
    {
      "epoch": 14.714285714285714,
      "grad_norm": 0.2901218831539154,
      "learning_rate": 2.065714285714286e-05,
      "loss": 0.0005,
      "step": 2060
    },
    {
      "epoch": 14.728571428571428,
      "grad_norm": 0.05188317969441414,
      "learning_rate": 2.062857142857143e-05,
      "loss": 0.0001,
      "step": 2062
    },
    {
      "epoch": 14.742857142857144,
      "grad_norm": 0.031779300421476364,
      "learning_rate": 2.06e-05,
      "loss": 0.0002,
      "step": 2064
    },
    {
      "epoch": 14.757142857142856,
      "grad_norm": 0.02291179448366165,
      "learning_rate": 2.0571428571428573e-05,
      "loss": 0.0001,
      "step": 2066
    },
    {
      "epoch": 14.771428571428572,
      "grad_norm": 0.030023304745554924,
      "learning_rate": 2.0542857142857143e-05,
      "loss": 0.0001,
      "step": 2068
    },
    {
      "epoch": 14.785714285714286,
      "grad_norm": 0.0382075235247612,
      "learning_rate": 2.0514285714285717e-05,
      "loss": 0.0,
      "step": 2070
    },
    {
      "epoch": 14.8,
      "grad_norm": 20.50564193725586,
      "learning_rate": 2.0485714285714287e-05,
      "loss": 0.1819,
      "step": 2072
    },
    {
      "epoch": 14.814285714285715,
      "grad_norm": 0.20547132194042206,
      "learning_rate": 2.0457142857142857e-05,
      "loss": 0.0001,
      "step": 2074
    },
    {
      "epoch": 14.82857142857143,
      "grad_norm": 0.1285354048013687,
      "learning_rate": 2.042857142857143e-05,
      "loss": 0.0002,
      "step": 2076
    },
    {
      "epoch": 14.842857142857143,
      "grad_norm": 0.0308724045753479,
      "learning_rate": 2.04e-05,
      "loss": 0.0001,
      "step": 2078
    },
    {
      "epoch": 14.857142857142858,
      "grad_norm": 0.029847947880625725,
      "learning_rate": 2.037142857142857e-05,
      "loss": 0.0002,
      "step": 2080
    },
    {
      "epoch": 14.871428571428572,
      "grad_norm": 0.026817509904503822,
      "learning_rate": 2.0342857142857145e-05,
      "loss": 0.0001,
      "step": 2082
    },
    {
      "epoch": 14.885714285714286,
      "grad_norm": 0.04707065969705582,
      "learning_rate": 2.0314285714285715e-05,
      "loss": 0.0001,
      "step": 2084
    },
    {
      "epoch": 14.9,
      "grad_norm": 0.057645946741104126,
      "learning_rate": 2.0285714285714286e-05,
      "loss": 0.0001,
      "step": 2086
    },
    {
      "epoch": 14.914285714285715,
      "grad_norm": 0.026545513421297073,
      "learning_rate": 2.025714285714286e-05,
      "loss": 0.0021,
      "step": 2088
    },
    {
      "epoch": 14.928571428571429,
      "grad_norm": 0.024137867614626884,
      "learning_rate": 2.022857142857143e-05,
      "loss": 0.0,
      "step": 2090
    },
    {
      "epoch": 14.942857142857143,
      "grad_norm": 0.029103271663188934,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 0.0,
      "step": 2092
    },
    {
      "epoch": 14.957142857142857,
      "grad_norm": 0.019611090421676636,
      "learning_rate": 2.0171428571428573e-05,
      "loss": 0.0002,
      "step": 2094
    },
    {
      "epoch": 14.971428571428572,
      "grad_norm": 0.03231516107916832,
      "learning_rate": 2.0142857142857144e-05,
      "loss": 0.0002,
      "step": 2096
    },
    {
      "epoch": 14.985714285714286,
      "grad_norm": 1.0348849296569824,
      "learning_rate": 2.0114285714285717e-05,
      "loss": 0.0026,
      "step": 2098
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.009784174151718616,
      "learning_rate": 2.0085714285714284e-05,
      "loss": 0.0001,
      "step": 2100
    },
    {
      "epoch": 15.014285714285714,
      "grad_norm": 0.02042611502110958,
      "learning_rate": 2.0057142857142858e-05,
      "loss": 0.001,
      "step": 2102
    },
    {
      "epoch": 15.028571428571428,
      "grad_norm": 0.039739012718200684,
      "learning_rate": 2.002857142857143e-05,
      "loss": 0.0001,
      "step": 2104
    },
    {
      "epoch": 15.042857142857143,
      "grad_norm": 0.02160526253283024,
      "learning_rate": 2e-05,
      "loss": 0.0,
      "step": 2106
    },
    {
      "epoch": 15.057142857142857,
      "grad_norm": 0.034724198281764984,
      "learning_rate": 1.9971428571428572e-05,
      "loss": 0.0002,
      "step": 2108
    },
    {
      "epoch": 15.071428571428571,
      "grad_norm": 0.03299969062209129,
      "learning_rate": 1.9942857142857142e-05,
      "loss": 0.0001,
      "step": 2110
    },
    {
      "epoch": 15.085714285714285,
      "grad_norm": 0.038947779685258865,
      "learning_rate": 1.9914285714285716e-05,
      "loss": 0.0001,
      "step": 2112
    },
    {
      "epoch": 15.1,
      "grad_norm": 0.035745542496442795,
      "learning_rate": 1.9885714285714286e-05,
      "loss": 0.0001,
      "step": 2114
    },
    {
      "epoch": 15.114285714285714,
      "grad_norm": 0.0456506609916687,
      "learning_rate": 1.9857142857142856e-05,
      "loss": 0.0002,
      "step": 2116
    },
    {
      "epoch": 15.128571428571428,
      "grad_norm": 0.05046030133962631,
      "learning_rate": 1.982857142857143e-05,
      "loss": 0.0001,
      "step": 2118
    },
    {
      "epoch": 15.142857142857142,
      "grad_norm": 0.03713081777095795,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 0.0001,
      "step": 2120
    },
    {
      "epoch": 15.157142857142857,
      "grad_norm": 0.026380743831396103,
      "learning_rate": 1.977142857142857e-05,
      "loss": 0.0001,
      "step": 2122
    },
    {
      "epoch": 15.17142857142857,
      "grad_norm": 0.03369130566716194,
      "learning_rate": 1.9742857142857144e-05,
      "loss": 0.0001,
      "step": 2124
    },
    {
      "epoch": 15.185714285714285,
      "grad_norm": 0.020701993256807327,
      "learning_rate": 1.9714285714285714e-05,
      "loss": 0.0001,
      "step": 2126
    },
    {
      "epoch": 15.2,
      "grad_norm": 0.03511622175574303,
      "learning_rate": 1.9685714285714288e-05,
      "loss": 0.0001,
      "step": 2128
    },
    {
      "epoch": 15.214285714285714,
      "grad_norm": 0.043595269322395325,
      "learning_rate": 1.9657142857142858e-05,
      "loss": 0.0001,
      "step": 2130
    },
    {
      "epoch": 15.228571428571428,
      "grad_norm": 0.04596496373414993,
      "learning_rate": 1.962857142857143e-05,
      "loss": 0.0001,
      "step": 2132
    },
    {
      "epoch": 15.242857142857142,
      "grad_norm": 0.01989131234586239,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0,
      "step": 2134
    },
    {
      "epoch": 15.257142857142856,
      "grad_norm": 0.08666272461414337,
      "learning_rate": 1.9571428571428572e-05,
      "loss": 0.0001,
      "step": 2136
    },
    {
      "epoch": 15.271428571428572,
      "grad_norm": 0.05331048369407654,
      "learning_rate": 1.9542857142857143e-05,
      "loss": 0.0001,
      "step": 2138
    },
    {
      "epoch": 15.285714285714286,
      "grad_norm": 0.031442780047655106,
      "learning_rate": 1.9514285714285716e-05,
      "loss": 0.0,
      "step": 2140
    },
    {
      "epoch": 15.3,
      "grad_norm": 0.02536492981016636,
      "learning_rate": 1.9485714285714286e-05,
      "loss": 0.0,
      "step": 2142
    },
    {
      "epoch": 15.314285714285715,
      "grad_norm": 0.016074523329734802,
      "learning_rate": 1.9457142857142857e-05,
      "loss": 0.0,
      "step": 2144
    },
    {
      "epoch": 15.32857142857143,
      "grad_norm": 0.03440941497683525,
      "learning_rate": 1.942857142857143e-05,
      "loss": 0.0001,
      "step": 2146
    },
    {
      "epoch": 15.342857142857143,
      "grad_norm": 0.030230123549699783,
      "learning_rate": 1.94e-05,
      "loss": 0.0,
      "step": 2148
    },
    {
      "epoch": 15.357142857142858,
      "grad_norm": 0.03557676449418068,
      "learning_rate": 1.9371428571428574e-05,
      "loss": 0.0001,
      "step": 2150
    },
    {
      "epoch": 15.371428571428572,
      "grad_norm": 0.028959015384316444,
      "learning_rate": 1.9342857142857144e-05,
      "loss": 0.0001,
      "step": 2152
    },
    {
      "epoch": 15.385714285714286,
      "grad_norm": 0.015359502285718918,
      "learning_rate": 1.9314285714285715e-05,
      "loss": 0.0,
      "step": 2154
    },
    {
      "epoch": 15.4,
      "grad_norm": 0.020946532487869263,
      "learning_rate": 1.928571428571429e-05,
      "loss": 0.0,
      "step": 2156
    },
    {
      "epoch": 15.414285714285715,
      "grad_norm": 0.03028465248644352,
      "learning_rate": 1.9257142857142855e-05,
      "loss": 0.0001,
      "step": 2158
    },
    {
      "epoch": 15.428571428571429,
      "grad_norm": 0.03538275882601738,
      "learning_rate": 1.922857142857143e-05,
      "loss": 0.0001,
      "step": 2160
    },
    {
      "epoch": 15.442857142857143,
      "grad_norm": 0.06454341113567352,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0001,
      "step": 2162
    },
    {
      "epoch": 15.457142857142857,
      "grad_norm": 0.02652362361550331,
      "learning_rate": 1.9171428571428573e-05,
      "loss": 0.0,
      "step": 2164
    },
    {
      "epoch": 15.471428571428572,
      "grad_norm": 0.033365294337272644,
      "learning_rate": 1.9142857142857143e-05,
      "loss": 0.0001,
      "step": 2166
    },
    {
      "epoch": 15.485714285714286,
      "grad_norm": 0.018040498718619347,
      "learning_rate": 1.9114285714285717e-05,
      "loss": 0.0001,
      "step": 2168
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.017600497230887413,
      "learning_rate": 1.9085714285714287e-05,
      "loss": 0.0,
      "step": 2170
    },
    {
      "epoch": 15.514285714285714,
      "grad_norm": 0.0430721752345562,
      "learning_rate": 1.9057142857142857e-05,
      "loss": 0.0001,
      "step": 2172
    },
    {
      "epoch": 15.528571428571428,
      "grad_norm": 0.42344871163368225,
      "learning_rate": 1.9028571428571427e-05,
      "loss": 0.0002,
      "step": 2174
    },
    {
      "epoch": 15.542857142857143,
      "grad_norm": 0.03980286419391632,
      "learning_rate": 1.9e-05,
      "loss": 0.0001,
      "step": 2176
    },
    {
      "epoch": 15.557142857142857,
      "grad_norm": 0.05715962499380112,
      "learning_rate": 1.8971428571428575e-05,
      "loss": 0.0001,
      "step": 2178
    },
    {
      "epoch": 15.571428571428571,
      "grad_norm": 0.02506534941494465,
      "learning_rate": 1.894285714285714e-05,
      "loss": 0.0,
      "step": 2180
    },
    {
      "epoch": 15.585714285714285,
      "grad_norm": 0.03623698279261589,
      "learning_rate": 1.8914285714285715e-05,
      "loss": 0.0001,
      "step": 2182
    },
    {
      "epoch": 15.6,
      "grad_norm": 77.04959869384766,
      "learning_rate": 1.888571428571429e-05,
      "loss": 0.0665,
      "step": 2184
    },
    {
      "epoch": 15.614285714285714,
      "grad_norm": 0.038822196424007416,
      "learning_rate": 1.885714285714286e-05,
      "loss": 0.0001,
      "step": 2186
    },
    {
      "epoch": 15.628571428571428,
      "grad_norm": 0.031966883689165115,
      "learning_rate": 1.882857142857143e-05,
      "loss": 0.0,
      "step": 2188
    },
    {
      "epoch": 15.642857142857142,
      "grad_norm": 0.02783985063433647,
      "learning_rate": 1.88e-05,
      "loss": 0.0001,
      "step": 2190
    },
    {
      "epoch": 15.657142857142857,
      "grad_norm": 0.12858499586582184,
      "learning_rate": 1.8771428571428573e-05,
      "loss": 0.0002,
      "step": 2192
    },
    {
      "epoch": 15.67142857142857,
      "grad_norm": 0.1307286024093628,
      "learning_rate": 1.8742857142857143e-05,
      "loss": 0.0002,
      "step": 2194
    },
    {
      "epoch": 15.685714285714285,
      "grad_norm": 0.023587841540575027,
      "learning_rate": 1.8714285714285714e-05,
      "loss": 0.0,
      "step": 2196
    },
    {
      "epoch": 15.7,
      "grad_norm": 0.013755982741713524,
      "learning_rate": 1.8685714285714287e-05,
      "loss": 0.0,
      "step": 2198
    },
    {
      "epoch": 15.714285714285714,
      "grad_norm": 0.02307436615228653,
      "learning_rate": 1.8657142857142858e-05,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 15.714285714285714,
      "eval_cer": 0.008488964346349746,
      "eval_loss": 0.023534605279564857,
      "eval_runtime": 10.1695,
      "eval_samples_per_second": 27.435,
      "eval_steps_per_second": 3.442,
      "step": 2200
    },
    {
      "epoch": 15.728571428571428,
      "grad_norm": 0.024437135085463524,
      "learning_rate": 1.8628571428571428e-05,
      "loss": 0.0002,
      "step": 2202
    },
    {
      "epoch": 15.742857142857144,
      "grad_norm": 0.03900635242462158,
      "learning_rate": 1.86e-05,
      "loss": 0.0002,
      "step": 2204
    },
    {
      "epoch": 15.757142857142856,
      "grad_norm": 0.01779060624539852,
      "learning_rate": 1.8571428571428572e-05,
      "loss": 0.0,
      "step": 2206
    },
    {
      "epoch": 15.771428571428572,
      "grad_norm": 0.029746463522315025,
      "learning_rate": 1.8542857142857142e-05,
      "loss": 0.0001,
      "step": 2208
    },
    {
      "epoch": 15.785714285714286,
      "grad_norm": 0.021997598931193352,
      "learning_rate": 1.8514285714285716e-05,
      "loss": 0.0,
      "step": 2210
    },
    {
      "epoch": 15.8,
      "grad_norm": 0.04290664568543434,
      "learning_rate": 1.8485714285714286e-05,
      "loss": 0.0001,
      "step": 2212
    },
    {
      "epoch": 15.814285714285715,
      "grad_norm": 0.026743900030851364,
      "learning_rate": 1.845714285714286e-05,
      "loss": 0.0,
      "step": 2214
    },
    {
      "epoch": 15.82857142857143,
      "grad_norm": 0.053255803883075714,
      "learning_rate": 1.842857142857143e-05,
      "loss": 0.0,
      "step": 2216
    },
    {
      "epoch": 15.842857142857143,
      "grad_norm": 0.03303242474794388,
      "learning_rate": 1.84e-05,
      "loss": 0.0001,
      "step": 2218
    },
    {
      "epoch": 15.857142857142858,
      "grad_norm": 0.061267219483852386,
      "learning_rate": 1.8371428571428574e-05,
      "loss": 0.0,
      "step": 2220
    },
    {
      "epoch": 15.871428571428572,
      "grad_norm": 0.019843166694045067,
      "learning_rate": 1.8342857142857144e-05,
      "loss": 0.0002,
      "step": 2222
    },
    {
      "epoch": 15.885714285714286,
      "grad_norm": 0.019866840913891792,
      "learning_rate": 1.8314285714285714e-05,
      "loss": 0.0,
      "step": 2224
    },
    {
      "epoch": 15.9,
      "grad_norm": 0.02901846542954445,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 0.0001,
      "step": 2226
    },
    {
      "epoch": 15.914285714285715,
      "grad_norm": 0.02764705754816532,
      "learning_rate": 1.8257142857142858e-05,
      "loss": 0.1673,
      "step": 2228
    },
    {
      "epoch": 15.928571428571429,
      "grad_norm": 0.046771664172410965,
      "learning_rate": 1.8228571428571428e-05,
      "loss": 0.0001,
      "step": 2230
    },
    {
      "epoch": 15.942857142857143,
      "grad_norm": 0.010939229279756546,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0,
      "step": 2232
    },
    {
      "epoch": 15.957142857142857,
      "grad_norm": 0.05062150955200195,
      "learning_rate": 1.8171428571428572e-05,
      "loss": 0.0001,
      "step": 2234
    },
    {
      "epoch": 15.971428571428572,
      "grad_norm": 0.020421311259269714,
      "learning_rate": 1.8142857142857146e-05,
      "loss": 0.0,
      "step": 2236
    },
    {
      "epoch": 15.985714285714286,
      "grad_norm": 0.021850071847438812,
      "learning_rate": 1.8114285714285713e-05,
      "loss": 0.0,
      "step": 2238
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.011799080297350883,
      "learning_rate": 1.8085714285714286e-05,
      "loss": 0.0,
      "step": 2240
    },
    {
      "epoch": 16.014285714285716,
      "grad_norm": 0.029851868748664856,
      "learning_rate": 1.805714285714286e-05,
      "loss": 0.0,
      "step": 2242
    },
    {
      "epoch": 16.02857142857143,
      "grad_norm": 0.022195173427462578,
      "learning_rate": 1.802857142857143e-05,
      "loss": 0.0,
      "step": 2244
    },
    {
      "epoch": 16.042857142857144,
      "grad_norm": 0.018314244225621223,
      "learning_rate": 1.8e-05,
      "loss": 0.0,
      "step": 2246
    },
    {
      "epoch": 16.057142857142857,
      "grad_norm": 0.020837685093283653,
      "learning_rate": 1.797142857142857e-05,
      "loss": 0.0,
      "step": 2248
    },
    {
      "epoch": 16.071428571428573,
      "grad_norm": 0.01615464873611927,
      "learning_rate": 1.7942857142857144e-05,
      "loss": 0.0,
      "step": 2250
    },
    {
      "epoch": 16.085714285714285,
      "grad_norm": 0.017813125625252724,
      "learning_rate": 1.7914285714285715e-05,
      "loss": 0.0,
      "step": 2252
    },
    {
      "epoch": 16.1,
      "grad_norm": 0.058640263974666595,
      "learning_rate": 1.7885714285714285e-05,
      "loss": 0.0001,
      "step": 2254
    },
    {
      "epoch": 16.114285714285714,
      "grad_norm": 0.017393138259649277,
      "learning_rate": 1.785714285714286e-05,
      "loss": 0.0,
      "step": 2256
    },
    {
      "epoch": 16.12857142857143,
      "grad_norm": 0.0319218747317791,
      "learning_rate": 1.7828571428571432e-05,
      "loss": 0.0001,
      "step": 2258
    },
    {
      "epoch": 16.142857142857142,
      "grad_norm": 0.02607567049562931,
      "learning_rate": 1.78e-05,
      "loss": 0.0,
      "step": 2260
    },
    {
      "epoch": 16.15714285714286,
      "grad_norm": 0.017879953607916832,
      "learning_rate": 1.7771428571428573e-05,
      "loss": 0.0,
      "step": 2262
    },
    {
      "epoch": 16.17142857142857,
      "grad_norm": 0.02224508300423622,
      "learning_rate": 1.7742857142857143e-05,
      "loss": 0.0,
      "step": 2264
    },
    {
      "epoch": 16.185714285714287,
      "grad_norm": 0.0426853708922863,
      "learning_rate": 1.7714285714285713e-05,
      "loss": 0.0001,
      "step": 2266
    },
    {
      "epoch": 16.2,
      "grad_norm": 0.050608113408088684,
      "learning_rate": 1.7685714285714287e-05,
      "loss": 0.0001,
      "step": 2268
    },
    {
      "epoch": 16.214285714285715,
      "grad_norm": 0.04513009265065193,
      "learning_rate": 1.7657142857142857e-05,
      "loss": 0.0,
      "step": 2270
    },
    {
      "epoch": 16.228571428571428,
      "grad_norm": 0.027950001880526543,
      "learning_rate": 1.762857142857143e-05,
      "loss": 0.0,
      "step": 2272
    },
    {
      "epoch": 16.242857142857144,
      "grad_norm": 0.043094366788864136,
      "learning_rate": 1.76e-05,
      "loss": 0.0001,
      "step": 2274
    },
    {
      "epoch": 16.257142857142856,
      "grad_norm": 0.03011041134595871,
      "learning_rate": 1.757142857142857e-05,
      "loss": 0.0001,
      "step": 2276
    },
    {
      "epoch": 16.271428571428572,
      "grad_norm": 0.027094688266515732,
      "learning_rate": 1.7542857142857145e-05,
      "loss": 0.0,
      "step": 2278
    },
    {
      "epoch": 16.285714285714285,
      "grad_norm": 0.018104391172528267,
      "learning_rate": 1.7514285714285715e-05,
      "loss": 0.0,
      "step": 2280
    },
    {
      "epoch": 16.3,
      "grad_norm": 0.015334728173911572,
      "learning_rate": 1.7485714285714285e-05,
      "loss": 0.0,
      "step": 2282
    },
    {
      "epoch": 16.314285714285713,
      "grad_norm": 0.013502920046448708,
      "learning_rate": 1.745714285714286e-05,
      "loss": 0.0,
      "step": 2284
    },
    {
      "epoch": 16.32857142857143,
      "grad_norm": 0.016789253801107407,
      "learning_rate": 1.742857142857143e-05,
      "loss": 0.0,
      "step": 2286
    },
    {
      "epoch": 16.34285714285714,
      "grad_norm": 0.018594181165099144,
      "learning_rate": 1.74e-05,
      "loss": 0.0,
      "step": 2288
    },
    {
      "epoch": 16.357142857142858,
      "grad_norm": 0.022991826757788658,
      "learning_rate": 1.7371428571428573e-05,
      "loss": 0.0,
      "step": 2290
    },
    {
      "epoch": 16.37142857142857,
      "grad_norm": 0.017111465334892273,
      "learning_rate": 1.7342857142857143e-05,
      "loss": 0.0,
      "step": 2292
    },
    {
      "epoch": 16.385714285714286,
      "grad_norm": 0.020361797884106636,
      "learning_rate": 1.7314285714285717e-05,
      "loss": 0.0,
      "step": 2294
    },
    {
      "epoch": 16.4,
      "grad_norm": 0.010151530615985394,
      "learning_rate": 1.7285714285714287e-05,
      "loss": 0.0,
      "step": 2296
    },
    {
      "epoch": 16.414285714285715,
      "grad_norm": 0.023232147097587585,
      "learning_rate": 1.7257142857142857e-05,
      "loss": 0.0,
      "step": 2298
    },
    {
      "epoch": 16.428571428571427,
      "grad_norm": 0.02301228791475296,
      "learning_rate": 1.722857142857143e-05,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 16.442857142857143,
      "grad_norm": 0.030271148309111595,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 0.0001,
      "step": 2302
    },
    {
      "epoch": 16.457142857142856,
      "grad_norm": 0.021304575726389885,
      "learning_rate": 1.717142857142857e-05,
      "loss": 0.0,
      "step": 2304
    },
    {
      "epoch": 16.47142857142857,
      "grad_norm": 0.023470941931009293,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 0.0,
      "step": 2306
    },
    {
      "epoch": 16.485714285714284,
      "grad_norm": 0.01353511493653059,
      "learning_rate": 1.7114285714285715e-05,
      "loss": 0.0,
      "step": 2308
    },
    {
      "epoch": 16.5,
      "grad_norm": 0.023498181253671646,
      "learning_rate": 1.7085714285714286e-05,
      "loss": 0.0,
      "step": 2310
    },
    {
      "epoch": 16.514285714285712,
      "grad_norm": 0.021147867664694786,
      "learning_rate": 1.7057142857142856e-05,
      "loss": 0.0,
      "step": 2312
    },
    {
      "epoch": 16.52857142857143,
      "grad_norm": 0.01601991057395935,
      "learning_rate": 1.702857142857143e-05,
      "loss": 0.0,
      "step": 2314
    },
    {
      "epoch": 16.542857142857144,
      "grad_norm": 0.02694178745150566,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.0,
      "step": 2316
    },
    {
      "epoch": 16.557142857142857,
      "grad_norm": 0.028336815536022186,
      "learning_rate": 1.697142857142857e-05,
      "loss": 0.0,
      "step": 2318
    },
    {
      "epoch": 16.571428571428573,
      "grad_norm": 0.013814608566462994,
      "learning_rate": 1.6942857142857144e-05,
      "loss": 0.0,
      "step": 2320
    },
    {
      "epoch": 16.585714285714285,
      "grad_norm": 0.011786007322371006,
      "learning_rate": 1.6914285714285717e-05,
      "loss": 0.0,
      "step": 2322
    },
    {
      "epoch": 16.6,
      "grad_norm": 0.018245162442326546,
      "learning_rate": 1.6885714285714284e-05,
      "loss": 0.0,
      "step": 2324
    },
    {
      "epoch": 16.614285714285714,
      "grad_norm": 0.018029356375336647,
      "learning_rate": 1.6857142857142858e-05,
      "loss": 0.0,
      "step": 2326
    },
    {
      "epoch": 16.62857142857143,
      "grad_norm": 0.024111328646540642,
      "learning_rate": 1.6828571428571428e-05,
      "loss": 0.0,
      "step": 2328
    },
    {
      "epoch": 16.642857142857142,
      "grad_norm": 0.01144684199243784,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0,
      "step": 2330
    },
    {
      "epoch": 16.65714285714286,
      "grad_norm": 0.010424923151731491,
      "learning_rate": 1.6771428571428572e-05,
      "loss": 0.0,
      "step": 2332
    },
    {
      "epoch": 16.67142857142857,
      "grad_norm": 0.01957126334309578,
      "learning_rate": 1.6742857142857142e-05,
      "loss": 0.0,
      "step": 2334
    },
    {
      "epoch": 16.685714285714287,
      "grad_norm": 0.028055833652615547,
      "learning_rate": 1.6714285714285716e-05,
      "loss": 0.0001,
      "step": 2336
    },
    {
      "epoch": 16.7,
      "grad_norm": 0.0217412281781435,
      "learning_rate": 1.6685714285714286e-05,
      "loss": 0.0,
      "step": 2338
    },
    {
      "epoch": 16.714285714285715,
      "grad_norm": 0.03926190361380577,
      "learning_rate": 1.6657142857142856e-05,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 16.728571428571428,
      "grad_norm": 0.013743041083216667,
      "learning_rate": 1.662857142857143e-05,
      "loss": 0.0,
      "step": 2342
    },
    {
      "epoch": 16.742857142857144,
      "grad_norm": 0.037079352885484695,
      "learning_rate": 1.66e-05,
      "loss": 0.0,
      "step": 2344
    },
    {
      "epoch": 16.757142857142856,
      "grad_norm": 0.008497224189341068,
      "learning_rate": 1.657142857142857e-05,
      "loss": 0.0,
      "step": 2346
    },
    {
      "epoch": 16.771428571428572,
      "grad_norm": 0.028994876891374588,
      "learning_rate": 1.6542857142857144e-05,
      "loss": 0.0,
      "step": 2348
    },
    {
      "epoch": 16.785714285714285,
      "grad_norm": 0.0426381453871727,
      "learning_rate": 1.6514285714285714e-05,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 16.8,
      "grad_norm": 0.049851927906274796,
      "learning_rate": 1.6485714285714288e-05,
      "loss": 0.0003,
      "step": 2352
    },
    {
      "epoch": 16.814285714285713,
      "grad_norm": 0.01566891372203827,
      "learning_rate": 1.645714285714286e-05,
      "loss": 0.0,
      "step": 2354
    },
    {
      "epoch": 16.82857142857143,
      "grad_norm": 0.012864651158452034,
      "learning_rate": 1.642857142857143e-05,
      "loss": 0.0,
      "step": 2356
    },
    {
      "epoch": 16.84285714285714,
      "grad_norm": 0.03496387228369713,
      "learning_rate": 1.6400000000000002e-05,
      "loss": 0.0,
      "step": 2358
    },
    {
      "epoch": 16.857142857142858,
      "grad_norm": 0.017823128029704094,
      "learning_rate": 1.6371428571428572e-05,
      "loss": 0.0,
      "step": 2360
    },
    {
      "epoch": 16.87142857142857,
      "grad_norm": 0.04108487069606781,
      "learning_rate": 1.6342857142857143e-05,
      "loss": 0.0001,
      "step": 2362
    },
    {
      "epoch": 16.885714285714286,
      "grad_norm": 0.02225462533533573,
      "learning_rate": 1.6314285714285716e-05,
      "loss": 0.0,
      "step": 2364
    },
    {
      "epoch": 16.9,
      "grad_norm": 0.0166720449924469,
      "learning_rate": 1.6285714285714287e-05,
      "loss": 0.0,
      "step": 2366
    },
    {
      "epoch": 16.914285714285715,
      "grad_norm": 0.026068642735481262,
      "learning_rate": 1.6257142857142857e-05,
      "loss": 0.0,
      "step": 2368
    },
    {
      "epoch": 16.928571428571427,
      "grad_norm": 0.021142156794667244,
      "learning_rate": 1.622857142857143e-05,
      "loss": 0.0,
      "step": 2370
    },
    {
      "epoch": 16.942857142857143,
      "grad_norm": 0.021484125405550003,
      "learning_rate": 1.62e-05,
      "loss": 0.0,
      "step": 2372
    },
    {
      "epoch": 16.957142857142856,
      "grad_norm": 0.01834680885076523,
      "learning_rate": 1.6171428571428574e-05,
      "loss": 0.0,
      "step": 2374
    },
    {
      "epoch": 16.97142857142857,
      "grad_norm": 0.020147155970335007,
      "learning_rate": 1.614285714285714e-05,
      "loss": 0.0,
      "step": 2376
    },
    {
      "epoch": 16.985714285714288,
      "grad_norm": 0.02158452197909355,
      "learning_rate": 1.6114285714285715e-05,
      "loss": 0.0,
      "step": 2378
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.04482899233698845,
      "learning_rate": 1.608571428571429e-05,
      "loss": 0.0001,
      "step": 2380
    },
    {
      "epoch": 17.014285714285716,
      "grad_norm": 0.026504138484597206,
      "learning_rate": 1.6057142857142855e-05,
      "loss": 0.0,
      "step": 2382
    },
    {
      "epoch": 17.02857142857143,
      "grad_norm": 0.017225435003638268,
      "learning_rate": 1.602857142857143e-05,
      "loss": 0.0,
      "step": 2384
    },
    {
      "epoch": 17.042857142857144,
      "grad_norm": 0.024765802547335625,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0,
      "step": 2386
    },
    {
      "epoch": 17.057142857142857,
      "grad_norm": 0.04037083312869072,
      "learning_rate": 1.5971428571428573e-05,
      "loss": 0.0001,
      "step": 2388
    },
    {
      "epoch": 17.071428571428573,
      "grad_norm": 0.013657903298735619,
      "learning_rate": 1.5942857142857143e-05,
      "loss": 0.0,
      "step": 2390
    },
    {
      "epoch": 17.085714285714285,
      "grad_norm": 0.04529699683189392,
      "learning_rate": 1.5914285714285713e-05,
      "loss": 0.0001,
      "step": 2392
    },
    {
      "epoch": 17.1,
      "grad_norm": 0.021779460832476616,
      "learning_rate": 1.5885714285714287e-05,
      "loss": 0.0,
      "step": 2394
    },
    {
      "epoch": 17.114285714285714,
      "grad_norm": 0.018527919426560402,
      "learning_rate": 1.5857142857142857e-05,
      "loss": 0.0,
      "step": 2396
    },
    {
      "epoch": 17.12857142857143,
      "grad_norm": 0.026414496824145317,
      "learning_rate": 1.5828571428571428e-05,
      "loss": 0.0001,
      "step": 2398
    },
    {
      "epoch": 17.142857142857142,
      "grad_norm": 0.010501014068722725,
      "learning_rate": 1.58e-05,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 17.142857142857142,
      "eval_cer": 0.003395585738539898,
      "eval_loss": 0.012823298573493958,
      "eval_runtime": 10.1783,
      "eval_samples_per_second": 27.411,
      "eval_steps_per_second": 3.439,
      "step": 2400
    },
    {
      "epoch": 17.15714285714286,
      "grad_norm": 0.009800494648516178,
      "learning_rate": 1.577142857142857e-05,
      "loss": 0.0,
      "step": 2402
    },
    {
      "epoch": 17.17142857142857,
      "grad_norm": 0.018940461799502373,
      "learning_rate": 1.574285714285714e-05,
      "loss": 0.0,
      "step": 2404
    },
    {
      "epoch": 17.185714285714287,
      "grad_norm": 0.020670654252171516,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.0,
      "step": 2406
    },
    {
      "epoch": 17.2,
      "grad_norm": 0.016222961246967316,
      "learning_rate": 1.5685714285714286e-05,
      "loss": 0.0,
      "step": 2408
    },
    {
      "epoch": 17.214285714285715,
      "grad_norm": 0.017609041184186935,
      "learning_rate": 1.565714285714286e-05,
      "loss": 0.0,
      "step": 2410
    },
    {
      "epoch": 17.228571428571428,
      "grad_norm": 0.014723443426191807,
      "learning_rate": 1.562857142857143e-05,
      "loss": 0.0,
      "step": 2412
    },
    {
      "epoch": 17.242857142857144,
      "grad_norm": 0.022565076127648354,
      "learning_rate": 1.56e-05,
      "loss": 0.0,
      "step": 2414
    },
    {
      "epoch": 17.257142857142856,
      "grad_norm": 0.01883077062666416,
      "learning_rate": 1.5571428571428573e-05,
      "loss": 0.0,
      "step": 2416
    },
    {
      "epoch": 17.271428571428572,
      "grad_norm": 0.013109900988638401,
      "learning_rate": 1.5542857142857144e-05,
      "loss": 0.0,
      "step": 2418
    },
    {
      "epoch": 17.285714285714285,
      "grad_norm": 0.01787763088941574,
      "learning_rate": 1.5514285714285714e-05,
      "loss": 0.0001,
      "step": 2420
    },
    {
      "epoch": 17.3,
      "grad_norm": 0.018168622627854347,
      "learning_rate": 1.5485714285714287e-05,
      "loss": 0.0,
      "step": 2422
    },
    {
      "epoch": 17.314285714285713,
      "grad_norm": 0.011848680675029755,
      "learning_rate": 1.5457142857142858e-05,
      "loss": 0.0,
      "step": 2424
    },
    {
      "epoch": 17.32857142857143,
      "grad_norm": 0.022809702903032303,
      "learning_rate": 1.5428571428571428e-05,
      "loss": 0.0,
      "step": 2426
    },
    {
      "epoch": 17.34285714285714,
      "grad_norm": 0.013414283283054829,
      "learning_rate": 1.54e-05,
      "loss": 0.0,
      "step": 2428
    },
    {
      "epoch": 17.357142857142858,
      "grad_norm": 0.01260414533317089,
      "learning_rate": 1.5371428571428572e-05,
      "loss": 0.0,
      "step": 2430
    },
    {
      "epoch": 17.37142857142857,
      "grad_norm": 0.03089662455022335,
      "learning_rate": 1.5342857142857146e-05,
      "loss": 0.0,
      "step": 2432
    },
    {
      "epoch": 17.385714285714286,
      "grad_norm": 0.02378116548061371,
      "learning_rate": 1.5314285714285716e-05,
      "loss": 0.0,
      "step": 2434
    },
    {
      "epoch": 17.4,
      "grad_norm": 0.019926821812987328,
      "learning_rate": 1.5285714285714286e-05,
      "loss": 0.0,
      "step": 2436
    },
    {
      "epoch": 17.414285714285715,
      "grad_norm": 0.039885394275188446,
      "learning_rate": 1.5257142857142858e-05,
      "loss": 0.0,
      "step": 2438
    },
    {
      "epoch": 17.428571428571427,
      "grad_norm": 0.020975349470973015,
      "learning_rate": 1.5228571428571428e-05,
      "loss": 0.0,
      "step": 2440
    },
    {
      "epoch": 17.442857142857143,
      "grad_norm": 0.01246132142841816,
      "learning_rate": 1.52e-05,
      "loss": 0.0,
      "step": 2442
    },
    {
      "epoch": 17.457142857142856,
      "grad_norm": 0.01256902888417244,
      "learning_rate": 1.5171428571428572e-05,
      "loss": 0.0,
      "step": 2444
    },
    {
      "epoch": 17.47142857142857,
      "grad_norm": 0.01281033642590046,
      "learning_rate": 1.5142857142857144e-05,
      "loss": 0.0,
      "step": 2446
    },
    {
      "epoch": 17.485714285714284,
      "grad_norm": 0.02542504109442234,
      "learning_rate": 1.5114285714285714e-05,
      "loss": 0.0,
      "step": 2448
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.01991601660847664,
      "learning_rate": 1.5085714285714286e-05,
      "loss": 0.0,
      "step": 2450
    },
    {
      "epoch": 17.514285714285712,
      "grad_norm": 0.017893914133310318,
      "learning_rate": 1.5057142857142858e-05,
      "loss": 0.0,
      "step": 2452
    },
    {
      "epoch": 17.52857142857143,
      "grad_norm": 0.04914677143096924,
      "learning_rate": 1.5028571428571428e-05,
      "loss": 0.0,
      "step": 2454
    },
    {
      "epoch": 17.542857142857144,
      "grad_norm": 0.035793237388134,
      "learning_rate": 1.5e-05,
      "loss": 0.0,
      "step": 2456
    },
    {
      "epoch": 17.557142857142857,
      "grad_norm": 0.01855996996164322,
      "learning_rate": 1.4971428571428572e-05,
      "loss": 0.0,
      "step": 2458
    },
    {
      "epoch": 17.571428571428573,
      "grad_norm": 0.009187356568872929,
      "learning_rate": 1.4942857142857144e-05,
      "loss": 0.0,
      "step": 2460
    },
    {
      "epoch": 17.585714285714285,
      "grad_norm": 0.02661922387778759,
      "learning_rate": 1.4914285714285715e-05,
      "loss": 0.0001,
      "step": 2462
    },
    {
      "epoch": 17.6,
      "grad_norm": 0.03061281144618988,
      "learning_rate": 1.4885714285714286e-05,
      "loss": 0.0,
      "step": 2464
    },
    {
      "epoch": 17.614285714285714,
      "grad_norm": 0.01182328537106514,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 0.0,
      "step": 2466
    },
    {
      "epoch": 17.62857142857143,
      "grad_norm": 0.010048529133200645,
      "learning_rate": 1.482857142857143e-05,
      "loss": 0.0,
      "step": 2468
    },
    {
      "epoch": 17.642857142857142,
      "grad_norm": 0.025466930121183395,
      "learning_rate": 1.48e-05,
      "loss": 0.0001,
      "step": 2470
    },
    {
      "epoch": 17.65714285714286,
      "grad_norm": 0.01692841947078705,
      "learning_rate": 1.4771428571428573e-05,
      "loss": 0.0001,
      "step": 2472
    },
    {
      "epoch": 17.67142857142857,
      "grad_norm": 0.020266013219952583,
      "learning_rate": 1.4742857142857144e-05,
      "loss": 0.0,
      "step": 2474
    },
    {
      "epoch": 17.685714285714287,
      "grad_norm": 0.019447045400738716,
      "learning_rate": 1.4714285714285713e-05,
      "loss": 0.0,
      "step": 2476
    },
    {
      "epoch": 17.7,
      "grad_norm": 0.019616087898612022,
      "learning_rate": 1.4685714285714287e-05,
      "loss": 0.0,
      "step": 2478
    },
    {
      "epoch": 17.714285714285715,
      "grad_norm": 0.01576649397611618,
      "learning_rate": 1.4657142857142859e-05,
      "loss": 0.0,
      "step": 2480
    },
    {
      "epoch": 17.728571428571428,
      "grad_norm": 0.011289126239717007,
      "learning_rate": 1.462857142857143e-05,
      "loss": 0.0,
      "step": 2482
    },
    {
      "epoch": 17.742857142857144,
      "grad_norm": 0.025304758921265602,
      "learning_rate": 1.4599999999999999e-05,
      "loss": 0.0,
      "step": 2484
    },
    {
      "epoch": 17.757142857142856,
      "grad_norm": 0.021372290328145027,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 0.0,
      "step": 2486
    },
    {
      "epoch": 17.771428571428572,
      "grad_norm": 0.013875432312488556,
      "learning_rate": 1.4542857142857145e-05,
      "loss": 0.0,
      "step": 2488
    },
    {
      "epoch": 17.785714285714285,
      "grad_norm": 0.010892563499510288,
      "learning_rate": 1.4514285714285713e-05,
      "loss": 0.0,
      "step": 2490
    },
    {
      "epoch": 17.8,
      "grad_norm": 0.021156931295990944,
      "learning_rate": 1.4485714285714285e-05,
      "loss": 0.0,
      "step": 2492
    },
    {
      "epoch": 17.814285714285713,
      "grad_norm": 0.019893145188689232,
      "learning_rate": 1.4457142857142857e-05,
      "loss": 0.0,
      "step": 2494
    },
    {
      "epoch": 17.82857142857143,
      "grad_norm": 0.017564235255122185,
      "learning_rate": 1.442857142857143e-05,
      "loss": 0.0,
      "step": 2496
    },
    {
      "epoch": 17.84285714285714,
      "grad_norm": 0.017530644312500954,
      "learning_rate": 1.44e-05,
      "loss": 0.0,
      "step": 2498
    },
    {
      "epoch": 17.857142857142858,
      "grad_norm": 0.022264497354626656,
      "learning_rate": 1.4371428571428571e-05,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 17.87142857142857,
      "grad_norm": 0.04162690415978432,
      "learning_rate": 1.4342857142857143e-05,
      "loss": 0.0,
      "step": 2502
    },
    {
      "epoch": 17.885714285714286,
      "grad_norm": 0.011214833706617355,
      "learning_rate": 1.4314285714285717e-05,
      "loss": 0.0,
      "step": 2504
    },
    {
      "epoch": 17.9,
      "grad_norm": 0.014298815280199051,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.0,
      "step": 2506
    },
    {
      "epoch": 17.914285714285715,
      "grad_norm": 0.027373911812901497,
      "learning_rate": 1.4257142857142857e-05,
      "loss": 0.0,
      "step": 2508
    },
    {
      "epoch": 17.928571428571427,
      "grad_norm": 0.02559841051697731,
      "learning_rate": 1.422857142857143e-05,
      "loss": 0.0,
      "step": 2510
    },
    {
      "epoch": 17.942857142857143,
      "grad_norm": 0.012415646575391293,
      "learning_rate": 1.42e-05,
      "loss": 0.0,
      "step": 2512
    },
    {
      "epoch": 17.957142857142856,
      "grad_norm": 0.010570178739726543,
      "learning_rate": 1.4171428571428572e-05,
      "loss": 0.0,
      "step": 2514
    },
    {
      "epoch": 17.97142857142857,
      "grad_norm": 0.029117345809936523,
      "learning_rate": 1.4142857142857143e-05,
      "loss": 0.0001,
      "step": 2516
    },
    {
      "epoch": 17.985714285714288,
      "grad_norm": 0.01330657210201025,
      "learning_rate": 1.4114285714285715e-05,
      "loss": 0.0,
      "step": 2518
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.023146629333496094,
      "learning_rate": 1.4085714285714286e-05,
      "loss": 0.0,
      "step": 2520
    },
    {
      "epoch": 18.014285714285716,
      "grad_norm": 0.015553389675915241,
      "learning_rate": 1.4057142857142858e-05,
      "loss": 0.0,
      "step": 2522
    },
    {
      "epoch": 18.02857142857143,
      "grad_norm": 0.012137616984546185,
      "learning_rate": 1.402857142857143e-05,
      "loss": 0.0,
      "step": 2524
    },
    {
      "epoch": 18.042857142857144,
      "grad_norm": 0.018434925004839897,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0,
      "step": 2526
    },
    {
      "epoch": 18.057142857142857,
      "grad_norm": 0.020467672497034073,
      "learning_rate": 1.3971428571428572e-05,
      "loss": 0.0,
      "step": 2528
    },
    {
      "epoch": 18.071428571428573,
      "grad_norm": 0.01625131443142891,
      "learning_rate": 1.3942857142857144e-05,
      "loss": 0.0,
      "step": 2530
    },
    {
      "epoch": 18.085714285714285,
      "grad_norm": 0.02265077270567417,
      "learning_rate": 1.3914285714285716e-05,
      "loss": 0.0,
      "step": 2532
    },
    {
      "epoch": 18.1,
      "grad_norm": 0.012217906303703785,
      "learning_rate": 1.3885714285714286e-05,
      "loss": 0.0,
      "step": 2534
    },
    {
      "epoch": 18.114285714285714,
      "grad_norm": 0.016266031190752983,
      "learning_rate": 1.3857142857142858e-05,
      "loss": 0.0,
      "step": 2536
    },
    {
      "epoch": 18.12857142857143,
      "grad_norm": 0.027992403134703636,
      "learning_rate": 1.382857142857143e-05,
      "loss": 0.0,
      "step": 2538
    },
    {
      "epoch": 18.142857142857142,
      "grad_norm": 0.013851664960384369,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 0.0,
      "step": 2540
    },
    {
      "epoch": 18.15714285714286,
      "grad_norm": 0.022734222933650017,
      "learning_rate": 1.3771428571428572e-05,
      "loss": 0.0,
      "step": 2542
    },
    {
      "epoch": 18.17142857142857,
      "grad_norm": 0.01325325295329094,
      "learning_rate": 1.3742857142857144e-05,
      "loss": 0.0,
      "step": 2544
    },
    {
      "epoch": 18.185714285714287,
      "grad_norm": 0.02046109549701214,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 0.0,
      "step": 2546
    },
    {
      "epoch": 18.2,
      "grad_norm": 0.01877230405807495,
      "learning_rate": 1.3685714285714284e-05,
      "loss": 0.0,
      "step": 2548
    },
    {
      "epoch": 18.214285714285715,
      "grad_norm": 0.026844190433621407,
      "learning_rate": 1.3657142857142858e-05,
      "loss": 0.0,
      "step": 2550
    },
    {
      "epoch": 18.228571428571428,
      "grad_norm": 0.01769590936601162,
      "learning_rate": 1.362857142857143e-05,
      "loss": 0.0,
      "step": 2552
    },
    {
      "epoch": 18.242857142857144,
      "grad_norm": 0.00952982623130083,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0,
      "step": 2554
    },
    {
      "epoch": 18.257142857142856,
      "grad_norm": 0.024408796802163124,
      "learning_rate": 1.357142857142857e-05,
      "loss": 0.0,
      "step": 2556
    },
    {
      "epoch": 18.271428571428572,
      "grad_norm": 0.02143479511141777,
      "learning_rate": 1.3542857142857142e-05,
      "loss": 0.0,
      "step": 2558
    },
    {
      "epoch": 18.285714285714285,
      "grad_norm": 0.021888593211770058,
      "learning_rate": 1.3514285714285716e-05,
      "loss": 0.0,
      "step": 2560
    },
    {
      "epoch": 18.3,
      "grad_norm": 0.02176615595817566,
      "learning_rate": 1.3485714285714288e-05,
      "loss": 0.0,
      "step": 2562
    },
    {
      "epoch": 18.314285714285713,
      "grad_norm": 0.01374385692179203,
      "learning_rate": 1.3457142857142857e-05,
      "loss": 0.0,
      "step": 2564
    },
    {
      "epoch": 18.32857142857143,
      "grad_norm": 0.009539440274238586,
      "learning_rate": 1.3428571428571429e-05,
      "loss": 0.0,
      "step": 2566
    },
    {
      "epoch": 18.34285714285714,
      "grad_norm": 0.025152334943413734,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0,
      "step": 2568
    },
    {
      "epoch": 18.357142857142858,
      "grad_norm": 0.008068758063018322,
      "learning_rate": 1.337142857142857e-05,
      "loss": 0.0,
      "step": 2570
    },
    {
      "epoch": 18.37142857142857,
      "grad_norm": 0.013472255319356918,
      "learning_rate": 1.3342857142857143e-05,
      "loss": 0.0,
      "step": 2572
    },
    {
      "epoch": 18.385714285714286,
      "grad_norm": 0.04044449329376221,
      "learning_rate": 1.3314285714285715e-05,
      "loss": 0.0001,
      "step": 2574
    },
    {
      "epoch": 18.4,
      "grad_norm": 0.02289496175944805,
      "learning_rate": 1.3285714285714288e-05,
      "loss": 0.0,
      "step": 2576
    },
    {
      "epoch": 18.414285714285715,
      "grad_norm": 0.019745642319321632,
      "learning_rate": 1.3257142857142857e-05,
      "loss": 0.0,
      "step": 2578
    },
    {
      "epoch": 18.428571428571427,
      "grad_norm": 0.011308152228593826,
      "learning_rate": 1.3228571428571429e-05,
      "loss": 0.0,
      "step": 2580
    },
    {
      "epoch": 18.442857142857143,
      "grad_norm": 0.02683543600142002,
      "learning_rate": 1.32e-05,
      "loss": 0.0,
      "step": 2582
    },
    {
      "epoch": 18.457142857142856,
      "grad_norm": 0.02172744646668434,
      "learning_rate": 1.3171428571428571e-05,
      "loss": 0.0001,
      "step": 2584
    },
    {
      "epoch": 18.47142857142857,
      "grad_norm": 0.02212526835501194,
      "learning_rate": 1.3142857142857143e-05,
      "loss": 0.0,
      "step": 2586
    },
    {
      "epoch": 18.485714285714284,
      "grad_norm": 0.02896765060722828,
      "learning_rate": 1.3114285714285715e-05,
      "loss": 0.0,
      "step": 2588
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.02593744918704033,
      "learning_rate": 1.3085714285714287e-05,
      "loss": 0.0,
      "step": 2590
    },
    {
      "epoch": 18.514285714285712,
      "grad_norm": 0.01605818420648575,
      "learning_rate": 1.3057142857142857e-05,
      "loss": 0.0,
      "step": 2592
    },
    {
      "epoch": 18.52857142857143,
      "grad_norm": 0.02560368925333023,
      "learning_rate": 1.3028571428571429e-05,
      "loss": 0.0,
      "step": 2594
    },
    {
      "epoch": 18.542857142857144,
      "grad_norm": 0.015484511852264404,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0,
      "step": 2596
    },
    {
      "epoch": 18.557142857142857,
      "grad_norm": 0.009845907799899578,
      "learning_rate": 1.2971428571428573e-05,
      "loss": 0.0,
      "step": 2598
    },
    {
      "epoch": 18.571428571428573,
      "grad_norm": 0.02955811843276024,
      "learning_rate": 1.2942857142857143e-05,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 18.571428571428573,
      "eval_cer": 0.003395585738539898,
      "eval_loss": 0.014146235771477222,
      "eval_runtime": 10.0599,
      "eval_samples_per_second": 27.734,
      "eval_steps_per_second": 3.479,
      "step": 2600
    },
    {
      "epoch": 18.585714285714285,
      "grad_norm": 0.019544899463653564,
      "learning_rate": 1.2914285714285715e-05,
      "loss": 0.0,
      "step": 2602
    },
    {
      "epoch": 18.6,
      "grad_norm": 0.013211789540946484,
      "learning_rate": 1.2885714285714287e-05,
      "loss": 0.0,
      "step": 2604
    },
    {
      "epoch": 18.614285714285714,
      "grad_norm": 0.011457474902272224,
      "learning_rate": 1.2857142857142857e-05,
      "loss": 0.0,
      "step": 2606
    },
    {
      "epoch": 18.62857142857143,
      "grad_norm": 0.017369698733091354,
      "learning_rate": 1.282857142857143e-05,
      "loss": 0.0,
      "step": 2608
    },
    {
      "epoch": 18.642857142857142,
      "grad_norm": 0.026273399591445923,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0,
      "step": 2610
    },
    {
      "epoch": 18.65714285714286,
      "grad_norm": 0.013917909935116768,
      "learning_rate": 1.2771428571428573e-05,
      "loss": 0.0,
      "step": 2612
    },
    {
      "epoch": 18.67142857142857,
      "grad_norm": 0.01931174285709858,
      "learning_rate": 1.2742857142857143e-05,
      "loss": 0.0,
      "step": 2614
    },
    {
      "epoch": 18.685714285714287,
      "grad_norm": 0.024227038025856018,
      "learning_rate": 1.2714285714285715e-05,
      "loss": 0.0,
      "step": 2616
    },
    {
      "epoch": 18.7,
      "grad_norm": 0.010381998494267464,
      "learning_rate": 1.2685714285714287e-05,
      "loss": 0.0,
      "step": 2618
    },
    {
      "epoch": 18.714285714285715,
      "grad_norm": 0.011770606972277164,
      "learning_rate": 1.2657142857142859e-05,
      "loss": 0.0,
      "step": 2620
    },
    {
      "epoch": 18.728571428571428,
      "grad_norm": 0.008267424069344997,
      "learning_rate": 1.2628571428571428e-05,
      "loss": 0.0,
      "step": 2622
    },
    {
      "epoch": 18.742857142857144,
      "grad_norm": 0.014301293529570103,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.0,
      "step": 2624
    },
    {
      "epoch": 18.757142857142856,
      "grad_norm": 0.015182035975158215,
      "learning_rate": 1.2571428571428573e-05,
      "loss": 0.0,
      "step": 2626
    },
    {
      "epoch": 18.771428571428572,
      "grad_norm": 0.011239460669457912,
      "learning_rate": 1.2542857142857142e-05,
      "loss": 0.0,
      "step": 2628
    },
    {
      "epoch": 18.785714285714285,
      "grad_norm": 0.010733936913311481,
      "learning_rate": 1.2514285714285714e-05,
      "loss": 0.0,
      "step": 2630
    },
    {
      "epoch": 18.8,
      "grad_norm": 0.01858573593199253,
      "learning_rate": 1.2485714285714287e-05,
      "loss": 0.0,
      "step": 2632
    },
    {
      "epoch": 18.814285714285713,
      "grad_norm": 0.011825601570308208,
      "learning_rate": 1.2457142857142858e-05,
      "loss": 0.0,
      "step": 2634
    },
    {
      "epoch": 18.82857142857143,
      "grad_norm": 0.014242485165596008,
      "learning_rate": 1.242857142857143e-05,
      "loss": 0.0,
      "step": 2636
    },
    {
      "epoch": 18.84285714285714,
      "grad_norm": 0.008135161362588406,
      "learning_rate": 1.24e-05,
      "loss": 0.0,
      "step": 2638
    },
    {
      "epoch": 18.857142857142858,
      "grad_norm": 0.01595950312912464,
      "learning_rate": 1.2371428571428574e-05,
      "loss": 0.0,
      "step": 2640
    },
    {
      "epoch": 18.87142857142857,
      "grad_norm": 0.012842204421758652,
      "learning_rate": 1.2342857142857144e-05,
      "loss": 0.0,
      "step": 2642
    },
    {
      "epoch": 18.885714285714286,
      "grad_norm": 0.01383458636701107,
      "learning_rate": 1.2314285714285714e-05,
      "loss": 0.0,
      "step": 2644
    },
    {
      "epoch": 18.9,
      "grad_norm": 0.01283132005482912,
      "learning_rate": 1.2285714285714286e-05,
      "loss": 0.0,
      "step": 2646
    },
    {
      "epoch": 18.914285714285715,
      "grad_norm": 0.021811824291944504,
      "learning_rate": 1.2257142857142858e-05,
      "loss": 0.0,
      "step": 2648
    },
    {
      "epoch": 18.928571428571427,
      "grad_norm": 0.01385491993278265,
      "learning_rate": 1.222857142857143e-05,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 18.942857142857143,
      "grad_norm": 0.013356211595237255,
      "learning_rate": 1.22e-05,
      "loss": 0.0,
      "step": 2652
    },
    {
      "epoch": 18.957142857142856,
      "grad_norm": 0.012550203129649162,
      "learning_rate": 1.2171428571428572e-05,
      "loss": 0.0,
      "step": 2654
    },
    {
      "epoch": 18.97142857142857,
      "grad_norm": 0.008767513558268547,
      "learning_rate": 1.2142857142857144e-05,
      "loss": 0.0,
      "step": 2656
    },
    {
      "epoch": 18.985714285714288,
      "grad_norm": 0.006487330887466669,
      "learning_rate": 1.2114285714285716e-05,
      "loss": 0.0,
      "step": 2658
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.010268299840390682,
      "learning_rate": 1.2085714285714286e-05,
      "loss": 0.0,
      "step": 2660
    },
    {
      "epoch": 19.014285714285716,
      "grad_norm": 0.011860177852213383,
      "learning_rate": 1.2057142857142856e-05,
      "loss": 0.0,
      "step": 2662
    },
    {
      "epoch": 19.02857142857143,
      "grad_norm": 0.012751962058246136,
      "learning_rate": 1.202857142857143e-05,
      "loss": 0.0,
      "step": 2664
    },
    {
      "epoch": 19.042857142857144,
      "grad_norm": 0.01412185374647379,
      "learning_rate": 1.2e-05,
      "loss": 0.0,
      "step": 2666
    },
    {
      "epoch": 19.057142857142857,
      "grad_norm": 0.027897808700799942,
      "learning_rate": 1.1971428571428572e-05,
      "loss": 0.0,
      "step": 2668
    },
    {
      "epoch": 19.071428571428573,
      "grad_norm": 0.02371126413345337,
      "learning_rate": 1.1942857142857142e-05,
      "loss": 0.0,
      "step": 2670
    },
    {
      "epoch": 19.085714285714285,
      "grad_norm": 0.009839947335422039,
      "learning_rate": 1.1914285714285716e-05,
      "loss": 0.0,
      "step": 2672
    },
    {
      "epoch": 19.1,
      "grad_norm": 0.016020601615309715,
      "learning_rate": 1.1885714285714286e-05,
      "loss": 0.0,
      "step": 2674
    },
    {
      "epoch": 19.114285714285714,
      "grad_norm": 0.013994975946843624,
      "learning_rate": 1.1857142857142858e-05,
      "loss": 0.0,
      "step": 2676
    },
    {
      "epoch": 19.12857142857143,
      "grad_norm": 0.013851557858288288,
      "learning_rate": 1.1828571428571429e-05,
      "loss": 0.0,
      "step": 2678
    },
    {
      "epoch": 19.142857142857142,
      "grad_norm": 0.01112008560448885,
      "learning_rate": 1.18e-05,
      "loss": 0.0,
      "step": 2680
    },
    {
      "epoch": 19.15714285714286,
      "grad_norm": 0.011024422943592072,
      "learning_rate": 1.1771428571428572e-05,
      "loss": 0.0,
      "step": 2682
    },
    {
      "epoch": 19.17142857142857,
      "grad_norm": 0.0074090478010475636,
      "learning_rate": 1.1742857142857143e-05,
      "loss": 0.0,
      "step": 2684
    },
    {
      "epoch": 19.185714285714287,
      "grad_norm": 0.012890667654573917,
      "learning_rate": 1.1714285714285715e-05,
      "loss": 0.0,
      "step": 2686
    },
    {
      "epoch": 19.2,
      "grad_norm": 0.01460954174399376,
      "learning_rate": 1.1685714285714287e-05,
      "loss": 0.0,
      "step": 2688
    },
    {
      "epoch": 19.214285714285715,
      "grad_norm": 0.005784021224826574,
      "learning_rate": 1.1657142857142859e-05,
      "loss": 0.0,
      "step": 2690
    },
    {
      "epoch": 19.228571428571428,
      "grad_norm": 0.01323574036359787,
      "learning_rate": 1.1628571428571429e-05,
      "loss": 0.0,
      "step": 2692
    },
    {
      "epoch": 19.242857142857144,
      "grad_norm": 0.006554049905389547,
      "learning_rate": 1.16e-05,
      "loss": 0.0,
      "step": 2694
    },
    {
      "epoch": 19.257142857142856,
      "grad_norm": 0.0186160895973444,
      "learning_rate": 1.1571428571428573e-05,
      "loss": 0.0,
      "step": 2696
    },
    {
      "epoch": 19.271428571428572,
      "grad_norm": 0.018956530839204788,
      "learning_rate": 1.1542857142857143e-05,
      "loss": 0.0,
      "step": 2698
    },
    {
      "epoch": 19.285714285714285,
      "grad_norm": 0.013721659779548645,
      "learning_rate": 1.1514285714285715e-05,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 19.3,
      "grad_norm": 0.008937126025557518,
      "learning_rate": 1.1485714285714285e-05,
      "loss": 0.0,
      "step": 2702
    },
    {
      "epoch": 19.314285714285713,
      "grad_norm": 0.010329910553991795,
      "learning_rate": 1.1457142857142859e-05,
      "loss": 0.0,
      "step": 2704
    },
    {
      "epoch": 19.32857142857143,
      "grad_norm": 0.010392271913588047,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0,
      "step": 2706
    },
    {
      "epoch": 19.34285714285714,
      "grad_norm": 0.008101219311356544,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 0.0,
      "step": 2708
    },
    {
      "epoch": 19.357142857142858,
      "grad_norm": 0.011351645924150944,
      "learning_rate": 1.1371428571428571e-05,
      "loss": 0.0,
      "step": 2710
    },
    {
      "epoch": 19.37142857142857,
      "grad_norm": 0.01571943797171116,
      "learning_rate": 1.1342857142857143e-05,
      "loss": 0.0,
      "step": 2712
    },
    {
      "epoch": 19.385714285714286,
      "grad_norm": 0.00505401287227869,
      "learning_rate": 1.1314285714285715e-05,
      "loss": 0.0,
      "step": 2714
    },
    {
      "epoch": 19.4,
      "grad_norm": 0.015194935724139214,
      "learning_rate": 1.1285714285714285e-05,
      "loss": 0.0,
      "step": 2716
    },
    {
      "epoch": 19.414285714285715,
      "grad_norm": 0.016436809673905373,
      "learning_rate": 1.1257142857142857e-05,
      "loss": 0.0,
      "step": 2718
    },
    {
      "epoch": 19.428571428571427,
      "grad_norm": 0.01400603074580431,
      "learning_rate": 1.122857142857143e-05,
      "loss": 0.0,
      "step": 2720
    },
    {
      "epoch": 19.442857142857143,
      "grad_norm": 0.014942018315196037,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0,
      "step": 2722
    },
    {
      "epoch": 19.457142857142856,
      "grad_norm": 0.01625313237309456,
      "learning_rate": 1.1171428571428571e-05,
      "loss": 0.0,
      "step": 2724
    },
    {
      "epoch": 19.47142857142857,
      "grad_norm": 0.011140878312289715,
      "learning_rate": 1.1142857142857143e-05,
      "loss": 0.0,
      "step": 2726
    },
    {
      "epoch": 19.485714285714284,
      "grad_norm": 0.01574818789958954,
      "learning_rate": 1.1114285714285715e-05,
      "loss": 0.0,
      "step": 2728
    },
    {
      "epoch": 19.5,
      "grad_norm": 0.006476135458797216,
      "learning_rate": 1.1085714285714287e-05,
      "loss": 0.0,
      "step": 2730
    },
    {
      "epoch": 19.514285714285712,
      "grad_norm": 0.008800038136541843,
      "learning_rate": 1.1057142857142858e-05,
      "loss": 0.0,
      "step": 2732
    },
    {
      "epoch": 19.52857142857143,
      "grad_norm": 0.015031576156616211,
      "learning_rate": 1.102857142857143e-05,
      "loss": 0.0,
      "step": 2734
    },
    {
      "epoch": 19.542857142857144,
      "grad_norm": 0.010956639423966408,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0,
      "step": 2736
    },
    {
      "epoch": 19.557142857142857,
      "grad_norm": 0.011173302307724953,
      "learning_rate": 1.0971428571428572e-05,
      "loss": 0.0,
      "step": 2738
    },
    {
      "epoch": 19.571428571428573,
      "grad_norm": 0.014383346773684025,
      "learning_rate": 1.0942857142857144e-05,
      "loss": 0.0,
      "step": 2740
    },
    {
      "epoch": 19.585714285714285,
      "grad_norm": 0.008816532790660858,
      "learning_rate": 1.0914285714285714e-05,
      "loss": 0.0,
      "step": 2742
    },
    {
      "epoch": 19.6,
      "grad_norm": 0.019768424332141876,
      "learning_rate": 1.0885714285714286e-05,
      "loss": 0.0,
      "step": 2744
    },
    {
      "epoch": 19.614285714285714,
      "grad_norm": 0.009107464924454689,
      "learning_rate": 1.0857142857142858e-05,
      "loss": 0.0,
      "step": 2746
    },
    {
      "epoch": 19.62857142857143,
      "grad_norm": 0.021227454766631126,
      "learning_rate": 1.082857142857143e-05,
      "loss": 0.0,
      "step": 2748
    },
    {
      "epoch": 19.642857142857142,
      "grad_norm": 0.014686443842947483,
      "learning_rate": 1.08e-05,
      "loss": 0.0,
      "step": 2750
    },
    {
      "epoch": 19.65714285714286,
      "grad_norm": 0.013166658580303192,
      "learning_rate": 1.0771428571428572e-05,
      "loss": 0.0,
      "step": 2752
    },
    {
      "epoch": 19.67142857142857,
      "grad_norm": 0.008534526452422142,
      "learning_rate": 1.0742857142857144e-05,
      "loss": 0.0,
      "step": 2754
    },
    {
      "epoch": 19.685714285714287,
      "grad_norm": 0.010131158865988255,
      "learning_rate": 1.0714285714285714e-05,
      "loss": 0.0,
      "step": 2756
    },
    {
      "epoch": 19.7,
      "grad_norm": 0.017698291689157486,
      "learning_rate": 1.0685714285714286e-05,
      "loss": 0.0,
      "step": 2758
    },
    {
      "epoch": 19.714285714285715,
      "grad_norm": 0.006948987953364849,
      "learning_rate": 1.0657142857142858e-05,
      "loss": 0.0,
      "step": 2760
    },
    {
      "epoch": 19.728571428571428,
      "grad_norm": 0.010886716656386852,
      "learning_rate": 1.062857142857143e-05,
      "loss": 0.0,
      "step": 2762
    },
    {
      "epoch": 19.742857142857144,
      "grad_norm": 0.010951858013868332,
      "learning_rate": 1.06e-05,
      "loss": 0.0,
      "step": 2764
    },
    {
      "epoch": 19.757142857142856,
      "grad_norm": 0.014384913258254528,
      "learning_rate": 1.0571428571428572e-05,
      "loss": 0.0,
      "step": 2766
    },
    {
      "epoch": 19.771428571428572,
      "grad_norm": 0.013653166592121124,
      "learning_rate": 1.0542857142857144e-05,
      "loss": 0.0,
      "step": 2768
    },
    {
      "epoch": 19.785714285714285,
      "grad_norm": 0.01153987180441618,
      "learning_rate": 1.0514285714285716e-05,
      "loss": 0.0,
      "step": 2770
    },
    {
      "epoch": 19.8,
      "grad_norm": 0.017126968130469322,
      "learning_rate": 1.0485714285714286e-05,
      "loss": 0.0,
      "step": 2772
    },
    {
      "epoch": 19.814285714285713,
      "grad_norm": 0.007371164858341217,
      "learning_rate": 1.0457142857142856e-05,
      "loss": 0.0,
      "step": 2774
    },
    {
      "epoch": 19.82857142857143,
      "grad_norm": 0.008818763308227062,
      "learning_rate": 1.0428571428571428e-05,
      "loss": 0.0,
      "step": 2776
    },
    {
      "epoch": 19.84285714285714,
      "grad_norm": 0.015020209364593029,
      "learning_rate": 1.04e-05,
      "loss": 0.0,
      "step": 2778
    },
    {
      "epoch": 19.857142857142858,
      "grad_norm": 0.01083984412252903,
      "learning_rate": 1.0371428571428572e-05,
      "loss": 0.0,
      "step": 2780
    },
    {
      "epoch": 19.87142857142857,
      "grad_norm": 0.014071098528802395,
      "learning_rate": 1.0342857142857143e-05,
      "loss": 0.0,
      "step": 2782
    },
    {
      "epoch": 19.885714285714286,
      "grad_norm": 0.011562200263142586,
      "learning_rate": 1.0314285714285715e-05,
      "loss": 0.0,
      "step": 2784
    },
    {
      "epoch": 19.9,
      "grad_norm": 0.009234819561243057,
      "learning_rate": 1.0285714285714286e-05,
      "loss": 0.0,
      "step": 2786
    },
    {
      "epoch": 19.914285714285715,
      "grad_norm": 0.007839243859052658,
      "learning_rate": 1.0257142857142858e-05,
      "loss": 0.0,
      "step": 2788
    },
    {
      "epoch": 19.928571428571427,
      "grad_norm": 0.016102420166134834,
      "learning_rate": 1.0228571428571429e-05,
      "loss": 0.0,
      "step": 2790
    },
    {
      "epoch": 19.942857142857143,
      "grad_norm": 0.0178461242467165,
      "learning_rate": 1.02e-05,
      "loss": 0.0,
      "step": 2792
    },
    {
      "epoch": 19.957142857142856,
      "grad_norm": 0.013102071359753609,
      "learning_rate": 1.0171428571428573e-05,
      "loss": 0.0,
      "step": 2794
    },
    {
      "epoch": 19.97142857142857,
      "grad_norm": 0.008993184193968773,
      "learning_rate": 1.0142857142857143e-05,
      "loss": 0.0,
      "step": 2796
    },
    {
      "epoch": 19.985714285714288,
      "grad_norm": 0.02575409971177578,
      "learning_rate": 1.0114285714285715e-05,
      "loss": 0.0,
      "step": 2798
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.018508369103074074,
      "learning_rate": 1.0085714285714287e-05,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 20.0,
      "eval_cer": 0.003395585738539898,
      "eval_loss": 0.013994339853525162,
      "eval_runtime": 12.8467,
      "eval_samples_per_second": 21.718,
      "eval_steps_per_second": 2.724,
      "step": 2800
    },
    {
      "epoch": 20.014285714285716,
      "grad_norm": 0.007739274296909571,
      "learning_rate": 1.0057142857142859e-05,
      "loss": 0.0,
      "step": 2802
    },
    {
      "epoch": 20.02857142857143,
      "grad_norm": 0.0167059525847435,
      "learning_rate": 1.0028571428571429e-05,
      "loss": 0.0,
      "step": 2804
    },
    {
      "epoch": 20.042857142857144,
      "grad_norm": 0.011883677914738655,
      "learning_rate": 1e-05,
      "loss": 0.0,
      "step": 2806
    },
    {
      "epoch": 20.057142857142857,
      "grad_norm": 0.009456703439354897,
      "learning_rate": 9.971428571428571e-06,
      "loss": 0.0,
      "step": 2808
    },
    {
      "epoch": 20.071428571428573,
      "grad_norm": 0.00730988709256053,
      "learning_rate": 9.942857142857143e-06,
      "loss": 0.0,
      "step": 2810
    },
    {
      "epoch": 20.085714285714285,
      "grad_norm": 0.014609051868319511,
      "learning_rate": 9.914285714285715e-06,
      "loss": 0.0,
      "step": 2812
    },
    {
      "epoch": 20.1,
      "grad_norm": 0.008793288841843605,
      "learning_rate": 9.885714285714285e-06,
      "loss": 0.0,
      "step": 2814
    },
    {
      "epoch": 20.114285714285714,
      "grad_norm": 0.01223477628082037,
      "learning_rate": 9.857142857142857e-06,
      "loss": 0.0,
      "step": 2816
    },
    {
      "epoch": 20.12857142857143,
      "grad_norm": 0.012919380329549313,
      "learning_rate": 9.828571428571429e-06,
      "loss": 0.0,
      "step": 2818
    },
    {
      "epoch": 20.142857142857142,
      "grad_norm": 0.011130017228424549,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.0,
      "step": 2820
    },
    {
      "epoch": 20.15714285714286,
      "grad_norm": 0.01836502179503441,
      "learning_rate": 9.771428571428571e-06,
      "loss": 0.0,
      "step": 2822
    },
    {
      "epoch": 20.17142857142857,
      "grad_norm": 0.009050879627466202,
      "learning_rate": 9.742857142857143e-06,
      "loss": 0.0,
      "step": 2824
    },
    {
      "epoch": 20.185714285714287,
      "grad_norm": 0.01113450713455677,
      "learning_rate": 9.714285714285715e-06,
      "loss": 0.0,
      "step": 2826
    },
    {
      "epoch": 20.2,
      "grad_norm": 0.016745422035455704,
      "learning_rate": 9.685714285714287e-06,
      "loss": 0.0,
      "step": 2828
    },
    {
      "epoch": 20.214285714285715,
      "grad_norm": 0.015193488448858261,
      "learning_rate": 9.657142857142857e-06,
      "loss": 0.0,
      "step": 2830
    },
    {
      "epoch": 20.228571428571428,
      "grad_norm": 0.010540955699980259,
      "learning_rate": 9.628571428571428e-06,
      "loss": 0.0,
      "step": 2832
    },
    {
      "epoch": 20.242857142857144,
      "grad_norm": 0.006184113211929798,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0,
      "step": 2834
    },
    {
      "epoch": 20.257142857142856,
      "grad_norm": 0.01205877773463726,
      "learning_rate": 9.571428571428572e-06,
      "loss": 0.0,
      "step": 2836
    },
    {
      "epoch": 20.271428571428572,
      "grad_norm": 0.011620782315731049,
      "learning_rate": 9.542857142857143e-06,
      "loss": 0.0,
      "step": 2838
    },
    {
      "epoch": 20.285714285714285,
      "grad_norm": 0.008040154352784157,
      "learning_rate": 9.514285714285714e-06,
      "loss": 0.0,
      "step": 2840
    },
    {
      "epoch": 20.3,
      "grad_norm": 0.014914928935468197,
      "learning_rate": 9.485714285714287e-06,
      "loss": 0.0,
      "step": 2842
    },
    {
      "epoch": 20.314285714285713,
      "grad_norm": 0.015738729387521744,
      "learning_rate": 9.457142857142858e-06,
      "loss": 0.0,
      "step": 2844
    },
    {
      "epoch": 20.32857142857143,
      "grad_norm": 0.014013364911079407,
      "learning_rate": 9.42857142857143e-06,
      "loss": 0.0,
      "step": 2846
    },
    {
      "epoch": 20.34285714285714,
      "grad_norm": 0.009472324512898922,
      "learning_rate": 9.4e-06,
      "loss": 0.0,
      "step": 2848
    },
    {
      "epoch": 20.357142857142858,
      "grad_norm": 0.012050814926624298,
      "learning_rate": 9.371428571428572e-06,
      "loss": 0.0,
      "step": 2850
    },
    {
      "epoch": 20.37142857142857,
      "grad_norm": 0.015038570389151573,
      "learning_rate": 9.342857142857144e-06,
      "loss": 0.0,
      "step": 2852
    },
    {
      "epoch": 20.385714285714286,
      "grad_norm": 0.018490998074412346,
      "learning_rate": 9.314285714285714e-06,
      "loss": 0.0,
      "step": 2854
    },
    {
      "epoch": 20.4,
      "grad_norm": 0.014251478016376495,
      "learning_rate": 9.285714285714286e-06,
      "loss": 0.0,
      "step": 2856
    },
    {
      "epoch": 20.414285714285715,
      "grad_norm": 0.008868875913321972,
      "learning_rate": 9.257142857142858e-06,
      "loss": 0.0,
      "step": 2858
    },
    {
      "epoch": 20.428571428571427,
      "grad_norm": 0.016349269077181816,
      "learning_rate": 9.22857142857143e-06,
      "loss": 0.0,
      "step": 2860
    },
    {
      "epoch": 20.442857142857143,
      "grad_norm": 0.01423556637018919,
      "learning_rate": 9.2e-06,
      "loss": 0.0,
      "step": 2862
    },
    {
      "epoch": 20.457142857142856,
      "grad_norm": 0.009893356822431087,
      "learning_rate": 9.171428571428572e-06,
      "loss": 0.0,
      "step": 2864
    },
    {
      "epoch": 20.47142857142857,
      "grad_norm": 0.008503183722496033,
      "learning_rate": 9.142857142857144e-06,
      "loss": 0.0,
      "step": 2866
    },
    {
      "epoch": 20.485714285714284,
      "grad_norm": 0.010811511427164078,
      "learning_rate": 9.114285714285714e-06,
      "loss": 0.0,
      "step": 2868
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.010011991485953331,
      "learning_rate": 9.085714285714286e-06,
      "loss": 0.0,
      "step": 2870
    },
    {
      "epoch": 20.514285714285712,
      "grad_norm": 0.012112068012356758,
      "learning_rate": 9.057142857142856e-06,
      "loss": 0.0,
      "step": 2872
    },
    {
      "epoch": 20.52857142857143,
      "grad_norm": 0.006897564511746168,
      "learning_rate": 9.02857142857143e-06,
      "loss": 0.0,
      "step": 2874
    },
    {
      "epoch": 20.542857142857144,
      "grad_norm": 0.012240268290042877,
      "learning_rate": 9e-06,
      "loss": 0.0,
      "step": 2876
    },
    {
      "epoch": 20.557142857142857,
      "grad_norm": 0.016031986102461815,
      "learning_rate": 8.971428571428572e-06,
      "loss": 0.0,
      "step": 2878
    },
    {
      "epoch": 20.571428571428573,
      "grad_norm": 0.010681659914553165,
      "learning_rate": 8.942857142857142e-06,
      "loss": 0.0,
      "step": 2880
    },
    {
      "epoch": 20.585714285714285,
      "grad_norm": 0.010163945145905018,
      "learning_rate": 8.914285714285716e-06,
      "loss": 0.0,
      "step": 2882
    },
    {
      "epoch": 20.6,
      "grad_norm": 0.014511429704725742,
      "learning_rate": 8.885714285714286e-06,
      "loss": 0.0,
      "step": 2884
    },
    {
      "epoch": 20.614285714285714,
      "grad_norm": 0.02205774188041687,
      "learning_rate": 8.857142857142857e-06,
      "loss": 0.0,
      "step": 2886
    },
    {
      "epoch": 20.62857142857143,
      "grad_norm": 0.027816200628876686,
      "learning_rate": 8.828571428571429e-06,
      "loss": 0.0,
      "step": 2888
    },
    {
      "epoch": 20.642857142857142,
      "grad_norm": 0.010927938856184483,
      "learning_rate": 8.8e-06,
      "loss": 0.0,
      "step": 2890
    },
    {
      "epoch": 20.65714285714286,
      "grad_norm": 0.014749802649021149,
      "learning_rate": 8.771428571428572e-06,
      "loss": 0.0,
      "step": 2892
    },
    {
      "epoch": 20.67142857142857,
      "grad_norm": 0.013350424356758595,
      "learning_rate": 8.742857142857143e-06,
      "loss": 0.0,
      "step": 2894
    },
    {
      "epoch": 20.685714285714287,
      "grad_norm": 0.02452407404780388,
      "learning_rate": 8.714285714285715e-06,
      "loss": 0.0001,
      "step": 2896
    },
    {
      "epoch": 20.7,
      "grad_norm": 0.017698705196380615,
      "learning_rate": 8.685714285714287e-06,
      "loss": 0.0,
      "step": 2898
    },
    {
      "epoch": 20.714285714285715,
      "grad_norm": 0.014511783607304096,
      "learning_rate": 8.657142857142858e-06,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 20.728571428571428,
      "grad_norm": 0.008031719364225864,
      "learning_rate": 8.628571428571429e-06,
      "loss": 0.0,
      "step": 2902
    },
    {
      "epoch": 20.742857142857144,
      "grad_norm": 0.020540187135338783,
      "learning_rate": 8.599999999999999e-06,
      "loss": 0.0,
      "step": 2904
    },
    {
      "epoch": 20.757142857142856,
      "grad_norm": 0.01372812781482935,
      "learning_rate": 8.571428571428573e-06,
      "loss": 0.0,
      "step": 2906
    },
    {
      "epoch": 20.771428571428572,
      "grad_norm": 0.012100276537239552,
      "learning_rate": 8.542857142857143e-06,
      "loss": 0.0,
      "step": 2908
    },
    {
      "epoch": 20.785714285714285,
      "grad_norm": 0.013778714463114738,
      "learning_rate": 8.514285714285715e-06,
      "loss": 0.0,
      "step": 2910
    },
    {
      "epoch": 20.8,
      "grad_norm": 0.009909420274198055,
      "learning_rate": 8.485714285714285e-06,
      "loss": 0.0,
      "step": 2912
    },
    {
      "epoch": 20.814285714285713,
      "grad_norm": 0.015179723501205444,
      "learning_rate": 8.457142857142859e-06,
      "loss": 0.0,
      "step": 2914
    },
    {
      "epoch": 20.82857142857143,
      "grad_norm": 0.009633324109017849,
      "learning_rate": 8.428571428571429e-06,
      "loss": 0.0,
      "step": 2916
    },
    {
      "epoch": 20.84285714285714,
      "grad_norm": 0.011943144723773003,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0,
      "step": 2918
    },
    {
      "epoch": 20.857142857142858,
      "grad_norm": 0.00755916815251112,
      "learning_rate": 8.371428571428571e-06,
      "loss": 0.0,
      "step": 2920
    },
    {
      "epoch": 20.87142857142857,
      "grad_norm": 0.009072629734873772,
      "learning_rate": 8.342857142857143e-06,
      "loss": 0.0,
      "step": 2922
    },
    {
      "epoch": 20.885714285714286,
      "grad_norm": 0.00924630556255579,
      "learning_rate": 8.314285714285715e-06,
      "loss": 0.0,
      "step": 2924
    },
    {
      "epoch": 20.9,
      "grad_norm": 0.0138010298833251,
      "learning_rate": 8.285714285714285e-06,
      "loss": 0.0,
      "step": 2926
    },
    {
      "epoch": 20.914285714285715,
      "grad_norm": 0.010707949288189411,
      "learning_rate": 8.257142857142857e-06,
      "loss": 0.0,
      "step": 2928
    },
    {
      "epoch": 20.928571428571427,
      "grad_norm": 0.007317167706787586,
      "learning_rate": 8.22857142857143e-06,
      "loss": 0.0,
      "step": 2930
    },
    {
      "epoch": 20.942857142857143,
      "grad_norm": 0.014563657343387604,
      "learning_rate": 8.200000000000001e-06,
      "loss": 0.0,
      "step": 2932
    },
    {
      "epoch": 20.957142857142856,
      "grad_norm": 0.0053980848751962185,
      "learning_rate": 8.171428571428571e-06,
      "loss": 0.0,
      "step": 2934
    },
    {
      "epoch": 20.97142857142857,
      "grad_norm": 0.014262374490499496,
      "learning_rate": 8.142857142857143e-06,
      "loss": 0.0,
      "step": 2936
    },
    {
      "epoch": 20.985714285714288,
      "grad_norm": 0.01466911006718874,
      "learning_rate": 8.114285714285715e-06,
      "loss": 0.0,
      "step": 2938
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.008212032727897167,
      "learning_rate": 8.085714285714287e-06,
      "loss": 0.0,
      "step": 2940
    },
    {
      "epoch": 21.014285714285716,
      "grad_norm": 0.00601525604724884,
      "learning_rate": 8.057142857142857e-06,
      "loss": 0.0,
      "step": 2942
    },
    {
      "epoch": 21.02857142857143,
      "grad_norm": 0.012297866865992546,
      "learning_rate": 8.028571428571428e-06,
      "loss": 0.0,
      "step": 2944
    },
    {
      "epoch": 21.042857142857144,
      "grad_norm": 0.010217043571174145,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0,
      "step": 2946
    },
    {
      "epoch": 21.057142857142857,
      "grad_norm": 0.01912711374461651,
      "learning_rate": 7.971428571428572e-06,
      "loss": 0.0,
      "step": 2948
    },
    {
      "epoch": 21.071428571428573,
      "grad_norm": 0.015764426440000534,
      "learning_rate": 7.942857142857144e-06,
      "loss": 0.0,
      "step": 2950
    },
    {
      "epoch": 21.085714285714285,
      "grad_norm": 0.016571516171097755,
      "learning_rate": 7.914285714285714e-06,
      "loss": 0.0,
      "step": 2952
    },
    {
      "epoch": 21.1,
      "grad_norm": 0.012249745428562164,
      "learning_rate": 7.885714285714286e-06,
      "loss": 0.0,
      "step": 2954
    },
    {
      "epoch": 21.114285714285714,
      "grad_norm": 0.009672185406088829,
      "learning_rate": 7.857142857142858e-06,
      "loss": 0.0,
      "step": 2956
    },
    {
      "epoch": 21.12857142857143,
      "grad_norm": 0.003820036770775914,
      "learning_rate": 7.82857142857143e-06,
      "loss": 0.0,
      "step": 2958
    },
    {
      "epoch": 21.142857142857142,
      "grad_norm": 0.014180613681674004,
      "learning_rate": 7.8e-06,
      "loss": 0.0,
      "step": 2960
    },
    {
      "epoch": 21.15714285714286,
      "grad_norm": 0.011562656611204147,
      "learning_rate": 7.771428571428572e-06,
      "loss": 0.0,
      "step": 2962
    },
    {
      "epoch": 21.17142857142857,
      "grad_norm": 0.009663522243499756,
      "learning_rate": 7.742857142857144e-06,
      "loss": 0.0,
      "step": 2964
    },
    {
      "epoch": 21.185714285714287,
      "grad_norm": 0.01326314453035593,
      "learning_rate": 7.714285714285714e-06,
      "loss": 0.0,
      "step": 2966
    },
    {
      "epoch": 21.2,
      "grad_norm": 0.01656031236052513,
      "learning_rate": 7.685714285714286e-06,
      "loss": 0.0,
      "step": 2968
    },
    {
      "epoch": 21.214285714285715,
      "grad_norm": 0.012526098638772964,
      "learning_rate": 7.657142857142858e-06,
      "loss": 0.0,
      "step": 2970
    },
    {
      "epoch": 21.228571428571428,
      "grad_norm": 0.008111749775707722,
      "learning_rate": 7.628571428571429e-06,
      "loss": 0.0,
      "step": 2972
    },
    {
      "epoch": 21.242857142857144,
      "grad_norm": 0.01194838248193264,
      "learning_rate": 7.6e-06,
      "loss": 0.0,
      "step": 2974
    },
    {
      "epoch": 21.257142857142856,
      "grad_norm": 0.01390457060188055,
      "learning_rate": 7.571428571428572e-06,
      "loss": 0.0,
      "step": 2976
    },
    {
      "epoch": 21.271428571428572,
      "grad_norm": 0.007850944064557552,
      "learning_rate": 7.542857142857143e-06,
      "loss": 0.0,
      "step": 2978
    },
    {
      "epoch": 21.285714285714285,
      "grad_norm": 0.0115200811997056,
      "learning_rate": 7.514285714285714e-06,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 21.3,
      "grad_norm": 0.010833242908120155,
      "learning_rate": 7.485714285714286e-06,
      "loss": 0.0,
      "step": 2982
    },
    {
      "epoch": 21.314285714285713,
      "grad_norm": 0.021684497594833374,
      "learning_rate": 7.457142857142857e-06,
      "loss": 0.0,
      "step": 2984
    },
    {
      "epoch": 21.32857142857143,
      "grad_norm": 0.016940027475357056,
      "learning_rate": 7.428571428571429e-06,
      "loss": 0.0,
      "step": 2986
    },
    {
      "epoch": 21.34285714285714,
      "grad_norm": 0.00880262441933155,
      "learning_rate": 7.4e-06,
      "loss": 0.0,
      "step": 2988
    },
    {
      "epoch": 21.357142857142858,
      "grad_norm": 0.004689779132604599,
      "learning_rate": 7.371428571428572e-06,
      "loss": 0.0,
      "step": 2990
    },
    {
      "epoch": 21.37142857142857,
      "grad_norm": 0.024831369519233704,
      "learning_rate": 7.342857142857143e-06,
      "loss": 0.0,
      "step": 2992
    },
    {
      "epoch": 21.385714285714286,
      "grad_norm": 0.014679166488349438,
      "learning_rate": 7.314285714285715e-06,
      "loss": 0.0,
      "step": 2994
    },
    {
      "epoch": 21.4,
      "grad_norm": 0.01675097830593586,
      "learning_rate": 7.285714285714286e-06,
      "loss": 0.0,
      "step": 2996
    },
    {
      "epoch": 21.414285714285715,
      "grad_norm": 0.007705361116677523,
      "learning_rate": 7.257142857142857e-06,
      "loss": 0.0,
      "step": 2998
    },
    {
      "epoch": 21.428571428571427,
      "grad_norm": 0.014877203851938248,
      "learning_rate": 7.228571428571429e-06,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 21.428571428571427,
      "eval_cer": 0.003395585738539898,
      "eval_loss": 0.014816002920269966,
      "eval_runtime": 10.9302,
      "eval_samples_per_second": 25.526,
      "eval_steps_per_second": 3.202,
      "step": 3000
    },
    {
      "epoch": 21.442857142857143,
      "grad_norm": 0.01629319041967392,
      "learning_rate": 7.2e-06,
      "loss": 0.0,
      "step": 3002
    },
    {
      "epoch": 21.457142857142856,
      "grad_norm": 0.01363687589764595,
      "learning_rate": 7.171428571428572e-06,
      "loss": 0.0,
      "step": 3004
    },
    {
      "epoch": 21.47142857142857,
      "grad_norm": 0.011452839709818363,
      "learning_rate": 7.142857142857143e-06,
      "loss": 0.0,
      "step": 3006
    },
    {
      "epoch": 21.485714285714284,
      "grad_norm": 0.007747937925159931,
      "learning_rate": 7.114285714285715e-06,
      "loss": 0.0,
      "step": 3008
    },
    {
      "epoch": 21.5,
      "grad_norm": 0.009548894129693508,
      "learning_rate": 7.085714285714286e-06,
      "loss": 0.0,
      "step": 3010
    },
    {
      "epoch": 21.514285714285712,
      "grad_norm": 0.013981034979224205,
      "learning_rate": 7.057142857142858e-06,
      "loss": 0.0,
      "step": 3012
    },
    {
      "epoch": 21.52857142857143,
      "grad_norm": 0.017490511760115623,
      "learning_rate": 7.028571428571429e-06,
      "loss": 0.0,
      "step": 3014
    },
    {
      "epoch": 21.542857142857144,
      "grad_norm": 0.01692439243197441,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.0,
      "step": 3016
    },
    {
      "epoch": 21.557142857142857,
      "grad_norm": 0.013330547139048576,
      "learning_rate": 6.971428571428572e-06,
      "loss": 0.0,
      "step": 3018
    },
    {
      "epoch": 21.571428571428573,
      "grad_norm": 0.013608403503894806,
      "learning_rate": 6.942857142857143e-06,
      "loss": 0.0,
      "step": 3020
    },
    {
      "epoch": 21.585714285714285,
      "grad_norm": 0.011282007209956646,
      "learning_rate": 6.914285714285715e-06,
      "loss": 0.0,
      "step": 3022
    },
    {
      "epoch": 21.6,
      "grad_norm": 0.011456210166215897,
      "learning_rate": 6.885714285714286e-06,
      "loss": 0.0,
      "step": 3024
    },
    {
      "epoch": 21.614285714285714,
      "grad_norm": 0.008110889233648777,
      "learning_rate": 6.857142857142858e-06,
      "loss": 0.0,
      "step": 3026
    },
    {
      "epoch": 21.62857142857143,
      "grad_norm": 0.01291718427091837,
      "learning_rate": 6.828571428571429e-06,
      "loss": 0.0,
      "step": 3028
    },
    {
      "epoch": 21.642857142857142,
      "grad_norm": 0.01470550149679184,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0,
      "step": 3030
    },
    {
      "epoch": 21.65714285714286,
      "grad_norm": 0.019955841824412346,
      "learning_rate": 6.771428571428571e-06,
      "loss": 0.0,
      "step": 3032
    },
    {
      "epoch": 21.67142857142857,
      "grad_norm": 0.010826709680259228,
      "learning_rate": 6.742857142857144e-06,
      "loss": 0.0,
      "step": 3034
    },
    {
      "epoch": 21.685714285714287,
      "grad_norm": 0.00954914465546608,
      "learning_rate": 6.714285714285714e-06,
      "loss": 0.0,
      "step": 3036
    },
    {
      "epoch": 21.7,
      "grad_norm": 0.01596442051231861,
      "learning_rate": 6.685714285714285e-06,
      "loss": 0.0,
      "step": 3038
    },
    {
      "epoch": 21.714285714285715,
      "grad_norm": 0.008473161607980728,
      "learning_rate": 6.657142857142857e-06,
      "loss": 0.0,
      "step": 3040
    },
    {
      "epoch": 21.728571428571428,
      "grad_norm": 0.01152766402810812,
      "learning_rate": 6.628571428571428e-06,
      "loss": 0.0,
      "step": 3042
    },
    {
      "epoch": 21.742857142857144,
      "grad_norm": 0.00610712356865406,
      "learning_rate": 6.6e-06,
      "loss": 0.0,
      "step": 3044
    },
    {
      "epoch": 21.757142857142856,
      "grad_norm": 0.010702239349484444,
      "learning_rate": 6.5714285714285714e-06,
      "loss": 0.0,
      "step": 3046
    },
    {
      "epoch": 21.771428571428572,
      "grad_norm": 0.00955264177173376,
      "learning_rate": 6.542857142857143e-06,
      "loss": 0.0,
      "step": 3048
    },
    {
      "epoch": 21.785714285714285,
      "grad_norm": 0.009996247477829456,
      "learning_rate": 6.5142857142857145e-06,
      "loss": 0.0,
      "step": 3050
    },
    {
      "epoch": 21.8,
      "grad_norm": 0.015925580635666847,
      "learning_rate": 6.485714285714286e-06,
      "loss": 0.0,
      "step": 3052
    },
    {
      "epoch": 21.814285714285713,
      "grad_norm": 0.014963919296860695,
      "learning_rate": 6.4571428571428575e-06,
      "loss": 0.0,
      "step": 3054
    },
    {
      "epoch": 21.82857142857143,
      "grad_norm": 0.009636442176997662,
      "learning_rate": 6.428571428571429e-06,
      "loss": 0.0,
      "step": 3056
    },
    {
      "epoch": 21.84285714285714,
      "grad_norm": 0.01544408779591322,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0,
      "step": 3058
    },
    {
      "epoch": 21.857142857142858,
      "grad_norm": 0.016224604099988937,
      "learning_rate": 6.371428571428572e-06,
      "loss": 0.0,
      "step": 3060
    },
    {
      "epoch": 21.87142857142857,
      "grad_norm": 0.026125149801373482,
      "learning_rate": 6.342857142857144e-06,
      "loss": 0.0,
      "step": 3062
    },
    {
      "epoch": 21.885714285714286,
      "grad_norm": 0.01102600246667862,
      "learning_rate": 6.314285714285714e-06,
      "loss": 0.0,
      "step": 3064
    },
    {
      "epoch": 21.9,
      "grad_norm": 0.012505311518907547,
      "learning_rate": 6.285714285714287e-06,
      "loss": 0.0,
      "step": 3066
    },
    {
      "epoch": 21.914285714285715,
      "grad_norm": 0.01166140753775835,
      "learning_rate": 6.257142857142857e-06,
      "loss": 0.0,
      "step": 3068
    },
    {
      "epoch": 21.928571428571427,
      "grad_norm": 0.009424496442079544,
      "learning_rate": 6.228571428571429e-06,
      "loss": 0.0,
      "step": 3070
    },
    {
      "epoch": 21.942857142857143,
      "grad_norm": 0.012682347558438778,
      "learning_rate": 6.2e-06,
      "loss": 0.0,
      "step": 3072
    },
    {
      "epoch": 21.957142857142856,
      "grad_norm": 0.00631501991301775,
      "learning_rate": 6.171428571428572e-06,
      "loss": 0.0,
      "step": 3074
    },
    {
      "epoch": 21.97142857142857,
      "grad_norm": 0.006375083699822426,
      "learning_rate": 6.142857142857143e-06,
      "loss": 0.0,
      "step": 3076
    },
    {
      "epoch": 21.985714285714288,
      "grad_norm": 0.017538433894515038,
      "learning_rate": 6.114285714285715e-06,
      "loss": 0.0,
      "step": 3078
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.01647677645087242,
      "learning_rate": 6.085714285714286e-06,
      "loss": 0.0,
      "step": 3080
    },
    {
      "epoch": 22.014285714285716,
      "grad_norm": 0.013807634823024273,
      "learning_rate": 6.057142857142858e-06,
      "loss": 0.0,
      "step": 3082
    },
    {
      "epoch": 22.02857142857143,
      "grad_norm": 0.007125087082386017,
      "learning_rate": 6.028571428571428e-06,
      "loss": 0.0,
      "step": 3084
    },
    {
      "epoch": 22.042857142857144,
      "grad_norm": 0.01978796161711216,
      "learning_rate": 6e-06,
      "loss": 0.0,
      "step": 3086
    },
    {
      "epoch": 22.057142857142857,
      "grad_norm": 0.008329451084136963,
      "learning_rate": 5.971428571428571e-06,
      "loss": 0.0,
      "step": 3088
    },
    {
      "epoch": 22.071428571428573,
      "grad_norm": 0.006154219154268503,
      "learning_rate": 5.942857142857143e-06,
      "loss": 0.0,
      "step": 3090
    },
    {
      "epoch": 22.085714285714285,
      "grad_norm": 0.0072456058114767075,
      "learning_rate": 5.914285714285714e-06,
      "loss": 0.0,
      "step": 3092
    },
    {
      "epoch": 22.1,
      "grad_norm": 0.018269434571266174,
      "learning_rate": 5.885714285714286e-06,
      "loss": 0.0,
      "step": 3094
    },
    {
      "epoch": 22.114285714285714,
      "grad_norm": 0.009220924228429794,
      "learning_rate": 5.857142857142857e-06,
      "loss": 0.0,
      "step": 3096
    },
    {
      "epoch": 22.12857142857143,
      "grad_norm": 0.010467004030942917,
      "learning_rate": 5.828571428571429e-06,
      "loss": 0.0,
      "step": 3098
    },
    {
      "epoch": 22.142857142857142,
      "grad_norm": 0.010307804681360722,
      "learning_rate": 5.8e-06,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 22.15714285714286,
      "grad_norm": 0.007389598526060581,
      "learning_rate": 5.7714285714285715e-06,
      "loss": 0.0,
      "step": 3102
    },
    {
      "epoch": 22.17142857142857,
      "grad_norm": 0.021076766774058342,
      "learning_rate": 5.7428571428571426e-06,
      "loss": 0.0,
      "step": 3104
    },
    {
      "epoch": 22.185714285714287,
      "grad_norm": 0.007529795169830322,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.0,
      "step": 3106
    },
    {
      "epoch": 22.2,
      "grad_norm": 0.007139142602682114,
      "learning_rate": 5.685714285714286e-06,
      "loss": 0.0,
      "step": 3108
    },
    {
      "epoch": 22.214285714285715,
      "grad_norm": 0.012643296271562576,
      "learning_rate": 5.6571428571428576e-06,
      "loss": 0.0,
      "step": 3110
    },
    {
      "epoch": 22.228571428571428,
      "grad_norm": 0.014283496886491776,
      "learning_rate": 5.628571428571429e-06,
      "loss": 0.0,
      "step": 3112
    },
    {
      "epoch": 22.242857142857144,
      "grad_norm": 0.005568979308009148,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0,
      "step": 3114
    },
    {
      "epoch": 22.257142857142856,
      "grad_norm": 0.010370228439569473,
      "learning_rate": 5.571428571428572e-06,
      "loss": 0.0,
      "step": 3116
    },
    {
      "epoch": 22.271428571428572,
      "grad_norm": 0.0068989647552371025,
      "learning_rate": 5.542857142857144e-06,
      "loss": 0.0,
      "step": 3118
    },
    {
      "epoch": 22.285714285714285,
      "grad_norm": 0.009086593985557556,
      "learning_rate": 5.514285714285715e-06,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 22.3,
      "grad_norm": 0.011118871159851551,
      "learning_rate": 5.485714285714286e-06,
      "loss": 0.0,
      "step": 3122
    },
    {
      "epoch": 22.314285714285713,
      "grad_norm": 0.012141807936131954,
      "learning_rate": 5.457142857142857e-06,
      "loss": 0.0,
      "step": 3124
    },
    {
      "epoch": 22.32857142857143,
      "grad_norm": 0.011936474591493607,
      "learning_rate": 5.428571428571429e-06,
      "loss": 0.0,
      "step": 3126
    },
    {
      "epoch": 22.34285714285714,
      "grad_norm": 0.010281704366207123,
      "learning_rate": 5.4e-06,
      "loss": 0.0,
      "step": 3128
    },
    {
      "epoch": 22.357142857142858,
      "grad_norm": 0.012618509121239185,
      "learning_rate": 5.371428571428572e-06,
      "loss": 0.0,
      "step": 3130
    },
    {
      "epoch": 22.37142857142857,
      "grad_norm": 0.014495603740215302,
      "learning_rate": 5.342857142857143e-06,
      "loss": 0.0,
      "step": 3132
    },
    {
      "epoch": 22.385714285714286,
      "grad_norm": 0.00962782371789217,
      "learning_rate": 5.314285714285715e-06,
      "loss": 0.0,
      "step": 3134
    },
    {
      "epoch": 22.4,
      "grad_norm": 0.016737351194024086,
      "learning_rate": 5.285714285714286e-06,
      "loss": 0.0,
      "step": 3136
    },
    {
      "epoch": 22.414285714285715,
      "grad_norm": 0.022228369489312172,
      "learning_rate": 5.257142857142858e-06,
      "loss": 0.0,
      "step": 3138
    },
    {
      "epoch": 22.428571428571427,
      "grad_norm": 0.013054206036031246,
      "learning_rate": 5.228571428571428e-06,
      "loss": 0.0,
      "step": 3140
    },
    {
      "epoch": 22.442857142857143,
      "grad_norm": 0.012541660107672215,
      "learning_rate": 5.2e-06,
      "loss": 0.0,
      "step": 3142
    },
    {
      "epoch": 22.457142857142856,
      "grad_norm": 0.0054624867625534534,
      "learning_rate": 5.171428571428571e-06,
      "loss": 0.0,
      "step": 3144
    },
    {
      "epoch": 22.47142857142857,
      "grad_norm": 0.014356674626469612,
      "learning_rate": 5.142857142857143e-06,
      "loss": 0.0,
      "step": 3146
    },
    {
      "epoch": 22.485714285714284,
      "grad_norm": 0.007604015059769154,
      "learning_rate": 5.114285714285714e-06,
      "loss": 0.0,
      "step": 3148
    },
    {
      "epoch": 22.5,
      "grad_norm": 0.011188824661076069,
      "learning_rate": 5.085714285714286e-06,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 22.514285714285712,
      "grad_norm": 0.005667675752192736,
      "learning_rate": 5.057142857142857e-06,
      "loss": 0.0,
      "step": 3152
    },
    {
      "epoch": 22.52857142857143,
      "grad_norm": 0.010556541383266449,
      "learning_rate": 5.028571428571429e-06,
      "loss": 0.0,
      "step": 3154
    },
    {
      "epoch": 22.542857142857144,
      "grad_norm": 0.014306513592600822,
      "learning_rate": 5e-06,
      "loss": 0.0,
      "step": 3156
    },
    {
      "epoch": 22.557142857142857,
      "grad_norm": 0.011996754445135593,
      "learning_rate": 4.9714285714285715e-06,
      "loss": 0.0,
      "step": 3158
    },
    {
      "epoch": 22.571428571428573,
      "grad_norm": 0.010802572593092918,
      "learning_rate": 4.942857142857143e-06,
      "loss": 0.0,
      "step": 3160
    },
    {
      "epoch": 22.585714285714285,
      "grad_norm": 0.010486883111298084,
      "learning_rate": 4.9142857142857145e-06,
      "loss": 0.0,
      "step": 3162
    },
    {
      "epoch": 22.6,
      "grad_norm": 0.009481525048613548,
      "learning_rate": 4.885714285714286e-06,
      "loss": 0.0,
      "step": 3164
    },
    {
      "epoch": 22.614285714285714,
      "grad_norm": 0.006888480391353369,
      "learning_rate": 4.857142857142858e-06,
      "loss": 0.0,
      "step": 3166
    },
    {
      "epoch": 22.62857142857143,
      "grad_norm": 0.01894558034837246,
      "learning_rate": 4.828571428571429e-06,
      "loss": 0.0,
      "step": 3168
    },
    {
      "epoch": 22.642857142857142,
      "grad_norm": 0.010745281353592873,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0,
      "step": 3170
    },
    {
      "epoch": 22.65714285714286,
      "grad_norm": 0.014067300595343113,
      "learning_rate": 4.771428571428572e-06,
      "loss": 0.0,
      "step": 3172
    },
    {
      "epoch": 22.67142857142857,
      "grad_norm": 0.007700009271502495,
      "learning_rate": 4.742857142857144e-06,
      "loss": 0.0,
      "step": 3174
    },
    {
      "epoch": 22.685714285714287,
      "grad_norm": 0.015006966888904572,
      "learning_rate": 4.714285714285715e-06,
      "loss": 0.0,
      "step": 3176
    },
    {
      "epoch": 22.7,
      "grad_norm": 0.008437559939920902,
      "learning_rate": 4.685714285714286e-06,
      "loss": 0.0,
      "step": 3178
    },
    {
      "epoch": 22.714285714285715,
      "grad_norm": 0.014444438740611076,
      "learning_rate": 4.657142857142857e-06,
      "loss": 0.0,
      "step": 3180
    },
    {
      "epoch": 22.728571428571428,
      "grad_norm": 0.01944267563521862,
      "learning_rate": 4.628571428571429e-06,
      "loss": 0.0,
      "step": 3182
    },
    {
      "epoch": 22.742857142857144,
      "grad_norm": 0.006063512992113829,
      "learning_rate": 4.6e-06,
      "loss": 0.0,
      "step": 3184
    },
    {
      "epoch": 22.757142857142856,
      "grad_norm": 0.010582481510937214,
      "learning_rate": 4.571428571428572e-06,
      "loss": 0.0,
      "step": 3186
    },
    {
      "epoch": 22.771428571428572,
      "grad_norm": 0.017864879220724106,
      "learning_rate": 4.542857142857143e-06,
      "loss": 0.0,
      "step": 3188
    },
    {
      "epoch": 22.785714285714285,
      "grad_norm": 0.014552202075719833,
      "learning_rate": 4.514285714285715e-06,
      "loss": 0.0,
      "step": 3190
    },
    {
      "epoch": 22.8,
      "grad_norm": 0.012177962809801102,
      "learning_rate": 4.485714285714286e-06,
      "loss": 0.0,
      "step": 3192
    },
    {
      "epoch": 22.814285714285713,
      "grad_norm": 0.012385395355522633,
      "learning_rate": 4.457142857142858e-06,
      "loss": 0.0,
      "step": 3194
    },
    {
      "epoch": 22.82857142857143,
      "grad_norm": 0.007746320683509111,
      "learning_rate": 4.428571428571428e-06,
      "loss": 0.0,
      "step": 3196
    },
    {
      "epoch": 22.84285714285714,
      "grad_norm": 0.009530012495815754,
      "learning_rate": 4.4e-06,
      "loss": 0.0,
      "step": 3198
    },
    {
      "epoch": 22.857142857142858,
      "grad_norm": 0.011802486144006252,
      "learning_rate": 4.371428571428571e-06,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 22.857142857142858,
      "eval_cer": 0.003395585738539898,
      "eval_loss": 0.014986508525907993,
      "eval_runtime": 9.7012,
      "eval_samples_per_second": 28.759,
      "eval_steps_per_second": 3.608,
      "step": 3200
    },
    {
      "epoch": 22.87142857142857,
      "grad_norm": 0.01242391113191843,
      "learning_rate": 4.342857142857143e-06,
      "loss": 0.0,
      "step": 3202
    },
    {
      "epoch": 22.885714285714286,
      "grad_norm": 0.008114115335047245,
      "learning_rate": 4.314285714285714e-06,
      "loss": 0.0,
      "step": 3204
    },
    {
      "epoch": 22.9,
      "grad_norm": 0.016174212098121643,
      "learning_rate": 4.285714285714286e-06,
      "loss": 0.0,
      "step": 3206
    },
    {
      "epoch": 22.914285714285715,
      "grad_norm": 0.012780871242284775,
      "learning_rate": 4.257142857142857e-06,
      "loss": 0.0,
      "step": 3208
    },
    {
      "epoch": 22.928571428571427,
      "grad_norm": 0.010684202425181866,
      "learning_rate": 4.228571428571429e-06,
      "loss": 0.0,
      "step": 3210
    },
    {
      "epoch": 22.942857142857143,
      "grad_norm": 0.012006121687591076,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0,
      "step": 3212
    },
    {
      "epoch": 22.957142857142856,
      "grad_norm": 0.010235668160021305,
      "learning_rate": 4.1714285714285715e-06,
      "loss": 0.0,
      "step": 3214
    },
    {
      "epoch": 22.97142857142857,
      "grad_norm": 0.012073266319930553,
      "learning_rate": 4.142857142857143e-06,
      "loss": 0.0,
      "step": 3216
    },
    {
      "epoch": 22.985714285714288,
      "grad_norm": 0.006877549923956394,
      "learning_rate": 4.114285714285715e-06,
      "loss": 0.0,
      "step": 3218
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.008400587365031242,
      "learning_rate": 4.085714285714286e-06,
      "loss": 0.0,
      "step": 3220
    },
    {
      "epoch": 23.014285714285716,
      "grad_norm": 0.018093856051564217,
      "learning_rate": 4.057142857142858e-06,
      "loss": 0.0,
      "step": 3222
    },
    {
      "epoch": 23.02857142857143,
      "grad_norm": 0.00970308668911457,
      "learning_rate": 4.028571428571429e-06,
      "loss": 0.0,
      "step": 3224
    },
    {
      "epoch": 23.042857142857144,
      "grad_norm": 0.012603255920112133,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0,
      "step": 3226
    },
    {
      "epoch": 23.057142857142857,
      "grad_norm": 0.014902534894645214,
      "learning_rate": 3.971428571428572e-06,
      "loss": 0.0,
      "step": 3228
    },
    {
      "epoch": 23.071428571428573,
      "grad_norm": 0.01158767007291317,
      "learning_rate": 3.942857142857143e-06,
      "loss": 0.0,
      "step": 3230
    },
    {
      "epoch": 23.085714285714285,
      "grad_norm": 0.01418254617601633,
      "learning_rate": 3.914285714285715e-06,
      "loss": 0.0,
      "step": 3232
    },
    {
      "epoch": 23.1,
      "grad_norm": 0.011761057190597057,
      "learning_rate": 3.885714285714286e-06,
      "loss": 0.0,
      "step": 3234
    },
    {
      "epoch": 23.114285714285714,
      "grad_norm": 0.00781980250030756,
      "learning_rate": 3.857142857142857e-06,
      "loss": 0.0,
      "step": 3236
    },
    {
      "epoch": 23.12857142857143,
      "grad_norm": 0.010916084982454777,
      "learning_rate": 3.828571428571429e-06,
      "loss": 0.0,
      "step": 3238
    },
    {
      "epoch": 23.142857142857142,
      "grad_norm": 0.0072904322296381,
      "learning_rate": 3.8e-06,
      "loss": 0.0,
      "step": 3240
    },
    {
      "epoch": 23.15714285714286,
      "grad_norm": 0.014370821416378021,
      "learning_rate": 3.7714285714285716e-06,
      "loss": 0.0,
      "step": 3242
    },
    {
      "epoch": 23.17142857142857,
      "grad_norm": 0.009778615087270737,
      "learning_rate": 3.742857142857143e-06,
      "loss": 0.0,
      "step": 3244
    },
    {
      "epoch": 23.185714285714287,
      "grad_norm": 0.013688422739505768,
      "learning_rate": 3.7142857142857146e-06,
      "loss": 0.0,
      "step": 3246
    },
    {
      "epoch": 23.2,
      "grad_norm": 0.025811774656176567,
      "learning_rate": 3.685714285714286e-06,
      "loss": 0.0,
      "step": 3248
    },
    {
      "epoch": 23.214285714285715,
      "grad_norm": 0.010711741633713245,
      "learning_rate": 3.6571428571428576e-06,
      "loss": 0.0,
      "step": 3250
    },
    {
      "epoch": 23.228571428571428,
      "grad_norm": 0.010879695415496826,
      "learning_rate": 3.6285714285714283e-06,
      "loss": 0.0,
      "step": 3252
    },
    {
      "epoch": 23.242857142857144,
      "grad_norm": 0.015222089365124702,
      "learning_rate": 3.6e-06,
      "loss": 0.0,
      "step": 3254
    },
    {
      "epoch": 23.257142857142856,
      "grad_norm": 0.013258337043225765,
      "learning_rate": 3.5714285714285714e-06,
      "loss": 0.0,
      "step": 3256
    },
    {
      "epoch": 23.271428571428572,
      "grad_norm": 0.004680169280618429,
      "learning_rate": 3.542857142857143e-06,
      "loss": 0.0,
      "step": 3258
    },
    {
      "epoch": 23.285714285714285,
      "grad_norm": 0.016014939174056053,
      "learning_rate": 3.5142857142857144e-06,
      "loss": 0.0,
      "step": 3260
    },
    {
      "epoch": 23.3,
      "grad_norm": 0.012217825278639793,
      "learning_rate": 3.485714285714286e-06,
      "loss": 0.0,
      "step": 3262
    },
    {
      "epoch": 23.314285714285713,
      "grad_norm": 0.011391505599021912,
      "learning_rate": 3.4571428571428574e-06,
      "loss": 0.0,
      "step": 3264
    },
    {
      "epoch": 23.32857142857143,
      "grad_norm": 0.0163121335208416,
      "learning_rate": 3.428571428571429e-06,
      "loss": 0.0,
      "step": 3266
    },
    {
      "epoch": 23.34285714285714,
      "grad_norm": 0.007100990973412991,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.0,
      "step": 3268
    },
    {
      "epoch": 23.357142857142858,
      "grad_norm": 0.011509280651807785,
      "learning_rate": 3.371428571428572e-06,
      "loss": 0.0,
      "step": 3270
    },
    {
      "epoch": 23.37142857142857,
      "grad_norm": 0.0115050645545125,
      "learning_rate": 3.3428571428571427e-06,
      "loss": 0.0,
      "step": 3272
    },
    {
      "epoch": 23.385714285714286,
      "grad_norm": 0.015132909640669823,
      "learning_rate": 3.314285714285714e-06,
      "loss": 0.0,
      "step": 3274
    },
    {
      "epoch": 23.4,
      "grad_norm": 0.008810773491859436,
      "learning_rate": 3.2857142857142857e-06,
      "loss": 0.0,
      "step": 3276
    },
    {
      "epoch": 23.414285714285715,
      "grad_norm": 0.015401610173285007,
      "learning_rate": 3.2571428571428572e-06,
      "loss": 0.0,
      "step": 3278
    },
    {
      "epoch": 23.428571428571427,
      "grad_norm": 0.011315311305224895,
      "learning_rate": 3.2285714285714288e-06,
      "loss": 0.0,
      "step": 3280
    },
    {
      "epoch": 23.442857142857143,
      "grad_norm": 0.014711245894432068,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0,
      "step": 3282
    },
    {
      "epoch": 23.457142857142856,
      "grad_norm": 0.019813379272818565,
      "learning_rate": 3.171428571428572e-06,
      "loss": 0.0,
      "step": 3284
    },
    {
      "epoch": 23.47142857142857,
      "grad_norm": 0.009028971195220947,
      "learning_rate": 3.1428571428571433e-06,
      "loss": 0.0,
      "step": 3286
    },
    {
      "epoch": 23.485714285714284,
      "grad_norm": 0.00958950724452734,
      "learning_rate": 3.1142857142857144e-06,
      "loss": 0.0,
      "step": 3288
    },
    {
      "epoch": 23.5,
      "grad_norm": 0.009591263718903065,
      "learning_rate": 3.085714285714286e-06,
      "loss": 0.0,
      "step": 3290
    },
    {
      "epoch": 23.514285714285712,
      "grad_norm": 0.017067914828658104,
      "learning_rate": 3.0571428571428575e-06,
      "loss": 0.0,
      "step": 3292
    },
    {
      "epoch": 23.52857142857143,
      "grad_norm": 0.00691175227984786,
      "learning_rate": 3.028571428571429e-06,
      "loss": 0.0,
      "step": 3294
    },
    {
      "epoch": 23.542857142857144,
      "grad_norm": 0.02624521777033806,
      "learning_rate": 3e-06,
      "loss": 0.0,
      "step": 3296
    },
    {
      "epoch": 23.557142857142857,
      "grad_norm": 0.014250058680772781,
      "learning_rate": 2.9714285714285716e-06,
      "loss": 0.0,
      "step": 3298
    },
    {
      "epoch": 23.571428571428573,
      "grad_norm": 0.01084103062748909,
      "learning_rate": 2.942857142857143e-06,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 23.585714285714285,
      "grad_norm": 0.012439175508916378,
      "learning_rate": 2.9142857142857146e-06,
      "loss": 0.0,
      "step": 3302
    },
    {
      "epoch": 23.6,
      "grad_norm": 0.011537236161530018,
      "learning_rate": 2.8857142857142857e-06,
      "loss": 0.0,
      "step": 3304
    },
    {
      "epoch": 23.614285714285714,
      "grad_norm": 0.008845037780702114,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.0,
      "step": 3306
    },
    {
      "epoch": 23.62857142857143,
      "grad_norm": 0.00961887277662754,
      "learning_rate": 2.8285714285714288e-06,
      "loss": 0.0,
      "step": 3308
    },
    {
      "epoch": 23.642857142857142,
      "grad_norm": 0.018605681136250496,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0,
      "step": 3310
    },
    {
      "epoch": 23.65714285714286,
      "grad_norm": 0.00872610043734312,
      "learning_rate": 2.771428571428572e-06,
      "loss": 0.0,
      "step": 3312
    },
    {
      "epoch": 23.67142857142857,
      "grad_norm": 0.019852707162499428,
      "learning_rate": 2.742857142857143e-06,
      "loss": 0.0,
      "step": 3314
    },
    {
      "epoch": 23.685714285714287,
      "grad_norm": 0.009165855124592781,
      "learning_rate": 2.7142857142857144e-06,
      "loss": 0.0,
      "step": 3316
    },
    {
      "epoch": 23.7,
      "grad_norm": 0.005987728014588356,
      "learning_rate": 2.685714285714286e-06,
      "loss": 0.0,
      "step": 3318
    },
    {
      "epoch": 23.714285714285715,
      "grad_norm": 0.01897760108113289,
      "learning_rate": 2.6571428571428575e-06,
      "loss": 0.0,
      "step": 3320
    },
    {
      "epoch": 23.728571428571428,
      "grad_norm": 0.007526527624577284,
      "learning_rate": 2.628571428571429e-06,
      "loss": 0.0,
      "step": 3322
    },
    {
      "epoch": 23.742857142857144,
      "grad_norm": 0.005248540546745062,
      "learning_rate": 2.6e-06,
      "loss": 0.0,
      "step": 3324
    },
    {
      "epoch": 23.757142857142856,
      "grad_norm": 0.01865796558558941,
      "learning_rate": 2.5714285714285716e-06,
      "loss": 0.0,
      "step": 3326
    },
    {
      "epoch": 23.771428571428572,
      "grad_norm": 0.00910746306180954,
      "learning_rate": 2.542857142857143e-06,
      "loss": 0.0,
      "step": 3328
    },
    {
      "epoch": 23.785714285714285,
      "grad_norm": 0.011285169050097466,
      "learning_rate": 2.5142857142857147e-06,
      "loss": 0.0,
      "step": 3330
    },
    {
      "epoch": 23.8,
      "grad_norm": 0.01988614909350872,
      "learning_rate": 2.4857142857142858e-06,
      "loss": 0.0,
      "step": 3332
    },
    {
      "epoch": 23.814285714285713,
      "grad_norm": 0.011762029491364956,
      "learning_rate": 2.4571428571428573e-06,
      "loss": 0.0,
      "step": 3334
    },
    {
      "epoch": 23.82857142857143,
      "grad_norm": 0.01886896602809429,
      "learning_rate": 2.428571428571429e-06,
      "loss": 0.0,
      "step": 3336
    },
    {
      "epoch": 23.84285714285714,
      "grad_norm": 0.015327389352023602,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0,
      "step": 3338
    },
    {
      "epoch": 23.857142857142858,
      "grad_norm": 0.00785437785089016,
      "learning_rate": 2.371428571428572e-06,
      "loss": 0.0,
      "step": 3340
    },
    {
      "epoch": 23.87142857142857,
      "grad_norm": 0.008172955363988876,
      "learning_rate": 2.342857142857143e-06,
      "loss": 0.0,
      "step": 3342
    },
    {
      "epoch": 23.885714285714286,
      "grad_norm": 0.006165509577840567,
      "learning_rate": 2.3142857142857145e-06,
      "loss": 0.0,
      "step": 3344
    },
    {
      "epoch": 23.9,
      "grad_norm": 0.006787907797843218,
      "learning_rate": 2.285714285714286e-06,
      "loss": 0.0,
      "step": 3346
    },
    {
      "epoch": 23.914285714285715,
      "grad_norm": 0.009063281118869781,
      "learning_rate": 2.2571428571428575e-06,
      "loss": 0.0,
      "step": 3348
    },
    {
      "epoch": 23.928571428571427,
      "grad_norm": 0.013067839667201042,
      "learning_rate": 2.228571428571429e-06,
      "loss": 0.0,
      "step": 3350
    },
    {
      "epoch": 23.942857142857143,
      "grad_norm": 0.008281636983156204,
      "learning_rate": 2.2e-06,
      "loss": 0.0,
      "step": 3352
    },
    {
      "epoch": 23.957142857142856,
      "grad_norm": 0.011694404296576977,
      "learning_rate": 2.1714285714285716e-06,
      "loss": 0.0,
      "step": 3354
    },
    {
      "epoch": 23.97142857142857,
      "grad_norm": 0.008762178011238575,
      "learning_rate": 2.142857142857143e-06,
      "loss": 0.0,
      "step": 3356
    },
    {
      "epoch": 23.985714285714288,
      "grad_norm": 0.013091864995658398,
      "learning_rate": 2.1142857142857147e-06,
      "loss": 0.0,
      "step": 3358
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.010956118814647198,
      "learning_rate": 2.0857142857142858e-06,
      "loss": 0.0,
      "step": 3360
    },
    {
      "epoch": 24.014285714285716,
      "grad_norm": 0.008768088184297085,
      "learning_rate": 2.0571428571428573e-06,
      "loss": 0.0,
      "step": 3362
    },
    {
      "epoch": 24.02857142857143,
      "grad_norm": 0.0049940114840865135,
      "learning_rate": 2.028571428571429e-06,
      "loss": 0.0,
      "step": 3364
    },
    {
      "epoch": 24.042857142857144,
      "grad_norm": 0.010378643870353699,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0,
      "step": 3366
    },
    {
      "epoch": 24.057142857142857,
      "grad_norm": 0.016250088810920715,
      "learning_rate": 1.9714285714285714e-06,
      "loss": 0.0,
      "step": 3368
    },
    {
      "epoch": 24.071428571428573,
      "grad_norm": 0.017858192324638367,
      "learning_rate": 1.942857142857143e-06,
      "loss": 0.0,
      "step": 3370
    },
    {
      "epoch": 24.085714285714285,
      "grad_norm": 0.013645818457007408,
      "learning_rate": 1.9142857142857145e-06,
      "loss": 0.0,
      "step": 3372
    },
    {
      "epoch": 24.1,
      "grad_norm": 0.010751473717391491,
      "learning_rate": 1.8857142857142858e-06,
      "loss": 0.0,
      "step": 3374
    },
    {
      "epoch": 24.114285714285714,
      "grad_norm": 0.010802689008414745,
      "learning_rate": 1.8571428571428573e-06,
      "loss": 0.0,
      "step": 3376
    },
    {
      "epoch": 24.12857142857143,
      "grad_norm": 0.012053796090185642,
      "learning_rate": 1.8285714285714288e-06,
      "loss": 0.0,
      "step": 3378
    },
    {
      "epoch": 24.142857142857142,
      "grad_norm": 0.00940841156989336,
      "learning_rate": 1.8e-06,
      "loss": 0.0,
      "step": 3380
    },
    {
      "epoch": 24.15714285714286,
      "grad_norm": 0.019690554589033127,
      "learning_rate": 1.7714285714285714e-06,
      "loss": 0.0,
      "step": 3382
    },
    {
      "epoch": 24.17142857142857,
      "grad_norm": 0.007882881909608841,
      "learning_rate": 1.742857142857143e-06,
      "loss": 0.0,
      "step": 3384
    },
    {
      "epoch": 24.185714285714287,
      "grad_norm": 0.011125294491648674,
      "learning_rate": 1.7142857142857145e-06,
      "loss": 0.0,
      "step": 3386
    },
    {
      "epoch": 24.2,
      "grad_norm": 0.013100565411150455,
      "learning_rate": 1.685714285714286e-06,
      "loss": 0.0,
      "step": 3388
    },
    {
      "epoch": 24.214285714285715,
      "grad_norm": 0.00901323277503252,
      "learning_rate": 1.657142857142857e-06,
      "loss": 0.0,
      "step": 3390
    },
    {
      "epoch": 24.228571428571428,
      "grad_norm": 0.019627418369054794,
      "learning_rate": 1.6285714285714286e-06,
      "loss": 0.0,
      "step": 3392
    },
    {
      "epoch": 24.242857142857144,
      "grad_norm": 0.010161023586988449,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.0,
      "step": 3394
    },
    {
      "epoch": 24.257142857142856,
      "grad_norm": 0.016659481450915337,
      "learning_rate": 1.5714285714285717e-06,
      "loss": 0.0,
      "step": 3396
    },
    {
      "epoch": 24.271428571428572,
      "grad_norm": 0.013706894591450691,
      "learning_rate": 1.542857142857143e-06,
      "loss": 0.0,
      "step": 3398
    },
    {
      "epoch": 24.285714285714285,
      "grad_norm": 0.016946448013186455,
      "learning_rate": 1.5142857142857145e-06,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 24.285714285714285,
      "eval_cer": 0.003395585738539898,
      "eval_loss": 0.014765673317015171,
      "eval_runtime": 10.1685,
      "eval_samples_per_second": 27.438,
      "eval_steps_per_second": 3.442,
      "step": 3400
    },
    {
      "epoch": 24.3,
      "grad_norm": 0.008471881970763206,
      "learning_rate": 1.4857142857142858e-06,
      "loss": 0.0,
      "step": 3402
    },
    {
      "epoch": 24.314285714285713,
      "grad_norm": 0.006212090607732534,
      "learning_rate": 1.4571428571428573e-06,
      "loss": 0.0,
      "step": 3404
    },
    {
      "epoch": 24.32857142857143,
      "grad_norm": 0.014761506579816341,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 0.0,
      "step": 3406
    },
    {
      "epoch": 24.34285714285714,
      "grad_norm": 0.011875911615788937,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.0,
      "step": 3408
    },
    {
      "epoch": 24.357142857142858,
      "grad_norm": 0.009621352888643742,
      "learning_rate": 1.3714285714285715e-06,
      "loss": 0.0,
      "step": 3410
    },
    {
      "epoch": 24.37142857142857,
      "grad_norm": 0.013295546174049377,
      "learning_rate": 1.342857142857143e-06,
      "loss": 0.0,
      "step": 3412
    },
    {
      "epoch": 24.385714285714286,
      "grad_norm": 0.00808736588805914,
      "learning_rate": 1.3142857142857145e-06,
      "loss": 0.0,
      "step": 3414
    },
    {
      "epoch": 24.4,
      "grad_norm": 0.009889297187328339,
      "learning_rate": 1.2857142857142858e-06,
      "loss": 0.0,
      "step": 3416
    },
    {
      "epoch": 24.414285714285715,
      "grad_norm": 0.013509890995919704,
      "learning_rate": 1.2571428571428573e-06,
      "loss": 0.0,
      "step": 3418
    },
    {
      "epoch": 24.428571428571427,
      "grad_norm": 0.013362610712647438,
      "learning_rate": 1.2285714285714286e-06,
      "loss": 0.0,
      "step": 3420
    },
    {
      "epoch": 24.442857142857143,
      "grad_norm": 0.008588356897234917,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.0,
      "step": 3422
    },
    {
      "epoch": 24.457142857142856,
      "grad_norm": 0.009221984073519707,
      "learning_rate": 1.1714285714285715e-06,
      "loss": 0.0,
      "step": 3424
    },
    {
      "epoch": 24.47142857142857,
      "grad_norm": 0.00807623378932476,
      "learning_rate": 1.142857142857143e-06,
      "loss": 0.0,
      "step": 3426
    },
    {
      "epoch": 24.485714285714284,
      "grad_norm": 0.019036784768104553,
      "learning_rate": 1.1142857142857145e-06,
      "loss": 0.0,
      "step": 3428
    },
    {
      "epoch": 24.5,
      "grad_norm": 0.006482376717031002,
      "learning_rate": 1.0857142857142858e-06,
      "loss": 0.0,
      "step": 3430
    },
    {
      "epoch": 24.514285714285712,
      "grad_norm": 0.011533847078680992,
      "learning_rate": 1.0571428571428573e-06,
      "loss": 0.0,
      "step": 3432
    },
    {
      "epoch": 24.52857142857143,
      "grad_norm": 0.01045171357691288,
      "learning_rate": 1.0285714285714286e-06,
      "loss": 0.0,
      "step": 3434
    },
    {
      "epoch": 24.542857142857144,
      "grad_norm": 0.010782573372125626,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0,
      "step": 3436
    },
    {
      "epoch": 24.557142857142857,
      "grad_norm": 0.015296095982193947,
      "learning_rate": 9.714285714285715e-07,
      "loss": 0.0,
      "step": 3438
    },
    {
      "epoch": 24.571428571428573,
      "grad_norm": 0.00888185203075409,
      "learning_rate": 9.428571428571429e-07,
      "loss": 0.0,
      "step": 3440
    },
    {
      "epoch": 24.585714285714285,
      "grad_norm": 0.01277809776365757,
      "learning_rate": 9.142857142857144e-07,
      "loss": 0.0,
      "step": 3442
    },
    {
      "epoch": 24.6,
      "grad_norm": 0.014637608081102371,
      "learning_rate": 8.857142857142857e-07,
      "loss": 0.0,
      "step": 3444
    },
    {
      "epoch": 24.614285714285714,
      "grad_norm": 0.007855360396206379,
      "learning_rate": 8.571428571428572e-07,
      "loss": 0.0,
      "step": 3446
    },
    {
      "epoch": 24.62857142857143,
      "grad_norm": 0.00981050729751587,
      "learning_rate": 8.285714285714285e-07,
      "loss": 0.0,
      "step": 3448
    },
    {
      "epoch": 24.642857142857142,
      "grad_norm": 0.007318771909922361,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.0,
      "step": 3450
    },
    {
      "epoch": 24.65714285714286,
      "grad_norm": 0.026796307414770126,
      "learning_rate": 7.714285714285715e-07,
      "loss": 0.0,
      "step": 3452
    },
    {
      "epoch": 24.67142857142857,
      "grad_norm": 0.015036258846521378,
      "learning_rate": 7.428571428571429e-07,
      "loss": 0.0,
      "step": 3454
    },
    {
      "epoch": 24.685714285714287,
      "grad_norm": 0.006312703713774681,
      "learning_rate": 7.142857142857143e-07,
      "loss": 0.0,
      "step": 3456
    },
    {
      "epoch": 24.7,
      "grad_norm": 0.013946570456027985,
      "learning_rate": 6.857142857142857e-07,
      "loss": 0.0,
      "step": 3458
    },
    {
      "epoch": 24.714285714285715,
      "grad_norm": 0.011939547024667263,
      "learning_rate": 6.571428571428572e-07,
      "loss": 0.0,
      "step": 3460
    },
    {
      "epoch": 24.728571428571428,
      "grad_norm": 0.009472262114286423,
      "learning_rate": 6.285714285714287e-07,
      "loss": 0.0,
      "step": 3462
    },
    {
      "epoch": 24.742857142857144,
      "grad_norm": 0.01308978907763958,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.0,
      "step": 3464
    },
    {
      "epoch": 24.757142857142856,
      "grad_norm": 0.006344786379486322,
      "learning_rate": 5.714285714285715e-07,
      "loss": 0.0,
      "step": 3466
    },
    {
      "epoch": 24.771428571428572,
      "grad_norm": 0.01533918920904398,
      "learning_rate": 5.428571428571429e-07,
      "loss": 0.0,
      "step": 3468
    },
    {
      "epoch": 24.785714285714285,
      "grad_norm": 0.009004263207316399,
      "learning_rate": 5.142857142857143e-07,
      "loss": 0.0,
      "step": 3470
    },
    {
      "epoch": 24.8,
      "grad_norm": 0.008373143151402473,
      "learning_rate": 4.857142857142857e-07,
      "loss": 0.0,
      "step": 3472
    },
    {
      "epoch": 24.814285714285713,
      "grad_norm": 0.0157256331294775,
      "learning_rate": 4.571428571428572e-07,
      "loss": 0.0,
      "step": 3474
    },
    {
      "epoch": 24.82857142857143,
      "grad_norm": 0.010250872001051903,
      "learning_rate": 4.285714285714286e-07,
      "loss": 0.0,
      "step": 3476
    },
    {
      "epoch": 24.84285714285714,
      "grad_norm": 0.014511785469949245,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 0.0,
      "step": 3478
    },
    {
      "epoch": 24.857142857142858,
      "grad_norm": 0.004697002936154604,
      "learning_rate": 3.7142857142857145e-07,
      "loss": 0.0,
      "step": 3480
    },
    {
      "epoch": 24.87142857142857,
      "grad_norm": 0.02442014403641224,
      "learning_rate": 3.4285714285714286e-07,
      "loss": 0.0,
      "step": 3482
    },
    {
      "epoch": 24.885714285714286,
      "grad_norm": 0.011790655553340912,
      "learning_rate": 3.1428571428571433e-07,
      "loss": 0.0,
      "step": 3484
    },
    {
      "epoch": 24.9,
      "grad_norm": 0.016434865072369576,
      "learning_rate": 2.8571428571428575e-07,
      "loss": 0.0,
      "step": 3486
    },
    {
      "epoch": 24.914285714285715,
      "grad_norm": 0.006669965572655201,
      "learning_rate": 2.5714285714285716e-07,
      "loss": 0.0,
      "step": 3488
    },
    {
      "epoch": 24.928571428571427,
      "grad_norm": 0.010390954092144966,
      "learning_rate": 2.285714285714286e-07,
      "loss": 0.0,
      "step": 3490
    },
    {
      "epoch": 24.942857142857143,
      "grad_norm": 0.013986942358314991,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 0.0,
      "step": 3492
    },
    {
      "epoch": 24.957142857142856,
      "grad_norm": 0.006637472193688154,
      "learning_rate": 1.7142857142857143e-07,
      "loss": 0.0,
      "step": 3494
    },
    {
      "epoch": 24.97142857142857,
      "grad_norm": 0.01975933089852333,
      "learning_rate": 1.4285714285714287e-07,
      "loss": 0.0,
      "step": 3496
    },
    {
      "epoch": 24.985714285714288,
      "grad_norm": 0.011841476894915104,
      "learning_rate": 1.142857142857143e-07,
      "loss": 0.0,
      "step": 3498
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.013997696340084076,
      "learning_rate": 8.571428571428572e-08,
      "loss": 0.0,
      "step": 3500
    }
  ],
  "logging_steps": 2,
  "max_steps": 3500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.337528779001037e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
